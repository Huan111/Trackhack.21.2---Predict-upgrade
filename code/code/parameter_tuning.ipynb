{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.0.3 in /opt/conda/lib/python3.7/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==1.0.3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==1.0.3) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "teamname = 'emotional-support-vector-machine-unsw'\n",
    "root_folder='s3://tf-trachack-notebooks/'+teamname+'/jupyter/jovyan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kevin = pd.read_csv(root_folder+\"kevin-zhu/dev-extracted.csv\")\n",
    "kevin_train_X = kevin.drop(['line_id','upgrade'],axis=1)\n",
    "kevin_train_y = kevin['upgrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tunning of GradientBoostingClassifier(GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV] n_estimators=691 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. n_estimators=691, total=  51.4s\n",
      "[CV] n_estimators=691 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done   1 out of   1 | elapsed:   51.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. n_estimators=691, total=  51.3s\n",
      "[CV] n_estimators=691 ................................................\n",
      "[CV] ................................. n_estimators=691, total=  50.8s\n",
      "[CV] n_estimators=691 ................................................\n",
      "[CV] ................................. n_estimators=691, total=  51.7s\n",
      "[CV] n_estimators=691 ................................................\n",
      "[CV] ................................. n_estimators=691, total=  51.6s\n",
      "[CV] n_estimators=721 ................................................\n",
      "[CV] ................................. n_estimators=721, total=  53.3s\n",
      "[CV] n_estimators=721 ................................................\n",
      "[CV] ................................. n_estimators=721, total=  53.9s\n",
      "[CV] n_estimators=721 ................................................\n",
      "[CV] ................................. n_estimators=721, total=  53.8s\n",
      "[CV] n_estimators=721 ................................................\n",
      "[CV] ................................. n_estimators=721, total=  53.3s\n",
      "[CV] n_estimators=721 ................................................\n",
      "[CV] ................................. n_estimators=721, total=  54.1s\n",
      "[CV] n_estimators=751 ................................................\n",
      "[CV] ................................. n_estimators=751, total=  56.2s\n",
      "[CV] n_estimators=751 ................................................\n",
      "[CV] ................................. n_estimators=751, total=  56.8s\n",
      "[CV] n_estimators=751 ................................................\n",
      "[CV] ................................. n_estimators=751, total=  56.2s\n",
      "[CV] n_estimators=751 ................................................\n",
      "[CV] ................................. n_estimators=751, total=  56.3s\n",
      "[CV] n_estimators=751 ................................................\n",
      "[CV] ................................. n_estimators=751, total=  56.6s\n",
      "[CV] n_estimators=781 ................................................\n",
      "[CV] ................................. n_estimators=781, total=  58.6s\n",
      "[CV] n_estimators=781 ................................................\n",
      "[CV] ................................. n_estimators=781, total=  58.3s\n",
      "[CV] n_estimators=781 ................................................\n",
      "[CV] ................................. n_estimators=781, total=  58.0s\n",
      "[CV] n_estimators=781 ................................................\n",
      "[CV] ................................. n_estimators=781, total=  58.4s\n",
      "[CV] n_estimators=781 ................................................\n",
      "[CV] ................................. n_estimators=781, total=  59.2s\n",
      "[CV] n_estimators=811 ................................................\n",
      "[CV] ................................. n_estimators=811, total= 1.0min\n",
      "[CV] n_estimators=811 ................................................\n",
      "[CV] ................................. n_estimators=811, total= 1.0min\n",
      "[CV] n_estimators=811 ................................................\n",
      "[CV] ................................. n_estimators=811, total= 1.0min\n",
      "[CV] n_estimators=811 ................................................\n",
      "[CV] ................................. n_estimators=811, total= 1.0min\n",
      "[CV] n_estimators=811 ................................................\n",
      "[CV] ................................. n_estimators=811, total= 1.0min\n",
      "[CV] n_estimators=841 ................................................\n",
      "[CV] ................................. n_estimators=841, total= 1.1min\n",
      "[CV] n_estimators=841 ................................................\n",
      "[CV] ................................. n_estimators=841, total= 1.1min\n",
      "[CV] n_estimators=841 ................................................\n",
      "[CV] ................................. n_estimators=841, total= 1.1min\n",
      "[CV] n_estimators=841 ................................................\n",
      "[CV] ................................. n_estimators=841, total= 1.1min\n",
      "[CV] n_estimators=841 ................................................\n",
      "[CV] ................................. n_estimators=841, total= 1.1min\n",
      "[CV] n_estimators=871 ................................................\n",
      "[CV] ................................. n_estimators=871, total= 1.1min\n",
      "[CV] n_estimators=871 ................................................\n",
      "[CV] ................................. n_estimators=871, total= 1.1min\n",
      "[CV] n_estimators=871 ................................................\n",
      "[CV] ................................. n_estimators=871, total= 1.1min\n",
      "[CV] n_estimators=871 ................................................\n",
      "[CV] ................................. n_estimators=871, total= 1.1min\n",
      "[CV] n_estimators=871 ................................................\n",
      "[CV] ................................. n_estimators=871, total= 1.1min\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total= 1.1min\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total= 1.1min\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total= 1.1min\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total= 1.1min\n",
      "[CV] n_estimators=901 ................................................\n",
      "[CV] ................................. n_estimators=901, total= 1.1min\n",
      "[CV] n_estimators=931 ................................................\n",
      "[CV] ................................. n_estimators=931, total= 1.2min\n",
      "[CV] n_estimators=931 ................................................\n",
      "[CV] ................................. n_estimators=931, total= 1.2min\n",
      "[CV] n_estimators=931 ................................................\n",
      "[CV] ................................. n_estimators=931, total= 1.2min\n",
      "[CV] n_estimators=931 ................................................\n",
      "[CV] ................................. n_estimators=931, total= 1.2min\n",
      "[CV] n_estimators=931 ................................................\n",
      "[CV] ................................. n_estimators=931, total= 1.2min\n",
      "[CV] n_estimators=961 ................................................\n",
      "[CV] ................................. n_estimators=961, total= 1.2min\n",
      "[CV] n_estimators=961 ................................................\n",
      "[CV] ................................. n_estimators=961, total= 1.2min\n",
      "[CV] n_estimators=961 ................................................\n",
      "[CV] ................................. n_estimators=961, total= 1.2min\n",
      "[CV] n_estimators=961 ................................................\n",
      "[CV] ................................. n_estimators=961, total= 1.2min\n",
      "[CV] n_estimators=961 ................................................\n",
      "[CV] ................................. n_estimators=961, total= 1.2min\n",
      "[CV] n_estimators=991 ................................................\n",
      "[CV] ................................. n_estimators=991, total= 1.2min\n",
      "[CV] n_estimators=991 ................................................\n",
      "[CV] ................................. n_estimators=991, total= 1.3min\n",
      "[CV] n_estimators=991 ................................................\n",
      "[CV] ................................. n_estimators=991, total= 1.2min\n",
      "[CV] n_estimators=991 ................................................\n",
      "[CV] ................................. n_estimators=991, total= 1.2min\n",
      "[CV] n_estimators=991 ................................................\n",
      "[CV] ................................. n_estimators=991, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done  55 out of  55 | elapsed: 57.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_depth=8,\n",
       "                                                  max_features='sqrt',\n",
       "                                                  min_samples_leaf=50,\n",
       "                                                  min_samples_split=500,\n",
       "                                                  random_state=10,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=-4, param_grid={'n_estimators': range(691, 1000, 30)},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'n_estimators':range(691,1000,30)}\n",
    "CV_boost1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate = 0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='f1',n_jobs=-4, cv=5,verbose=2)\n",
    "CV_boost1.fit(kevin_train_X,kevin_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933924852860085"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_boost1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 961}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_result = pd.DataFrame(CV_boost1.cv_results_)\n",
    "boost_result = boost_result.sort_values(by = ['rank_test_score'])\n",
    "boost_result.iloc[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] max_depth=5, min_samples_split=200 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... max_depth=5, min_samples_split=200, total=  49.0s\n",
      "[CV] max_depth=5, min_samples_split=200 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done   1 out of   1 | elapsed:   49.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............... max_depth=5, min_samples_split=200, total=  48.8s\n",
      "[CV] max_depth=5, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=200, total=  48.3s\n",
      "[CV] max_depth=5, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=200, total=  50.8s\n",
      "[CV] max_depth=5, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=200, total=  49.2s\n",
      "[CV] max_depth=5, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=400, total=  48.7s\n",
      "[CV] max_depth=5, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=400, total=  48.9s\n",
      "[CV] max_depth=5, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=400, total=  48.5s\n",
      "[CV] max_depth=5, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=400, total=  48.4s\n",
      "[CV] max_depth=5, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=400, total=  48.7s\n",
      "[CV] max_depth=5, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=600, total=  48.3s\n",
      "[CV] max_depth=5, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=600, total=  52.5s\n",
      "[CV] max_depth=5, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=600, total=  48.8s\n",
      "[CV] max_depth=5, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=600, total=  48.7s\n",
      "[CV] max_depth=5, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=600, total=  49.3s\n",
      "[CV] max_depth=5, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=800, total=  48.6s\n",
      "[CV] max_depth=5, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=800, total=  48.0s\n",
      "[CV] max_depth=5, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=800, total=  49.6s\n",
      "[CV] max_depth=5, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=800, total=  48.8s\n",
      "[CV] max_depth=5, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=5, min_samples_split=800, total=  48.4s\n",
      "[CV] max_depth=5, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=5, min_samples_split=1000, total=  48.0s\n",
      "[CV] max_depth=5, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=5, min_samples_split=1000, total=  47.4s\n",
      "[CV] max_depth=5, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=5, min_samples_split=1000, total=  47.8s\n",
      "[CV] max_depth=5, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=5, min_samples_split=1000, total=  49.2s\n",
      "[CV] max_depth=5, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=5, min_samples_split=1000, total=  48.2s\n",
      "[CV] max_depth=7, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=200, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=200, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=200, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=200, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=200, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=400, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=400, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=400, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=400, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=400, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=600, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=600, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=600, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=600, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=600, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=800, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=800, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=800, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=800, total= 1.0min\n",
      "[CV] max_depth=7, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=7, min_samples_split=800, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=7, min_samples_split=1000, total= 1.0min\n",
      "[CV] max_depth=7, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=7, min_samples_split=1000, total= 1.0min\n",
      "[CV] max_depth=7, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=7, min_samples_split=1000, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=7, min_samples_split=1000, total= 1.1min\n",
      "[CV] max_depth=7, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=7, min_samples_split=1000, total= 1.1min\n",
      "[CV] max_depth=9, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=200, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=200, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=200, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=200, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=200 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=200, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=400, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=400, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=400, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=400, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=400 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=400, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=600, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=600, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=600, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=600, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=600 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=600, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=800, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=800, total= 1.4min\n",
      "[CV] max_depth=9, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=800, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=800, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=800 ..............................\n",
      "[CV] ............... max_depth=9, min_samples_split=800, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=9, min_samples_split=1000, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=9, min_samples_split=1000, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=9, min_samples_split=1000, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=9, min_samples_split=1000, total= 1.3min\n",
      "[CV] max_depth=9, min_samples_split=1000 .............................\n",
      "[CV] .............. max_depth=9, min_samples_split=1000, total= 1.3min\n",
      "[CV] max_depth=11, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=200, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=200, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=200, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=200, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=200, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=400, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=400, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=400, total= 1.7min\n",
      "[CV] max_depth=11, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=400, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=400, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=600, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=600, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=600, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=600, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=600, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=800, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=800, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=800, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=800, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=11, min_samples_split=800, total= 1.6min\n",
      "[CV] max_depth=11, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=11, min_samples_split=1000, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=11, min_samples_split=1000, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=11, min_samples_split=1000, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=11, min_samples_split=1000, total= 1.5min\n",
      "[CV] max_depth=11, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=11, min_samples_split=1000, total= 1.5min\n",
      "[CV] max_depth=13, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=200, total= 1.9min\n",
      "[CV] max_depth=13, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=200, total= 1.9min\n",
      "[CV] max_depth=13, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=200, total= 2.0min\n",
      "[CV] max_depth=13, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=200, total= 1.9min\n",
      "[CV] max_depth=13, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=200, total= 2.0min\n",
      "[CV] max_depth=13, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=400, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=400, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=400, total= 1.9min\n",
      "[CV] max_depth=13, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=400, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=400, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=600, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=600, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=600, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=600, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=600, total= 1.8min\n",
      "[CV] max_depth=13, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=800, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=800, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=800, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=800, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=13, min_samples_split=800, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=13, min_samples_split=1000, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=13, min_samples_split=1000, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=13, min_samples_split=1000, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=13, min_samples_split=1000, total= 1.7min\n",
      "[CV] max_depth=13, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=13, min_samples_split=1000, total= 1.7min\n",
      "[CV] max_depth=15, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=200, total= 2.2min\n",
      "[CV] max_depth=15, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=200, total= 2.2min\n",
      "[CV] max_depth=15, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=200, total= 2.2min\n",
      "[CV] max_depth=15, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=200, total= 2.1min\n",
      "[CV] max_depth=15, min_samples_split=200 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=200, total= 2.2min\n",
      "[CV] max_depth=15, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=400, total= 2.1min\n",
      "[CV] max_depth=15, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=400, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=400, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=400, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=400 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=400, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=600, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=600, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=600, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=600, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=600 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=600, total= 2.0min\n",
      "[CV] max_depth=15, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=800, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=800, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=800, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=800, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=800 .............................\n",
      "[CV] .............. max_depth=15, min_samples_split=800, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=15, min_samples_split=1000, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=15, min_samples_split=1000, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=15, min_samples_split=1000, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=15, min_samples_split=1000, total= 1.9min\n",
      "[CV] max_depth=15, min_samples_split=1000 ............................\n",
      "[CV] ............. max_depth=15, min_samples_split=1000, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done 150 out of 150 | elapsed: 214.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(max_features='sqrt',\n",
       "                                                  n_estimators=961,\n",
       "                                                  random_state=10,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=-4,\n",
       "             param_grid={'max_depth': range(5, 16, 2),\n",
       "                         'min_samples_split': range(200, 1001, 200)},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "CV_boost2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=961,\n",
    "                                                max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                       param_grid = param_test2, scoring='f1',n_jobs=-4, cv=5,verbose=2)\n",
    "CV_boost2.fit(kevin_train_X,kevin_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967699965779111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_boost2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13, 'min_samples_split': 600}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_result = pd.DataFrame(CV_boost2.cv_results_)\n",
    "boost_result = boost_result.sort_values(by = ['rank_test_score'])\n",
    "boost_result.iloc[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] min_samples_leaf=30 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. min_samples_leaf=30, total= 1.4min\n",
      "[CV] min_samples_leaf=30 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. min_samples_leaf=30, total= 1.4min\n",
      "[CV] min_samples_leaf=30 .............................................\n",
      "[CV] .............................. min_samples_leaf=30, total= 1.4min\n",
      "[CV] min_samples_leaf=40 .............................................\n",
      "[CV] .............................. min_samples_leaf=40, total= 1.4min\n",
      "[CV] min_samples_leaf=40 .............................................\n",
      "[CV] .............................. min_samples_leaf=40, total= 1.4min\n",
      "[CV] min_samples_leaf=40 .............................................\n",
      "[CV] .............................. min_samples_leaf=40, total= 1.9min\n",
      "[CV] min_samples_leaf=50 .............................................\n",
      "[CV] .............................. min_samples_leaf=50, total= 2.0min\n",
      "[CV] min_samples_leaf=50 .............................................\n",
      "[CV] .............................. min_samples_leaf=50, total= 1.9min\n",
      "[CV] min_samples_leaf=50 .............................................\n",
      "[CV] .............................. min_samples_leaf=50, total= 1.9min\n",
      "[CV] min_samples_leaf=60 .............................................\n",
      "[CV] .............................. min_samples_leaf=60, total= 2.1min\n",
      "[CV] min_samples_leaf=60 .............................................\n",
      "[CV] .............................. min_samples_leaf=60, total= 2.0min\n",
      "[CV] min_samples_leaf=60 .............................................\n",
      "[CV] .............................. min_samples_leaf=60, total= 1.9min\n",
      "[CV] min_samples_leaf=70 .............................................\n",
      "[CV] .............................. min_samples_leaf=70, total= 1.9min\n",
      "[CV] min_samples_leaf=70 .............................................\n",
      "[CV] .............................. min_samples_leaf=70, total= 1.9min\n",
      "[CV] min_samples_leaf=70 .............................................\n",
      "[CV] .............................. min_samples_leaf=70, total= 2.0min\n",
      "[CV] min_samples_leaf=80 .............................................\n",
      "[CV] .............................. min_samples_leaf=80, total= 2.2min\n",
      "[CV] min_samples_leaf=80 .............................................\n",
      "[CV] .............................. min_samples_leaf=80, total= 2.2min\n",
      "[CV] min_samples_leaf=80 .............................................\n",
      "[CV] .............................. min_samples_leaf=80, total= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done  18 out of  18 | elapsed: 33.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingClassifier(max_depth=13,\n",
       "                                                  max_features='sqrt',\n",
       "                                                  min_samples_split=600,\n",
       "                                                  n_estimators=961,\n",
       "                                                  random_state=10,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=-4, param_grid={'min_samples_leaf': range(30, 81, 10)},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_leaf':range(30,81,10)}\n",
    "CV_boost3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                                n_estimators=961,\n",
    "                                                                min_samples_split=600,\n",
    "                                                                max_depth=13,\n",
    "                                                                max_features='sqrt', \n",
    "                                                                subsample=0.8, \n",
    "                                                                random_state=10), \n",
    "                       param_grid = param_test3, scoring='f1',n_jobs=-4, cv=3,verbose=2)\n",
    "CV_boost3.fit(train_feature,kevin_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8838203255207122"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_boost3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 80}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_result3 = pd.DataFrame(CV_boost3.cv_results_)\n",
    "boost_result3 = boost_result3.sort_values(by = ['rank_test_score'])\n",
    "boost_result3.iloc[0]['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final F1 score of GBM after para tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938637461749074"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8)\n",
    "optimaize = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                       n_estimators=961,\n",
    "                                       min_samples_split=600,\n",
    "                                       min_samples_leaf=80,\n",
    "                                       max_depth=13,\n",
    "                                       max_features='sqrt',\n",
    "                                       subsample=0.8,\n",
    "                                       random_state=10)\n",
    "optimaize.fit(X_train,y_train)\n",
    "pred = optimaize.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most important features in GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAKOCAYAAACsiH/OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOydedxvU/XH3+teYyJjMhMqs5AhlalCE9GgKCSl4ZdKUakMpZKhUiEJlSQpoRQqQylTZldKZq55uFzjvXf9/ljr3O95znO+55zn3se9D9/P+/U6r+f7nLPP3vucs4e11157bXN3hBBCCCGEGDTGze4MCCGEEEIIMTuQICyEEEIIIQYSCcJCCCGEEGIgkSAshBBCCCEGEgnCQgghhBBiIJEgLIQQQgghBhIJwkKIMY+ZfcnMjp3d+Xg+Ymb7m9mJszsfI+X5mm8hxPMLCcJCvMAxs1vN7Ekze7x0LDkKcb5xtPLYhrt/w90/PKvSa2KQBbRKWbrHzE4wsxfP7nyNBDNb3sy8Uh+unsV5cDNbaVamKYSoR4KwEIPB2939xaXj7tmZGTObY3amP6M8X/M9yrzd3V8MrA28Gvji7M3ODLNgqT6sNdKbVRaEeGEgQViIAcXMXmJmPzGziWZ2l5l93czG57UVzeyvZvagmT1gZr8wswXz2s+BZYEzU5u2t5ltamZ3VuKfrjVOLeqpZnaimU0CdmlKvyav07WwJY3ermZ2h5k9bGZ7mNlrzOwaM3vEzH5QuncXM7vIzL5vZo+a2b/NbIvS9SXN7Awze8jMbjKz3SvplvO9B/Al4L1lTWLm5QYze8zMbjazj5bi2NTM7jSzvczsvnzeXUvX5zWzw8zstszf381s3ry2oZn9I5/pajPbtPJcN2eat5jZjg2fex4z+1WGvcLM1so4Pm9mv6m86++b2Xcb4gLA3e8BziYE4uLeL5jZ/zKdCWb2zkp+/25mh+Y3u8XMti5dX8HMLsh7zwUWreTrHWZ2fb6L881sldK1W/NZrjGzyVmuFjezP2Z8fzazhdqeaYRlobEMm9lK+TyPWtShX+X5CzPKq7MMvbctX0KI5xB316FDxwv4AG4F3lhz/nfAj4D5gJcClwIfzWsrAW8C5gYWAy4EvtsvTmBT4M5+6QL7A88C2xID8Hmb0q/J6/7Aifl7ecCBo4F5gDcDT2V8LwWWAu4DNsnwuwBTgM8AcwLvBR4FFs7rFwBHZlxrA/cDWzTke3peSvl7K7AiYMAmwBPAOqV3MwU4MNN/S15fKK//EDg/8z0eeG2+96WABzP8uPweD+b3mA+YBLwy41gCWK3h3T0LvCvT/xxwS/5eAphMaEcB5sh3t25bWQKWBq4Fvle6/m5gyczvezPuJUrf4Vlg93zOjwF3A5bX/wkcns/+BuCx0jd/Rcb1psz33sBNwFylfF0MLF76/lcQGuu5gb8C+1XKzxw1zzfSsvA7+tehXwL7Zth5gNeV0nFgpdndNujQocMlCOvQ8UI/Ukh4HHgkj9+lwPA0MG8p3PuA8/rEsS1wZSXOkQrCF5aujTT9/RkuCC9Vuv4g8N7S/78BPp2/dykLXHnuUuADwDLAVGD+0rVvAifU5bual4Z3/jtgz9K7ebIseBGC2oYpJD0JrFUTxz7AzyvnzgZ2TsHrEWD78jtseHcXl/4fB0wEXp///xHYPX+/DZjQoSw9lt/gL6QQ3Sf8VcA2pe9wU+naizKOlxEzDFOA+UrXTyp9868Ap1Se4S5g01K+dqx8/6NK//8f8LtK+XmkdHxupGWBljIM/Aw4Bli65r1IENahY4wcMo0QYjDY1t0XzGNbYDlCszYxp5ofITRbLwUws5ea2ck53TsJOJHKVPUMcEfpd2P6Hbm39PvJmv/Li7jucncv/X8boblcEnjI3R+rXFuqT75rMbOtzezinFJ/hNDilt/Xg+4+pfT/E5m/RQlt4f9qol0OeHfxfjLe1xEa1smExnUP4h3+wcxe1ZDF6c/g7tOAO4lnB/gpsFP+3gn4ecvjbuvu8xMC/qvKz2lmHzSzq0r5XZ2h7+GeUj6eyJ8vzrw8nM9VcFvp95Ll//MZ7mDodxpJeQBYtFQnDmXkZaGtDO9NzBBcmiYdH0IIMeaQICzEYHIHoc0qCwMLuPtqef2bhNZqTXdfgBCQrHS/D42OyYSGD4C0k1ysEqZ8T1v6o81SZlbO/7KElvhuYGEzm79y7a4++R72v5nNTWggDwUWd/cFgbMY+r768QBh1rFizbU7CI3wgqVjPnf/FoC7n+3ubyLMG/4N/LghnWVK+R1HmDUUCyZ/B6xpZqsTGuFfdMg37n4BcALx3JjZcpmHTwKL5Hu4jm7vYSKwkJnNVzq3bOn33YTgWTyD5TOVv9PMMtKy0FiG3f0ed9/d3ZcEPgocafIUIcSYQ4KwEAOIu08EzgEOM7MFzGycxQK5TTLI/KQ5hZktBXy+EsW9wMtL//+HWJD1VjObE/gyYZs5o+mPNi8FPmVmc5rZu4FVgLPc/Q7gH8A3zWweM1sT2I1mYfBeYPkUKAHmIp71fmBKLgB7c5dMpWbzOODwXKg13sw2SuH6RODtZrZlnp/HYuHd0rkQ7B0pOD5NfKupDUmta2bbWXg6+HTec3Hm4SngVMIU4VJ3v71L3pPvAm8ys7UJcw3P94DFgsDVO76H24DLgQPMbC4zex3w9lKQU4C3mtkWWb72ymf4xwjy2paHEZWFtjJsZu82s6Uz+MPEuym+UbX+CCFmExKEhRhcPkgIcROIjvpUQrsIcACwDrGo7A/Abyv3fhP4ck4Jf87dHwU+DhxLaNAmE9PvM5r+aHMJsDKhgT0IeJe7P5jX3kfYjd4NnEYsqjq3Ia5f598HzeyKnEr/FCGsPQy8HzhjBHn7HLHo7DLgIeBgYFwKZtsQXiruJzSQnyfa7XGEMHh33rMJ8f77cTphSvEwYRu9nbs/W7r+U2AN2s0ihuDu9xO2sF9x9wnAYcSit3szvotGEN37gQ2I59kv4y3SuZGYlfg+8Q3fTrhxe2Yk+e3ASMtCUxl+DXCJmT1OlIc93f2WvLY/8NOsP+8Z5WcQQoyAYrWuEEK8IDGzXYAPu/vrZndexipmtixhXvEyd580u/MjhBCzCmmEhRBigEkTj88CJ0sIFkIMGtoZRwghBpS0Mb6X8I6w1WzOjhBCzHJkGiGEEEIIIQYSmUYIIYQQQoiBZLaZRiy66KK+/PLLz67khRBCCCHEgPCvf/3rAXev+reffYLw8ssvz+WXXz67khdCCCGEEAOCmd1Wd16mEUIIIYQQYiCRICyEEEIIIQYSCcJCCCGEEGIgkSAshBBCCCEGEgnCQgghhBBiIJEgLIQQQgghBhIJwkIIIYQQYiCRICyEEEIIIQYSCcJCCCGEEGIgkSAshBBCCCEGEgnCQgghhBBiIGkVhM3sODO7z8yu63PdzOwIM7vJzK4xs3VGP5tCCCGEEEKMLl00wicAWzVc3xpYOY+PAEfNfLaEEEIIIYR4bpmjLYC7X2hmyzcE2Qb4mbs7cLGZLWhmS7j7xNHKpBBCCCFmDSddcjunX3XX7M6GEJ1ZdckF2O/tq83Qva2CcAeWAu4o/X9nnhsmCJvZRwitMcsuu+woJC2EEEIMBrNKQL3klocA2GCFhZ/ztISY3YyGIGw157wuoLsfAxwDsN5669WGEUIIIZ4vzErt6awSUDdYYWG2WXsp3r+BFFbihc9oCMJ3AsuU/l8auHsU4hVCCCGeM0ZDiJ2V2lMJqEKMPqMhCJ8BfNLMTgY2AB6VfbAQQojnitHSwo6GECvhVIjnN62CsJn9EtgUWNTM7gT2A+YEcPejgbOAtwA3AU8Auz5XmRVCCPH8ZSwJsMX9EmKFGGy6eI14X8t1Bz4xajkSQgjxvKRN0JUAK4QYa4yGaYQQQogXOF20uW2CrgRYIcRYQ4KwEEIMOKMh5BbXJOgKIZ5PSBAWQogB5/Sr7mLCxEmsusQCfcNIyBVCvBCRICyEEC9gumh7CyH4Vx/daBblSgghxgbjZncGhBBCPHcU2t4mVl1iAbZZe6lZlCMhhBg7SCMshBDPU6TtFUKImUMaYSGEeJ4iba8QQswc0ggLIcQYpU3jK22vEELMHBKEhRBiNjAaLsuk7RVCiJlDgrAQQswG5LJMCCFmPxKEhRBilNEiNiGEeH6gxXJCCDHKaBGbEEI8P5BGWAghRoC0vUII8cJBGmEhhBgB0vYKIcQLB2mEhRAikbZXCCEGC2mEhRAikbZXCCEGC2mEhRADgzaoEEIIUUYaYSHEwNCm8ZW2VwghBgtphIUQA4U0vkIIIQokCAshXhCMZKGbEEIIATKNEEK8QNBCNyGEECNFGmEhxAsGmT0IIYQYCRKEhRBjHpk9CCGEeC6QaYQQYswjswchhBDPBdIICyFmK9rNTQghxOxCGmEhxGxF2l4hhBCzC2mEhRCzHWl7hRBCzA4kCAshnjO0yE0IIcRYRqYRQojnDJk9CCGEGMtIIyyEeE6R2YMQQoixigRhIcQMIbMHIYQQz3dkGiGEmCFk9iCEEOL5jjTCQogZRmYPQgghns9IEBZC1NJm+iCzByGEEM93ZBohhKilzfRBZg9CCCGe70gjLIToi0wfhBBCvJCRICzEACKPD0IIIYRMI4QYSOTxQQghhJBGWIiBRWYPQgghBh0JwkK8wJDZgxBCCNENmUYI8QJDZg9CCCFEN6QRFuIFiMwehBBCiHYkCAvxPEJmD0IIIcToIdMIIZ5HyOxBCCGEGD2kERbieYbMHoQQQojRQRphIYQQQggxkEgjLMQYQfa/QgghxKxFGmEhxgiy/xVCCCFmLdIICzGGkP2vEEIIMeuQICzELKLN9EFmD0IIIcSsRaYRQswi2kwfZPYghBBCzFqkERZiFiLTByGEEGLsII2wEEIIIYQYSDpphM1sK+B7wHjgWHf/VuX6S4ATgWUzzkPd/fhRzqsQYxa5PhNCCCGef7RqhM1sPPBDYGtgVeB9ZrZqJdgngAnuvhawKXCYmc01ynkVYswi12dCCCHE848uGuH1gZvc/WYAMzsZ2AaYUArjwPxmZsCLgYeAKaOcVyHGNLL/FUIIIZ5fdLERXgq4o/T/nXmuzA+AVYC7gWuBPd19WjUiM/uImV1uZpfff//9M5hlIYQQQgghZp4ugrDVnPPK/1sCVwFLAmsDPzCzYcaQ7n6Mu6/n7usttthiI8yqEEIIIYQQo0cX04g7gWVK/y9NaH7L7Ap8y90duMnMbgFeBVw6KrkUYjaihXBCCCHEC5MuGuHLgJXNbIVcALcDcEYlzO3AFgBmtjjwSuDm0cyoELMLLYQTQgghXpi0aoTdfYqZfRI4m3Cfdpy7X29me+T1o4GvASeY2bWEKcU+7v7Ac5hvIWYpWggnhBBCvPDo5EfY3c8CzqqcO7r0+27gzaObNSGEEEIIIZ47tMWyGGhk/yuEEEIMLtpiWQw0sv8VQgghBhdphMXAI/tfIYQQYjCRRlgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJLIRFi9Y5BFCCCGEEE1IIyxesMgjhBBCCCGakEZYvKCRRwghhBBC9EMaYSGEEEIIMZBIEBZCCCGEEAOJTCPE85a2xXBaCCeEEEKIJqQRFs9b2hbDaSGcEEIIIZqQRlg8r9FiOCGEEELMKNIICyGEEEKIgUSCsBBCCCGEGEgkCAshhBBCiIFEgrAQQgghhBhItFhOjEnaXKOB3KMJIYQQYuaQRliMSdpco4HcowkhhBBi5pBGWIxZ5BpNCCGEEM8l0ggLIYQQQoiBRIKwEEIIIYQYSCQICyGEEEKIgUSCsBBCCCGEGEi0WE7McuQaTQghhBBjAWmExSxHrtGEEEIIMRaQRljMFuQaTQghhBCzG2mEhRBCCCHEQCJBWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIq8RYlSRj2AhhBBCPF+QRliMKvIRLIQQQojnC9IIi1FHPoKFEEII8XxAGmEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkEgQFkIIIYQQA4kEYSGEEEIIMZBIEBZCCCGEEAOJ3KeJzmizDCGEEEK8kJBGWHRGm2UIIYQQ4oWENMJiRGizDCGEEEK8UJBGWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJPIaIabT5idYPoKFEEII8UJCGmExnTY/wfIRLIQQQogXEtIIiyHIT7AQQgghBoVOGmEz28rMbjSzm8zsC33CbGpmV5nZ9WZ2wehmUwghhBBCiNGlVSNsZuOBHwJvAu4ELjOzM9x9QinMgsCRwFbufruZvfQ5yq8QQgghhBCjQheN8PrATe5+s7s/A5wMbFMJ837gt+5+O4C73ze62RRCCCGEEGJ06SIILwXcUfr/zjxX5hXAQmZ2vpn9y8w+WBeRmX3EzC43s8vvv//+GcuxEEIIIYQQo0AXQdhqznnl/zmAdYG3AlsCXzGzVwy7yf0Yd1/P3ddbbLHFRpxZIYQQQgghRosuXiPuBJYp/b80cHdNmAfcfTIw2cwuBNYC/jMquRRCCCGEEGKU6SIIXwasbGYrAHcBOxA2wWVOB35gZnMAcwEbAN8ZzYyKmaNtswzQhhlCCCGEGCxaTSPcfQrwSeBs4AbgFHe/3sz2MLM9MswNwJ+Aa4BLgWPd/brnLttipLRtlgHaMEMIIYQQg0WnDTXc/SzgrMq5oyv/HwIcMnpZE6ONNssQQgghhOihLZaFEEIIIcRAIkFYCCGEEEIMJBKEhRBCCCHEQCJBWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJJ021BBjG22fLIQQQggxcqQRfgGg7ZOFEEIIIUaONMIvELR9shBCCCHEyJBGWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJBKEhRBCCCHEQCJBWAghhBBCDCTyIzzG0a5xQgghhBDPDdIIj3G0a5wQQgghxHODNMLPA7RrnBBCCCHE6CONsBBCCCGEGEgkCAshhBBCiIFEgrAQQgghhBhIJAgLIYQQQoiBRIKwEEIIIYQYSCQICyGEEEKIgUSCsBBCCCGEGEgkCAshhBBCiIFEG2rMRrR9shBCCCHE7EMa4dmItk8WQgghhJh9SCM8m9H2yUIIIYQQswdphIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJBKEhRBCCCHEQCJBWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwk2lDjOULbJwshhBBCjG2kEX6O0PbJQgghhBBjG2mEn0O0fbIQQgghxNhFGmEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkEgQFkIIIYQQA4kEYSGEEEIIMZBIEBZCCCGEEAOJBGEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkGhnuRnkpEtu5/Sr7up7fcLESay6xAKzMEdCCCGEEGIkdNIIm9lWZnajmd1kZl9oCPcaM5tqZu8avSyOTU6/6i4mTJzU9/qqSyzANmsvNQtzJIQQQgghRkKrRtjMxgM/BN4E3AlcZmZnuPuEmnAHA2c/Fxkdi6y6xAL86qMbze5sCCGEEEKIGaCLRnh94CZ3v9ndnwFOBrapCfd/wG+A+0Yxf0IIIYQQQjwndBGElwLuKP1/Z56bjpktBbwTOLopIjP7iJldbmaX33///SPNqxBCCCGEEKNGF0HYas555f/vAvu4+9SmiNz9GHdfz93XW2yxxTpmUQghhBBCiNGni9eIO4FlSv8vDdxdCbMecLKZASwKvMXMprj770Yjk0IIIYQQQow2XQThy4CVzWwF4C5gB+D95QDuvkLx28xOAH4vIVgIIYQQQoxlWgVhd59iZp8kvEGMB45z9+vNbI+83mgXLIQQQgghxFik04Ya7n4WcFblXK0A7O67zHy2hBBCCCGEeG7RFstCCCGEEGIgkSAshBBCCCEGEgnCQgghhBBiIJEgLIQQQgghBhIJwkIIIYQQYiCRICyEEEIIIQaSTu7TBo2TLrmd06+6qzHMhImTWHWJBWZRjoQQQgghxGgjjXANp191FxMmTmoMs+oSC7DN2kvNohwJIYQQQojRRhrhPqy6xAL86qMbze5sCCGEEEKI5whphIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJBKEhRBCCCHEQCJBWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAIkFYCCGEEEIMJBKEhRBCCCHEQCJBWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAMsfszsCs5qRLbuf0q+5qDDNh4iRWXWKBWZQjIYQQQggxOxg4jfDpV93FhImTGsOsusQCbLP2UrMoR0IIIYQQYnYwcBphCEH3Vx/daHZnQwghhBBCzEYGTiMshBBCCCEESBAWQgghhBADigRhIYQQQggxkEgQFkIIIYQQA4kEYSGEEEIIMZBIEBZCCCGEEAOJBGEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkEgQFkIIIYQQA4kEYSGEEEIIMZBIEBZCCCGEEAOJBGEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkMwxuzMwmpx0ye2cftVdjWEmTJzEqkssMItyJIQQQgghxiovKI3w6VfdxYSJkxrDrLrEAmyz9lKzKEdCCCGEEGKs8oLSCEMIur/66EazOxtCCCGEEGKM84LSCAshhBBCCNEVCcJCCCGEEGIgkSAshBBCCCEGEgnCQgghhBBiIJEgLIQQQgghBhIJwkIIIYQQYiCRICyEEEIIIQYSCcJCCCGEEGIg6SQIm9lWZnajmd1kZl+oub6jmV2Txz/MbK3Rz6oQQgghhBCjR6sgbGbjgR8CWwOrAu8zs1UrwW4BNnH3NYGvAceMdkaFEEIIIYQYTbpohNcHbnL3m939GeBkYJtyAHf/h7s/nP9eDCw9utkUQgghhBBidOkiCC8F3FH6/84814/dgD/WXTCzj5jZ5WZ2+f333989l0IIIYQQQowyXQRhqznntQHNNiME4X3qrrv7Me6+nruvt9hii3XPpRBCCCGEEKPMHB3C3AksU/p/aeDuaiAzWxM4Ftja3R8cnewJIYQQQgjx3NBFI3wZsLKZrWBmcwE7AGeUA5jZssBvgQ+4+39GP5tCCCGEEEKMLq0aYXefYmafBM4GxgPHufv1ZrZHXj8a+CqwCHCkmQFMcff1nrtsCyGEEEIIMXN0MY3A3c8CzqqcO7r0+8PAh0c3a0M56ZLbOf2quxrDTJg4iVWXWOC5zIYQQgghhHiB8LzZWe70q+5iwsRJjWFWXWIBtlm7yaGFEEIIIYQQQSeN8Fhh1SUW4Fcf3Wh2Z0MIIYQQQrwAeN5ohIUQQgghhBhNJAgLIYQQQoiBRIKwEEIIIYQYSCQICyGEEEKIgUSCsBBCCCGEGEgkCAshhBBCiIFEgrAQQgghhBhIJAgLIYQQQoiBRIKwEEIIIYQYSCQICyGEEEKIgUSCsBBCCCGEGEgkCAshhBBCiIFEgrAQQgghhBhIJAgLIYQQQoiBRIKwEEIIIYQYSCQICyGEEEKIgUSCsBBCCCGEGEgkCAshhBBCiIFEgrAQQgghhBhIJAgLIYQQQoiBZI7ZnYF+HHDm9Uy4e9L0/ydMnMSqSywwG3MkhBBCCCFeSIwpQfi3N06c/vumhyfzwJPPTP//pQvOwzZrLzU7siWEEEIIIV6AjClBuMw7N1hm2LntXrnEbMiJEEIIIYR4ISIbYSGEEEIIMZBIEBZCCCGEEAOJBGEhhBBCCDGQSBAWQgghhBADiQRhIYQQQggxkEgQFkIIIYQQA4kEYSGEEEIIMZBIEBZCCCGEEAOJBGEhhBBCCDGQjNmd5fpR3oa5inaeE0IIIYQQXZFGWAghhBBCDCQShIUQQgghxEDyvDON6ILMJ4QQQgghRBsvSEG4C12EZQnUQgghhBAvXGQaIYQQQgghBpKB1QiPFtIaCyGEEEI8P5FGWAghhBBCDCQShIUQQgghxEAiQVgIIYQQQgwkEoSFEEIIIcRAosVyzzFy0yaEEEIIMTaRIPw8YbQEagndQgghhBCBTCOEEEIIIcRAIo2wGMKs1DxLOy2EEEKI2Yk0wkIIIYQQYiCRRliMadq0xk3XizBCCCGEEHVIEBYveGSmIYQQQog6JAgL0REJ1EIIIcQLi06CsJltBXwPGA8c6+7fqly3vP4W4AlgF3e/YpTzKsQLgpkx95gdCxZHI79CCCHEWKRVEDaz8cAPgTcBdwKXmdkZ7j6hFGxrYOU8NgCOyr9CCPG8E9zlGUUIIQaDLhrh9YGb3P1mADM7GdgGKAvC2wA/c3cHLjazBc1sCXdvXskkhBADzmgsCB1rwr1mEYQQzxe6CMJLAXeU/r+T4dreujBLAUNaOzP7CPCR/PdxM7uxJe1FgQdmQZhZlc5ohRlLeRmtMGMpL13CjKW8dAkzlvIyWmHGUl66hBlLeekSZizlpUuYsZSX0QozlvLSJcxYykuXMGMpL6MVZizlpUuYWZmX5WrPunvjAbybsAsu/v8A8P1KmD8Aryv9/xdg3ba4O6R9+awIM6vSGdT8vhCfaSzl5YWY3xfiM42lvCi/z48wYykvyu/zI8xYystYy2+/o8uGGncCy5T+Xxq4ewbCCCGEEEIIMWboIghfBqxsZiuY2VzADsAZlTBnAB+0YEPgUZd9sBBCCCGEGMO02gi7+xQz+yRwNuE+7Th3v97M9sjrRwNnEa7TbiLcp+06Svk7ZhaFmVXpjFaYsZSX0QozlvLSJcxYykuXMGMpL6MVZizlpUuYsZSXLmHGUl66hBlLeRmtMGMpL13CjKW8dAkzlvIyWmHGUl66hJmVeanF0rZCCCGEEEKIgaKLaYQQQgghhBAvOCQICyGEEEKIgUSCsBBCCCGEGEgkCAshhBCzifS0JJ6nmNkbzexFszsfs5P0KNZ0fZyZvXxW5WekSBAeQ5jZemb2XjObL/+fz8y67P4nRoiZrWJmN3cNY2Zrz5KMDShmtqyZWc15M7Nlu4YZYZovNrMXz1iOO8U/zszGlf5/mZl92Mw27nj/xmZ2iJl9ycyWqVxbyMz+Oop5nSVpmdkeZvYLM9s9/9/RzP5rZreb2UGjkcasZhSe6UIz+9pYa+uz/K5a9EfPB8xscTP7nJkdZWaL5rmNzWyFSrhFzWwDM5t7FJI9iz47lpnZvGa2eh7zjjTipjJhZguNNL6aOE4ys/lL/+9R+X8hM7uwQ1RPmtlLS/f93cyWKl1fDPjvzOb3ueJ57TXCzBakXpg/CNgCeGn1ursvMAPpLAqsCFzl7k+Xzk8FlnD3+yrhFwHuc/fxZjYPsGdDftY0s8UJX8yvARxYGXgEOBx4CvhSU/7c/aGRPlMprysBd7r7Uy1hFgWeaYjqraXftzWl6e4/a0hrfWBK0/2leK7oEq5POmsBV7j7+C5hzGwacCVwLHCSuz86A2kuBOwPbEZ9WSg3JEtWwmyWf29pSKLY+vySDtn5vbv3/Z4pwC0P3Jp5m5bnXwa8DbjB3S/qkE4nOtal1jClc9X3Rz7HFWb2aeCzxDbwEJv/HA5817NBNLM1gI8S9f5D7j7RzLYFbnP3Kyvp16ZFtEN/cvfvpcD9b2A+4MXAbi314O3AacC/gPkzr+939z/k9cWBu5vKbxPFAMDdHx9pWmb2Gne/rE+8OwGPuPvva67tBXwD+D2wEXAk8Bni3Y8H9gL2dvcfteR9LWBhdz+vdG5H4GvEu70Q2NHdnzazdZriyvJwHLCnuz9WSedWYGGat219CbAQ8f4an8nMFqa+bxoPzAtcBezk7hOa8lzJ43pEGf29u09OofVpd+/UhrbEbcDTwKruftNMxjUP0W6sCPzI3R8xsxWBh939ITNbDMDd78/wawDvBa5391+W4lmc2N12ReAr7v5ADizvJr7VX4g2cjXgVe5+s5ntD7zC3d+fQt5PgHeRfW2GOR14CDi+4TGKa5Mr51cnhLyn8xnWTAH7YKINmQso3uUxwD5Ff5sDzO3c/ZHK+1oA+B2wAPA+d/9v5fobgePdfcigdaRU21QzmwSs7e6FAqhTO5P948tK8TwGrFWJZ6K7jzOzN/SJxgl5538zI9PMCGNtBNpaGcxsOeBoQjCYs3w78SLPAF5NFLi781zBNmb21S55cfcD6yoNcLOZHQ3ck2nWMTc9ofFI4J3Ar4F/VPJT8J2MbxHg9jz3QIYdB+zeJ53imTt1hmb2DeBGd/9pNnLnEI3yo2a2lbtf0hDGgGkNz1w+/zhR+efMe8jneJZoDH6W+fkUcJe7/yb//wnwoQzfNkJzYLyZbQI85e6XZBy7AB8mBPdL6S9ULxzB7biGNBYu/X5l5m1f4DAz+y3wE3c/ryWOMm/M/PwUuJeaZzSzVwMnAq9i6Dstfje9ly5hpl83s3ID+Hfgve5+V4YpRvDnAH8CCmHuckKYe4mZ/Zsot82JuW9uZqsCU939xkzvTcDOwPXAt+mV5SovJhpHuoRpeH8AbmaHAR8BDgH+mec3Ar4KLAHsbWZvJtqRPwKbE0IKROe7C7Btl7SAB4G98//tgEnACsCOwOfo1YOriAHWL9z94Qy/L3Cgux+YYT4B/MrMPuDupxWJZF7/Wgg+ZjZ/WaBLAeT97n5c/v9pSoMAM7sbmNolrRJ/MLM3uPu/yyfN7ANE2zzFzN5SM1DaB3jW3bfPd3cpsIe7/yTvvwv4GPCj/L9fmVkX+CVwXinc8fn/v4FPET7tv0CUV6e+3Srazp0z7GOV68cB+wEHEGXss5nncrnZHPiNu7+7wzP9hP590zzA+sDlZvZldz+8Jr/TqVOemNkU4JvA0yn89cXdb894tgY+Abwc2NLd7zCzDwO3uPtfzOxGoi0YIgg3CDN13A2cSwyyFiT6wkeI97Ig0V6fAvwcOC4VTxfmff9nZku6+2Fmti5DBd1DiH7yTcAriPr7PXffLwWxgrPp7W1wMFH21wH+XgrzdqKM7Fy8ouJRS/8XA5f9y68i8/JnoDxAPwp4cz5bubx8M99D0c9tSvSVVeYBXg+cClxpZp9192PMbE7gW8AngYPN7LM19w7D3Q+vG4xk/hcs5b1f/x4Xo7/dnigvDtxMfM9O2ci/51P/fiHesVvMxJ5Dff/9LmJw9kjm6ZvAIYXwnOXnCnfvPks4I/syP1cH0ZB9KH8vCjxMdJSPAnvl+b8CVwDvJwrRJpVjErBBn/ivrRyT8kXfnseUPHdNhj8SuAhYmxDuXp7njwXuIjqQrxINZHF8nmigrsywDwFvbHnue4HV8/djRCHbhBgEPFnzjOVjWuajy3EbsGGm8xbgfqLx/R5wXp7vF+Y4QpBfrsPxVmJHwo2JwdYc+fsS4G2l574JeEP+fkM++8eBM4kGrzGdvO9KYJv8/UpC0D6SqFgTM66644IM8/eWMFMr32pcPt+pmdb/gBuIhr6471Gi7F6Yx0NEwz8FWKelLFxGCJ6vJTSyw555lOraNOClpf8fI8t3/r94hrkPWCPPfRCYQAxwziU6oe/n+34UuJEQ7n5GCCSPAj/Me/8J7JC/lyY23jkr072cKJ/HAkeUjh/m+7g7/28Kc1GX95ff4l017+NdwIP5+xLg49X3Qghgd3f9VkTdXSbDnggclL+XBSaX4jmIaH+eJAS8LYh26OWVPG5PaKO2z+9T1OvydxxyXxEuf3+bKIf7EgLc5vnbiY6xMa3StX0yv8uUzn0ww78N2IkYBKxZuv7lTOftpXNPAauV/l+J0BAW//crM1OBn5bCHUjM1hX/7w1cl7+b2pA1CeXDNKLtWLh0LEYMeu7KeE4AvlRTbp4BTuvyTDT0TZX3PoXobyaVj0q4k4DTCW100WcUfYHT0hdkHDvmvd8hyl5Rzj8KnJ2/tybayLXJGeRS+zE1/5b7oOr/U4kZgGOIQUe5Pr2B0P6R5WXV/L0HcFn+3gb4T/4+Dzigpl5uRPRbk0rnyteXJ5QlAHcCr+lTtx/L8vAWop3bMd/ry/P3LUSf8pXKu3i2yHulPX1Tzfd9U+ZznTymEQqSdUrHa4j6cmupbj1KyBVXZT42zmu3NBw3E3VmKlEObyHa7Cml53bgxJZ+oCgv38v8PkjUzYuJ9rQoc239SRHP1sB1wPtK7/d9wDX0ZLMn81udVzmeqEmrb5vXuT8cSeDn+qBbZXicFBr7xHETpYaoIdyu+WKXLZ1blhDACmG8X6W5g16Fv71S+G4kRqAblOJ4ZUteJhFTN9V01ic754Z730U0ntsTQuQDwI+JEeeH8vf9ee0pYOm87wf0hJSViOlMuoTp8G5vADaqOb8RoW0u/n+yeP/E6P64/L0K8EDHtMqN35eIKULyWzzUcN/aWaE+2BKmtkIRI/bP5PuaRnSIJxMj/lOA+Uph58trE4H1Wp5nclEWnuO61kUQnkoHYY7oSI+g1Dnk+e8SGhoIAawo45+hN/C6MtOYRgw6y43e2YQm7eL8vynMyl3eH9FwD7tOaJQezt+PA8vX1McVyA61Y1o3ElvSz0fUwU1L5er+SlgjOohTskxNJbSry1bCFQLq/9ETPLp2QP0GAY9SU7eraVWuHUoMdhYltGhPAG8tXf8UUd5XJASHh7MMrFIKcwelwR3RxjxW+r9fmXkGuKMU7nzga6X//0kKjoQQMXdDHWgSGKcA+2bYScBKfcrT412eiZa+CViPaDtvAHbL9zr9qIStU56sS2g2nyQEizsYPui5nZhqB7ia3kCjXM7XAu4tnX8238fT9ATzx2gXHK8nlAbT6xzDBdQn8/cT9PqCUwmzB4BlSmEaBd18J+vWXN8KuL1UZ+viWJteH/gv+gux1wC/IQYHRX7rBOF7qufy/KqZz7rBQ/mYTMohed/B9PqZ1/UrQ6XwLycG1VOIvqffYGQaof1v6wfels+5OzCudH0cMXByslyVvtUKfdqhfwFb1OT5jcC/8vfbKvl6HaGIqxOE+7Z5XY/ntLMd6dGxMlxbFPY+cbw3C+qLW9K6hbBhqZ5fm7ADbK00REe8UEs6nyI66nENYX4PfKOUzgpZYH8DnFIJ+zJCCJl+lK6dAexeE//uwB8ILXYxkvwPsH3+fhXwaP5uDVOKd0lgQ2JkXz6epKQNKoVfq/iO+X+54bqKsOuD6Dweb0snrz1KTwj6C/DJ/P07YErDO18rK9R3W8JMq5xbnxBQHia0EPvnd9iAmMp5hvoGcDVioHduxju+T5oXF8/WUq7mIDSROxCd/fSjSxi6C8Ktwlw+Vz/h8qFS/MuXyvvn8/eyWV6OBxZoeeYuYRrfHyXhvHL+O8AR+fsOenWgXO+3B24aQVofJTqPh4nyPa7UJvy14b6Fibr3LNGRnQ1sVbr+nixnMyII132nvwFP9MnL9LT6fI//Ee3kW2quH5hpPkgIaRcB72l47reSmtyWMnM3PQ1f0bGXZ5qeodeeDdGYV9LbhJhVnEaYr21SOjYCliyFnQh8uCaOm2hQEJSfiT59E1FPv5b5/i4wT4f636g8IWaz+s18/C1/P0FvZq0cx4r0+tudm44M0yQ4XpllYLWadN4A3JO/rwY+TfT10zXnxOBgYv5uFHQJQe8MwjSx6EeXz7i/k2HPBz5dimOF/H0UcFb+fpLSgK30PKuW3svHs0zsSE2bTww6fgXMWzo3LyGcfpmYkVieKHvrMXSmYgmyfyAGmmfkO/wgYV7zBGHTXlcuFsky9BTRH65XrfsMF4Sn0Jthe5ow3Sv+P5aoQ78FDmsoj060V8VAaVqmUx44TS2931fVxLFK6f0uV3wHoi9/Np99aUbQ5nU9OgecFQfdKsPmhMAxbHSe16/NF/MEMbK+pnyUwj1BmgBU7t+QnqbrfFoqTZ88nFE5HiGEpj9Wr5Uq2P2EkPRMFrobiVHlisSCjJ9mwaid5sp4Hq97L4RgOTkL9m30prXny+s70BuJdQmzZL6b8vRYOU/n57FUKQ9LEWYt55XO/Zwwc/lJ5n3hPL9NfsfGdDLsn4mp+A/ku1sxz7+T1AI0fKeX0dHcgDB7uY5oKH5LaEHG1bxnp8YUhhjtPkZoEpqmKzcnBKw3EhW6PF1bvJ9XEfa7U/LeZ/LdPE1PE9YYJs8tVspf7QieDsIc0chuX/PM29MThP9JaDVeT5TjwtxiI0ravVFoQ+re349Kx5H5rP8mprtPINqJR4EjM46DCe3D0hn2FYRwdAuh8S++R5dvtV6WxReX8vhWUtDu0/4cQ9TXRwlt6pFE/fhuKdwO9LTkXQXh71I/CJhuytUnTzsQ9XG7yvFuQgA5lhCKi6NsKnY78Iv8/QOaO9NPUurgG8rMH/P/lxNmEI8xdAbm1iyTO+f7+STDB4LTB41Ep2v98pVh9ibqztGEycQu+fvpunda90z075ueJOrnMC1ZQ7yNypOMs9/g9In8fRMpwDJUONqV0oCkQ14aBUdCI/mTSl4XyPJbnN8u3+VU4JxSHPvSE1AbBd2M8+/02re7iPbvAnr92Gvz3h9n3r5P9EuPk2ZrhKnWyQwXYk8GLi+dW4PoE6YxXBA+M/PxEL3+8EF6Jg5DZICGdzsx819WeG1H9M1nV/K3b8Z/NbB1JZ5+g5Er872f13LcTs0sbyn+A/P5dm46Muy/iL5/7tL9c+e5QsbYht5sxO8Zam5U7bumy2bVNq/rMaa8RpjZdsSIaQ7gL+7+5jy/L9FxvCWN4OcmKv3TDDemPqwpDXc/IOM8nWhIdyds/SBsc35EqOS3NbPXEtqYkwm7t2MJzd76hCboCjN7L8NXAa+df//S9szuvmvm52XE4oF1M54rCLOEiWb248zbPoQQ9iFCsNyTsJ0+NeO4FTja3b9VTsPMvkCYmqyU9ywLnOC5+t3MPkNM3x1r4a6lLcwpxMjzE/nutiIK34HEFObNxCjuVURjROb3RmBbzxXIuTL2oEzrKHf/U54/gPi2azel4+7nmtnqhL3ccsDhpe/7A0Jbv2PbN+iCmf2XENiPd/d7+4SZi/jmyxO24hfnpQ2JDn1uYsBzNDWL5dz9N7n6dvqpcvQRxMeb2Z+IwdVuxGBpbWKwdBTw5XwvjWGIcj25lMaLK/8b8KJMb13iG53r7o/ns76V0IRdZGaHZjoHV55573xfe+Ximt9lHn7q7h/KeL5JdM7lha/DcPd3mNkZHcLUvb9xpXPnN0fhm+eClBMIAbC8SPQkQgNU/S7UnHPv6NHBwu3QBwkBZEWig/yxu59bCrM50Wm+uHLvNGJRzkN56kJiWryod18F3kEIoXMQ7djd9L7TBsSA8xfu/vGGPE7rd60IUvp9a0M4d/eXt8RVpNmvzBxJvK8XEZ3ip9z9qNJ9FxJlam5COHqS+kWW7u4LNCy4vZ5oX4sy/x6ibVwl77+BEIJP6fg8+/W5tB3wB3fv6x3IzDZ094tL/69KCEhXEYO03xN900uI9Ri/JwSlT1fi+S6xKG4VM9ubKHMfJmzd30a0XYcC+7v7D/Oevp4a3P0WM7ucEKp3dfcn8555iUHRSkT5Oy+z8HJC+FqJaAPf4L3F8YsTZfFq73mp2YDQ7v87+4uzCNvu+Yh2bXFipuEt7j4579mcsLUdRyya+nPlHaxBLFYt97UHu/u1ef01+f7mJAYqEELvVML857JSXHMRGty7vOSpw8yOpztfJQZ7dZ5nXkQMeIbUPwtPNScQfeJuxILOZ4mB88+9ItiZ2cmEgm+3lKHWJATX04Gb3X23pgya2ZPEzOudfa4vDfzX3VtdxOU3PTOf9Tqibq5BtLPvIWYS9iLKxwfc/cLK/dMIRV3hwWtroi48kf/PTSijOrW/wNgShKFTZdi56X53/2nHdBYjtKxbEQUc4sOcTYxcyp4raiuNmR1CaLDPY/gq4OlCboe8LEtoxYZ9jLz2D8L+5m8W7k3WcfebzOx9hB3RmzLsB4nG58/0VqpuSGisduv6bjrk916iQbg887Oeu/8nhaOvuPuGZmZEgS5W1E8A/lz3jDOTTsO98xCjwmdn/EmHxLc8oWGuNkhG2NDenv/PSwzGPkRPuJtCCNG7AOu7+3UN6WzSlA93v8DMHgQ2cffrzOzRjPPGvPf7Hu57GsPQMmAsJwn8yktuAzOfcxH2hT+zcLX2OUJIWCKDTCQWVxzm7lPznvGEacPDpXiWJxqwgyvpzkmYkCwD/NbdP1TTudSFaX1/3R4bLBzAFx3qle7+37b4q2mZ2ceJgdwKhE3nzWa2DzHYPiXTeYYQJH5CCHzD3HWlEHC6u29WOT+N/l4RKJ0/vz27vnm3J3vuSOH3H97zgtGvzDxNCA73u/vdlTjWIlxCPmgVt0590rySEPxON7NXEsLPTwi7xIvc/WOj+pD98/Fios16snTu1cDXCdOY8ZXwTcqTrQiXbrcxdNCzPOGu648Zx0GE8mKeDPM0cKi7fyWvr0u7S7JWwTHbxfdRElCJwdf0Zx3Be2oUdEcDiw0ydmJo/3VSIWy33Dsu77u9GEQ1hN2RWIg+hVCSlPvH1kGjmU0glEBHEO16Pzeo89BhMNKQTmM9SrntbmKw/WqGepW4qkYwn494v68k3u8NxMzRrYTwfwT9vVHsTwjxjXSVv2AMCsIF+WLvrwoeI7h/c2Jqxgn3a+f3CfcKeoX9Bnf/zwjSuBf4hKdGtk+Yv9LgJzA1UFNp8I9KaDRWdffbzewOwvbrkuwQrnf3+Ur3bEBMW69CrwIfUdJ2vIjQDlZHn+7pKqktTAqla7r7rRZa6J3c/e8WTsuvd/cR7bJj/f2wnj+a6cwMbd+oppOaj9CgGGFXOjk1J59y93/MZF4eIgYFN5vZTcBH3P2vFn45r3X3F3UJ8xw99wIA7j5pZp6xFN9hxEzE/jMTZhTyMczfdr8BbDE4IjR9exNC/reI6b2bLdyM7e7ub8jwr3f3v81gvpbrEs7db5uR+Gc15fJm4ULpNe7e2OlZuEvyunD5fm5vGoBne3YGodT4CPBad39btqW/cfelZ/yJhqVV50/3tcTU/nqE8PgDYpr7SGIG4gxiQPnPUjyNypPsK5YmbFnLwtzR7n5HJfyLiL5yHDChLLyZ2XnAhd5zSbZWluGNgJPdfblSHDMkOJbSeif09bH+no5xbEB/n/2fMrN3A8+4++mV+7YB5mzqy7uS9b+T/2Uz+x9hS/yVQmFQub5OS3KXl37XlfHyTGLdYGRhuvntP5QQQPsJ9vMTmu2bCSG4PFN2E6Gwa/U7b8Nn9GrdHlb7nZllrPkRnpOYKv8YYfPyCsJv78HEArYjM9zcRAMxXdAFfunhQH0pYiS8LjFCAVgyhZB3VrUHHhrGR6kRulNT8HOiQtf5Sx1HTE01sSnNfgKBVv+o/yMK1+3EyGkHM7uU6GgfKt+QAm+tOYCFE+5fEuYGVZzwy9sahrCvfBUxersK2CMF9E+QU7JtDVKGeTXNflj/1SGdhRnlDVT60PaNqsybx1UlbeqXgcPN7MuEvWChrV6TEE4fbGv4PDYRuY7QhN5M+C3dJwWI3en5+2wMk++tjsd8qBa933MvS9ij9QKWnPvn/38gprtaR9vu/o4+l35E2P3t33D73wj7wf07dByH9cmPE9/xJnJTBm/wt5333EJowKtakoXz2n8JgfcPZvb10vUrCO1awQFm1jhY7vcws0vA7SBw1JmMFdf7fWsIW/QViHe6fPXeUvqFWdX7CBdimNnDhPnKVzw3vOn4fpzwDf3VzPNpef7PZB+ZQmDfctylncnB1J+J8rUgPX+6xxJT/HsSdvV7En3DtYTHoVtqoqstezlAvYVYbHUnLZsxZd6fYKhAVWZdYuq9ysTMczmOY+oisJiprE2aXp3bifBOchGhpRwmFGZcfcsd0T9+O+OrztAWv/cn7NWrvBr4kLWbAOHuv2257tbH/3INiwPH1gnBSZ0f7PJzbUZHUvt+XB4AmFld2Sqn8zLC1OB2er6Y65gj8ziRGPxPyP9XIwaYfzSzNd391vJNFju2rpz3XUTU/Ta+Y2ab+Ahm99oYU4Iw4bz87USlOKl0/lLCPvZIC9uoPxG2X9fm9d2JzmQrYhppKrFo7BaYPsV5IqFuf1ee6yJ0/5Ge4+rzCaH4t6UR8zGZ1/2rD1LpkNdMDV3BeGBLYlvCI4gC900ze6ISZn1CADyVEJbOJzRLv898jSMazXK6hT3Xy4Gv+tCdd75HeI/4UnVAUKJrmJfl7wOJ7/E+YhS8s5l9jvYGCeL93UF8v2GmJcTUZN908vxP6O+kfqbJ71Pku+kbFeHnJxqa7fOe8iYshZuZcyr5HEcIjOPptgHAQYSNHIRw/Xti2usBYmU6HcI8QP27mmZmtxEDtYcyzAUWzvrLz70cYa9XlLkzGLoz4s2EUDyVqL8zyis7hPktvamytvf3I8IH+USGrg14GWGP+jpCY3JlXtuamB3ZkBhgfote59M2OFqOGJBUeZbeJh0QNp5tg+VGso3blqFTkqd77uyUYc7rk9+yQPJTb9mxsa1+W4vJWAu/IcrbxLzv8hzAlRlHmM89Q/QTRae7KiG0bW5mG3v33R8vI77BtsT7/kie/z7R3kC0tzPLd4m6/zFCAC5YjLBR/oGZnUq8s994Za1HhdaBufV2R3w5YRo3ZHdE67DrKTEbuVBNOq+iJIRbw8YchK/vuajfYInS+V3d/ed9H7i9X3knMeP2g35xZP5urDn/VeKdtmmEiza4jb2BQ8zsk4SZZ786cBZhsnJzn+tVwXBOor/bF/hiV2HQwgTmDnc/unLpYGJR+1cq4V9O9CHvBn7t7ju0xP9dot3cpPKs/zaz0wjZ5U8Wu1I+ZmEG9BvCfHIq8U4L7yOPtKS1NHBeatMLc7KJTfe04iNYWfdcH4TmcxMfvrLxlfR8/J1LGHgvULpvAaIjPpt0Vl0T93qU3H8RAvMNxOrEspu07YFLK/e+jpimuj/D/pLwGvBDQoNxEbEI6YjS4bT7CbyBjv5RK/lZltAGr1E5vy7RwF5JdBLFM+1PdBiTSa8KDd+gNUzNPS8iKsGi+f8dpBuzDml19plbTSfPTaL/BipzEpsjNPpxbkmz+B6dvhH9N2F5G9GAb1JzvIdeuV+u6WjI58LQuvJ9epg++diEqA8HEh3gafnchxCD1OL4IiEgzJVxDXPun+ffSJgbdXnPR1SO7xOd0mTC7rkpzBOlMI3vj95WytX0DyNsIyGmCovVy8N8aZfSn0rDBh/ETNU7a9qzTxMC+zo0O9X/KjHoa/NDvhc9d2oTiUVEhaeQz1TK5iNEu/OzPG4g2rDjiY7oWVq8F9BSvwmN3jDXXR3LgRFeNT6d72X/fL7ycX4+4xI19y+Z7/2QEaS5er6vScB+pfM/IOxY2+7v1M7Q34XVVIa6lZxMjReGSh1oK3tvJgTi07IMFWntRcwyQAzYHyZnUxhax/fLMF1ckjVuzEEMJi8mPMTMkcdGxNqXtxAzV88QA7eZKXePUvKY0ifM3dS7ensz6Tt5NA76+1+eRGlzFEIJdDshj7yXimeWhvjfTG4i1JKP9QgF0u3U9JNEO3Nb6f9FqHG/1iGdq8m2rs/1d1Ly/0v0KTdn+pZlYAJRj15Uuu8tDPXesQDRbq2e5e2+ouwQStS+bmob8z9aH36UCs+T1DuyX430K0t0esOckhPG+ZPpLwivw1BBuFXoroljDkKguTIL+HkNx0V08BOY8R5Pg39U+jiFJ0bZZb+x59G888451Pj7rMTZJcxXy4W1dH7evNbaIGX4Nj+sjenk7zYn9ffRQdgmRuVfIhqBIQJXl29UiqffJiwrUtosYCbryXGE+59FK+fno7cpyXHA/DX3Tg/TksauxBT+zrT4NaXGuX/+XoHSDmp5bh6iEVutHG9N/fkL4a3lI8AcXcN0eK4HCY31kQwdUL2C3s5y99Jrb4b50qbj4Cjf4V2EoPB4/t2PaKfeSzen+pOayi/hIWAqob1ZuHR+EcLV2xR6PpG7DAJOJjrN71JTDzJMY/0mFAa17i071LdTS9/7eOrL8M00tFGEIH3zCOvUY9VnyrI6Z+Xc5oR2+BOkT+0839rO0N+F1VRKQhgVd1CVOLqWvUto2R2RbrueLkC7S7KradiYgxhs1QlhG5ID5SwHk2moxx3K3dHFMzeEOYqYpXlF6dwr89yPmu7tWH6L/mLnpqMUT129L46+LsDyGxduXt9ECJbfKL37VxDC4VRCEH6q7t0RGvKnaHe/9g9gwdL/32RoezOJ3IWxT35XZKggfB0Vn+KE0Ds9TCnevj6CiUHouwnN+hRioPMNWtqfYfkbSeDn+iC0JIVvx3KFOgC4IH8/RI0PTkJr+yAxAv47Q7f/XJawI/xt6Vyr0F2JfxnCPOOaLFwXzML3MpUap/BEZ1cuFJNKz1F+puWzsG9HjLo+TFTksgaq8KHYJUxjfujQIGX4zWnww9rluWnZQIVoIBq1Q4THg2mE0HM+QzuXvhsf9Imry85FfTcIGUF5qOu4FyU3EWl4d9PDtKSxIsO3dV2w+o1K5a5xZ0SiwTqEni/safn721SEjee4Lj1ETIFXG9ht6fk8/lnmsa8v7fz/eNo3+NidGIQWndsdxDQ1dHCq31Z+iZXWxzdcP4HUapKDgJowr8hrRT2Y2lQPaKnfhFC+/wzWt3JneTOwSM39T5G7X/aJf2lKOwB2LBePETMibyME6WrdWoow8Zma3/CO/H0JUZ+7tDP9/Ok6oZm9Jo8pxDqMa6jxgV8qe8MGCaXrj9OyOyIddj0txbd5fre9qQjPtGzMQckHdOW+NeltoLBSPve9RF/91/LRsdztSwzCfkH01Z8tHxlmfmIAMaX0HacQgl55lnlrwkTwBno7a36YMCMZtf6iw3uv9omLEIqEU+kpKqYR7dS0fH87EALt8fQUFP+hsjthnt+VGMTdTbRTH6RmZpHh/sqr7edUmgX3xYlyvlj+fz8VBRbR7lUF4cdoEIRr6uiXibastY8rH2PNRvgA4EQzW4boBN5tZq8ibPremmHOBH5sZrvTcwuzETESPoPQIp5O2GUWdkRLEY3Jp0ppXU8IILdW8vAeYooQM1uIGG3sSGhebiQq2Yme7rIy3KJEpb/Kh7uZal0o4GGvtRkx3bwsw+0Fuy5YarPnKuyf6hY1OPHOu4Tpl59XE4LGHYTN9sbEex/iwszdD8+fhdubqs1sEX9bOhAFf3ngvrRtrbpL+zuwo5m9ifiuQ1Yxeyzc25Ma2zILv7U7lX73xXsLgC4j/GZ+t7iUfz8K/Cttzd/Q5/kabc9ygZuVjpeUFr2NJ+rIfblgxoCFamx730o0lm28hFgcthzRAW3GUF+/Rd7HE75rd6G3MMct3F7tQ8+X9sFE+d6D+CYQ9pjfJOwFP5fPOA+9jUn+5yUvDaX30BqmgZ8SdmVzARtkW7N+5vWEDHMRMbCeAOztvZXvSxAapXjIBvc8Fv64P0JMQ/8424hxXvK+4b2FXOPq4sh45qOh/BIDqg81PO8J+bzQW7zy30qYVfPansQOZ59y900b4mys38SA6f2Z57rrfW05zewB2hfLPUIIn7U+TQlB+JGG/FfTXICee6lpvdP2G2LQ8hg9c4R+a0/uo72d+Sxh23hjpvcrohw/QMzgFOsPftMnn9U26BexlrOWh4l+79bK+XXovbdvA581s495i3cmdy+E0jruJgZT1YWJbyBmXh8kFgl/wHPRuYXrt0OJgQSEmdM4oi0Z5mM9aSt3HyYGAK/NY8gjEH7mHwM2zu+0NlHuryD2LfDM245Em3csMQAo2r3xxEBgVer7i4XLf5tw94fawiR1azmMeBfvzXx+yd2/ZeHn+mTCh/067v6/0j0/IhaZzUXvO25BzIxNI2aFvk/IJAs1lKtyHoaf7P/sxflinY3TM2MqWLQt0b6ZiTr8dkKhsRA9N37d7s9vP2Ywsy2JDnVdei4+DnT3c/L6gkRn9naG+v89A9jFc4FEFvTprlx8uFPttxON2LeJkeQBGf79hO/DP5vZ00RB/BUh/F5RiWPYwigP1zJHE1tH7p+rjdsWCtxOLNY5jegkTicaljWJBm0hQgivXbDk6VrGzI7JeN6d+V4z83U6Ufi/2/fFEx2zNbtjuj6fYT56e36X8zMPUTHf0pxM+Ea0/j5Z/5hxz9OUjrt/wvo7qS/YtCUvm1t4DXm1lxYWZf6OJxq8x8zsBOob5yKiXfOepk1Y/pH577tBSNODWM9nLPQW2A3JRp5vqtRO2P8d1JDO3IRWdDzRgC1IdFp1vrIvsBbn/u7+PzO7h3Chc1YlrbcS72hZYkrrk0R9KVwQfR/Y192fzQWujWEanrtIbzzRUXyjdPoeYgHooe4+1cI11TTv4zy+FFc/waAY5L4Z2Kb6zHnvdsCZ+VzbNSRzAFGX+6WzAeHb9Y4+eVwGuNHDpd53CI3Pt4jy5/QGAT8jFpp9izA76LtIz9pXmjd5anCibR9W3zLuHxFarolEmbiT4R4EXkr0XfNRg8VmSZPd/f0N+SiHP55odz9ItD0Qio+jCTvM3SxcrG1a0wesRwz2mhYYuqfnD5sJf7o2sk0a7iMGmu8hBnTrEQO5E4gZhAPN7MwM82iGqSos3pHptnkI2ZuGjTkIRcfviOn8snLqP+QGSxYbNnzP3b/Q8PyN5c47btTShpldDXzT3U+2oS7j1spnmYf6/qLcPveNPvM6Pu8xYvFk1df4F4gZkarSYhqhTb3J3adk/tb02NhkHNEevtFrFtFZbF70aXqKtmfyWYo81+W9rJSa7ke4/F5Kz24M75PK8RhD/Zn/wt2PLeXvK0RfuHhDOosTpj3F+9uMaLfeSZTfYtblMkbAmBOEu2JmKzNU0G1zU1IXR5vQ/WZiE4jaj2uxw9FaRCH+O1EgbzaztwEHuftaFqtp9yOclpdXqR9GGMjfRWi2r3L3jSoV7xKisG6c4cs+/J4hRvu/cfdnMj8L0GHnnRnFYjMTI4T/TzNUG/0McKuXfF2O9XRK6R1NTD0eOUrxrUHNJiyEBnyGNgjJeDch3stfiQZvV0JggHgvtxGdTRFme4a613uGWBhxd4OG+yWExmMK0UleRWxF3ncTkMxbX+f+ef1JYG13v7Fy36sIm/ujCAHhCwzXGP/C3T9nZoe3hWnKYyXdx4h6davX+DxOrdNdxMByyAyN505HWf+bPFBsTyzw3NLd/1KOw0oO6q3ZZdP0TrPPc0yPp8/16R1HaRDwKXreWKYPAojFVncQq7AbBwEzQ1N9S8HgLUQ5PpzoGB+rBFuM0F5fS7SL/yY669UIresqhJ3+DdbBHaHF5jPbesWXs8XmHqe5+yINgvA6xLbxL+n29LMGa94dcZcc8DUK1u6+q7V4aigJ+AfRvDGHEQPD8gYK55a0sLcQbeOEmXx0Mr4XZ/4mm9lnie3Tn8rfTc98eGosV0nFULk/XpGwbf0pNeW3QbFTl84Fec+n6eBrvOE5h9T/quBYE34+ejNAE4j2ugt/zXSKjcamC+D5/7bETMbmTZHUCeilvL2cKGf705N1DiLagcIrUOGveH9iFnIFQr75CXCKhxu/EfO8FYTLjLSgj2K6dxIrJS+rqTBXufv8ZnYD0fBcUrl3Q2JkvoqZPQU87O5LWEwNbu7u16SQcD6hsfmVd5wCtoadd8xsTUJIK3wwTyAarGu7hskK/4+OGrjGjVHy+icY6hP6KHe/d4TpbE7DBirWbL6yLyFwn0MfUw4zOw7Y02NqrXzvfITHgqbp6SLsJEZhgxALrf11NDd4yxHucvq9936d4CRi9uFEd59kZtcS5fdfDflZlnbn/hcT9rWfqFw/ipiiXIEGjXHWjUatsrsvQUeaOgyLDV5up6ddH2LCUtJGHE6YO3y6cn/hq/hyYkryIULbWJ0ub9IiVvNUW36zI9yNik/nEgsS2zUPEaatZuOTUj24gtDwD2lvRqvt7FLfMtz0GZmaONYnBspFnYeegLUKQwcZxTes4jlAeIIYlA4Rwiy2b7/E3eezcAG1GLHD5x15fVnCVO5+d98uz/VtZ/J6nZuxq4iZr36a/yKz72i6Xkf2Ra+mtDviCO+/g9hJtcklWRG278YcHe79IGFStkuX+8qCbuX8J4j+cqk8dSehFHqlh5/2Vq2yxQZEH/PYqr7cr+9KeN34JR3KbxfM7D7CE8YplbRWI3yZL2L9N7iCMGUs1/+fE333EE2yt/g+7pDPaczktsZmNn9dXa6EuZVefV6KngecMssTz/czQvtb5w5vRIwpQdj6Ty0YYf96E2H7dXXl+s6E+cJThMlEP9zbtyy8hvAm8XAKAU0vaEViEcDNlUK8NnC+uy+YmrD1y4JmprMm0cjOa2HLvKDH9OXVRMNzUmqlziq0DW3CXhtm9g7C5+rf6GnUXpfHdu5+ZpcwGVfTpibDfDTne6lujLIxMZV2L70toTciKvyW7v7PpnQyjqWo2UCFEELeSWiT2sxXujSOU6nfYW1RorK+tCGOgnOJKfw/mdnviFHvvoQj+W3cfeUOcRTpPp7PtSSVAUQpTN9BxgjS2ZzQwH7c+8y6NLybRcjd51K7dhbxjf6Z+dko87818W76aoyznjRqlb3DPvele5oE4VOIRaNbEWWr1oTFQpO4YVW4sNit8p/07PXrbN29qdMoxdVofkVoR1px9752yKW0inqwHD3vAAULA0t6aNiOqLn9bYRg8AzRUTWxRnNWh7bR1mATbrEpT1Fv/uPuV1lpNzlr2XnPQ+t3LjEA/ICnRikHuD8jFlC9ycLE5PTMe3XtyTaEINLWzpRtT/egp/37B/HOz2nJa1+b9JkhNXFFG3GDD/U9XWs2Vrn/ZYS3hzsr55cGnvVQaixM1KNha2A8zDSupWcTfjvDhcs1M846Qfdgdz/SzL5EuHY8lKEzRp8FvuHNfpnL+W4z9WiaeWqVMSppOfB6D4VIWYZ4BTEb9w6aN7hqMuYt2h0nFv41sQdRdl+Z4f9DzDbfnfnsZJZTV0bN7HXEouHt3f3FXeLJ+2rbaAtTsjM8t2EfDcbaYrlPEgXtNHpG9BsQhfIgYkT+KcLW6a7SfVeQjaG7r9AvcjObZsOdsw8LRozMxxOq/iZBeDP6L4z6R/6+lPaFAv8mVoICnAIcYWHjvAVwbj9hz2K3vD8SjXgXdiFMNobY1ZrZgYSZxpn5tzGMtW9qsiMtG6Pk/4cSlXwPT82lhZ3T0cBhFg7Z+6bj7jfQbRHLkoSGvGgcIexYi9XtTWVmYWtffDaesNtqomiwiinpA6nfIKSVHEDMRTTQF+XpnYiFL8UAom6QMSRMKb5FCI2sE6YCxTQUROc/N3Cjhc38kMbHY0etfosapzv3d/cLs3H/BD2Tpl8TMzl35wDwU3m9zJ70NixpDWMt2x57b5HrifSvN5sQ3+TmfK773f2ifP6vEUI7+QxNi89WyON0wlypFuvj7N7M9iA646fpU367CLhdKepBdkCb+PDNOIpFQ3WC7Lz0TGqabIQb2+gyFgsOv0nFJtzMptuEu/uV9DY/KeIvp38MsQjufOAyr9/B6zNEXbkrFSFOmLxNJjY+gpiaXZ9o84etPbEwk2lsZ4gp8N09bE8/XArzMeCcmRV0LWatOuHuH7KYFfgJIQAVM0dmQxcJ/pIQYJvMxn5O9Fs/rpzfEnivmX2VEMSeJvrwu4g+/GnCvO9A2jeyoEHQ/VY+yx7EVvK/LN32FzP7L7EmoJMg7O7fNrOXEPW8WERZmHr8kDAhGi2mEX3/3yvn30LMxH6P9g2uarGha1yaBNlXEosa56bXJi4AfNvMPu3uPxpp2TSzlxJ92m7EIOKvhMJnpsiB7Q4zq+Eeho+iq4+ZPYgOY7ea87uRzraJwn59QxwfpL/P3e8TlX57Yg/2B4jK+6E8fkwINK2uvzLO1xIaxx8TGuvvEx/8cXquxlYmNHGFTe8t+fs60tcdub1k/h5HCItnEBV+QUIg/ycl35LE1No/iMb6lg7HzYRQMsy/XuaxcKnTJcy5NG9q0slHc76zYe57iI7mybZ0vOfGpe8GKsykX1+G+nqtO6bk99+ky1GJe9gGIaXzryVWwG5HxcF6loVjKDkPz3JzDGFK0jXMK4lGvvo8f6bnDm3nhuMcujn3b91wgFhh/jihifgpYd94Y36z140gTCdXgy3ffFKm83KizhZxrwA8UQr3HUJA+jyxKHOT/P0AsUIdYuD2t5b0bqe/s/spzKRfalp8xdaEn57O7DwI28CJWdZWzONcQhN+aKW8DTsyjoMIIePpfK6zCWFqI4b6cp83v9Vhme6HSUf+xED3WWDVhry2tjO0uBkbhfd1ZuV4lFhsfWEeDxEzqmdk+OOz/mxC1NE5sxzfS9TXz9LNJdkj1Lfjr8g0/5bfxIrnJmZY/grsOILnu50wTame35EYfLX2Xfn/W/N9PJDPdgE1fqmJdng9YgBU655zFL7Zk1med6Te1/hkRrjB1QjT34poY75DzPgU55ckhPBngTd3jKuw7z8tv8XfM+51ZzBvw9ohYoDqVDYoqTtGktZY0whvQdjgVLmAqEgQnfcwjYLFatzPE4XoT1T2YCeMrD/u7v+X4c8gtigsj2KPM7NLCQHkSItV4dt5Zcu/HH3+zsPjwGuJqZL/Zf6vADbyNIVw9/9a2Jr1XSjg7icWcXtoRg+upPcmYqHGLaVwN5vZpwi3L101LLcTWuXqFPe69GyK7usQZmOi0Z+uUfOwJ92XWPg3jnqtULGrUMGjxLes2visQDSubek0UWg4FqJnaF9mfkq2R6mtfBfDp+7+RCwWaVx81pIX0lzkDjPbwt2vz2d5gspqczN7I81TYeMJe7FdvGT/6+7TLGxWC+1YYxgzW4zoDB4hyu8EehrOjwIXmtnq7v7ThmfahdAOGmGX+Uzp8jP5bId6eEYoNM61eIvGuGsYOminO1CeobkK2MPCVvITDJ2JKmzxPsPQxWeHEIIaRD24N2dvnBqbfMKspm5G4UHie7eW3yo5i7QroURYlm7bwhb1YC7ga6kBn453sIPvSkN9K6fzfio24akl/hTRSf+7IYmibd0375uXaE82JQShA4jyUNhKP8lwjWaRn6kWrhmrbi3LdGln+rkZuyCyaNdUzj9KtI3fKdqMJtx9ulmgmX2RELJ29bSjTXOPn9CbXXsHwxcJnp+zpuvRM/dqdElGtOlz12Rpnjy/JqHg8ox77uy/9iFmDH+R7RHeW4y1BiEIXu89De9L6S1KLXMpIVj/hygzB1auv5/sY1ITfyQh2Bdt2+uB0yzcyE3Xqmf7fHlNel3LbxemEGX5G4Tg/XOijfmUu//KzHajp7Gty0e/NVGPEt5i/p7hNiJ2zK22GZ8n2qMh3jqyPd3TwhxtHzPboeU51iHMlyYSs22f9fBk8SxRDkcTZxS0y0NjfI5GGjM4ArgN+FzN+c+R2wBS2YWnFGYReo76F6u5/mrSYX7+/zj1o8eV6O3YMo167dJLCdunmXnWZUdw9NN6rkNpt7wOaX6FEHz2Jab4NiX88D5CTDV2DfMQzZuatG6Mkv9/l97OWysQUyg7EdqVw9vSyd+n0bCBCjEl+ulSXlbI30cR9tcQHeNThBb1GUKLeQ+hTSm0J8vRZ/tGhjs973fcRYNWKeO6ntB0LtkQ5h5gq5rzWwMTu4QhzFyuoX7nvmXy2tfaninDH0/7xhKHMIJtbxviOZKKBj3PF5rAqYSweQw12umOaexIbhVL1LH7Mt4ngHf3uWeB6jsgBI0phNb9a3mcR2hZ3l4K9x/qnd3vkvloLL+l8OMJu/g/ZBr/Iqbja3cpq0mvqAdTa+rBzTRrYG8uHWe0HK31LfPTOGM0wnKzOCFY/Sjf95OEtwcIrfEeNffsAXwtf+9MDIqHlb28fn7bd8pvcQMhkD9GaGJ3JrR+v6eyxTGhpbuA0GYPawdbnnciNW0NMdC9J38/0SfM6lR2hGxJ6y/E2oPq+R/le7mf3gzTjWS7RAyei772PGLQA+FP9mGiLXwU2CvPX0PuKFpJZz/CbGo7ejNaBxDmKH8m6sK2Gfa/1GzTTAhW/8nf8xDa73OIgfA1laNT+e347sr946JU5A1aNrii/wzww/R2H1yYPjMi+X5rt/MufaNHGT7b8Ex+9+L/aUS9Gl+5v3Empeu7KZ1bi2ifOu0k2jmt0YxspjMT5glTiUU1+2cBLxr1XTLMNMKlTfXem7MSFB1hueBeTwi+p5TC3wp8oSaeLxAj93UyrTdWCt5rCMHw1lKl+RChATo0f89biXMDhm/H6LRPuxdHk7B3DZXpqobDCO3VnfR2urqTsLEsFk52CfPTfMcbE5VpPCGcXk8IRW8nKs++RGO7T54vfBwWzzAXMRp+uvSsTxEdwFxt6WQcyxCax2eJgdSt9ISApelmvvIvYnYAelN38xDaxs+W8tvPZKHLdyze5c9p3ka0dSqMlgFElzCEYPj+PvFPJUyHLm94tml0NDXIOI/MMnEVoZUaNo3dMZ5J1G8Veh69DRGmEJ1Uce5scuvZEaRT7qBqTVg6xHENueV55fyBwNWl//ciBn270zMB+AgxqPxhh/L7SmKgcS/RDn6dGeiAyHrAUNOQoh78l6E7aFWPiXncTdT1pqNrfbuYcMFXzedRwD87PtMP6Q1iziP6lU0pmc/RbJpSKGCuzXfyNKGdqwpHre1MxnNQ5qVoD54khe2GZziIke9w+Rg1JjFEfzYpf59LmN29qHR9vjx3bv7/Vdq3ud8wn+kf9AZ8F+W5wq/6jhn2R0S7snOm/888/2BRXokByGX5ext6AmoXQXddQiP5L6JfOJFY7Ffk+2n6K8Cezt/HEYLkMfTkkPLRqfyOpJ0h6vzb8ijvpDat4Whsf+mZTx6V3+tNRNtQNhWaQiw27BfH8tQMiqgIqYR8cR3RBnyneOc8N4KwU6OgnJlj1CIatQzFSOWkLMRX5u8N86VMore9bNkeZHIWjEvz7yGVgvtFYlHSXKV0PphxnZ2FfX9ixD+FoZ1/XQGcTAi86xAN/8MMtcOaSK+T+hz12zFelse6mbc7CMFx8zz2JW2iaBb2bqejjXDlPc9PwxadTWEIu+XT87mezaMQ2BfMMFsS2ozHiQbx7/SxNSIEjTWIKbQXjSSdUtg3EaP6TzF8C9A1CKH6OkKwPpHSlp+Zx0LoeYjetpRrEKvPITqQ+/uUh6l0sxG+iCiv9xKj6SGaskznHGrs1SrP0ziA6BKGKLO1gmHmdZUM0/hMpXs2IzqOP1G/PWqTENW5k6fFfpUQtEbNxpXQJDbNBBxF1O1HGG6n1slmMc99k97201Pz97fayi8xGH6YtFMvxTcjgnAh/D6WzzOsHozSO22tb/l/q014h7SKOno4Md1ft33sU3XlJd9FsS6iKgwNOTp8pzkI+8lFGKHtKbEI8f4RvuMTiD5lB0KYWT5/3wackGFWJwbGDxNt9fn5+05y+1s62twTAsovCCVF8exr5bX1gM3y92L0FnhfXno/TwDL5u9TCb/qEH3fk6V0GgXdDu/lv4RrtOr5j9MTuB+iwa6+a/ntmJ9z830UA/hCmXd6vuPlmo4O8b+B8LRSPb8S0VY6sXlQv/s/SnjkqZ6vbWMJ+e3Y/L7X5/NsNoL3Ue4T/0UoQsvnzmcQBOGGF7QzMVU4jRB2di4d7yPscotw83SMc4OsvIXQ/Ys8txzRcEzLSlwufEuQ6v+syKcA85XinI9w5XZ5/n8HNVMxlXxcALyr5vy7KC20oUHYm03fZCVC+/sOajr850s6lKYRs/Jum79fTW+hS6vJQod0jm86MkzjVFglvtoBRJcw2UAt3pDXxem4X3vWy6cI2+ansvxfSQhTPxjlb9Uq5FbDENq8qgav9sjwcxJ24YXGpOj0Dqa0kJYYkN1KzPbswvDFhLcD763J3w6kprFyfj5CC9l5cQ49G8PVK+eHCcLEwGTBmjgWyGut9WCE32peQthandIs2UjSIRbtHERoKX9LaLQ610Gi7XiK2ODkDkLQO5PQYBXKiibTlJtGsew+BSw/A/etAjwwA+/+SHqmLlOJQfGRDG0H+i4SzOv9TA3fSAfhnFgvsiqlPrJPuKsJ37zLEELUBnl+PdLcawTPviSxRmJY20kIds8QA8dd8xsfm+/mIxnmTpoX9nbpL7oOIE4jBk4b01tDszHRHv12FMrc8oTg/lJil8GjCPOcJwih8qx832+vufcdhKD/fzXX2hQS82VZ+meWocuBfUrXt6W3YPEBYkD/TtpnkwrhfViZnJljrC2Wm066GCsboZ/n4Zj/Fho2WfBc3GM9n7sQbm7+WhP2EmLquB/jWrK5GmELO92pt4efzQPpGdkvQBS2Jtanfm/sa4B1LZyN/8rDf2nhugmLfcN3cPef9YvYuvlFXpnQGK/WEAYIf47pDudQD7+y0xfVFQsW3f3A/H/YN8hFijt5LHo7o186yeV90tmbEBS+2mexwLz0DPRPaErAY8/3SwiTiwnECPQwi+0030nP9djywDu828K4fr6Pu7igKdwIHVOXXWC8Dd3cY/qiKytt7tEWBhq3w5wevOV5isVUnyMGe8em660veiyG+QFDd0N8zrHwOTsX8FMLH7zjCC1UwVEdotmPbu7/tgDe5JXNckp5WRb4kZmtRExROlHOPkfMWg0h25HLzGxhz00FLPyvNrEe6ZnCwhn9z4gBSR2bUr/gax5iwdAfaK8HxbO9lz7b7hJbvB9MCB1lt2fHEO+vS30Dpi/a2bfh+QvXZV9192EbUnhs3/ssMWV9s5mtQm8nr3GEudWPgO9ke1r0E1sQWvqDq3GW0l0424/W75ThriYE81ubwtawPVHnOuOx+O/jZvZ5YtrdCKF+ck24YYsEsx57Hjdb+LstGE9uc1+5Z0nqy8PFRNtR64c8OYAot4cRC8CLOrUlFfd4Dek4oSEuFtJWr4139x9ZbGKxF6F0gBAM3+Pup+f/3ybcTH7M6zck6lJ+q+kXzM3QRcVbAlv4UHeWixMa6rOteft1vN2N2JrELMA9xIzmMYTpycUePv+NeO+nm9l/iHfhxPdamRiA/qAljbp8TSYGGMdabA7yYWLwebCZ7UUsDvwZvf65sAT4irsfOjzGHhY7zx6RC/ma8vChrvkdaxtqvISwGXwPNQ22D98dqSosQ1TS39JzfA4xQryWcOh8cyWO2krlsfVmk3/PpQh7ns97aee2vP5G4DCPLZaPpmX7Xovd58724TtUfZeoKK+gZcOC0rm3Ep1NIbRMJjYBOM3M9qdeyN2EGFx8uSEMAO5+gLVsoEA09v2+wU3Eoog234YQ5it16dwGLO2xUcMtNfctT2jjpubvuucxejtLvZwQrK+x2MXnMGJU/h+iA73dzM4BvuuVXc2GRVrvY3kNwj628H3cdP9yhIZga0KDNQSPDQD6vf9FiYUwc7SFIcr7ZPp/a6OnTW58HouduVb12DHvASo7I7r7y1JA3ZM+wpOnw/w2rH0L0eMITc/JxDT6kOdz9wM6pPE/ooxeYEOd3L+S2ARnwQx3E7ERSq2Qkp3Mp4lOd8k8fTchBB/hpcbXzDYjZraWJer83wmt7mbUD1iml9+8fx5CAN2NKLvjiPUOx9LzsnM54b3moVI84zO9DxMmWY31INM6JJ/rPIZvu0v+/2aiHSo6+I0IwfLPhFa3NZ2uWOzYuHZdmbDwS/4Y0ZmvmenMQ8wCnufuX8xw38xnKvqTZzJc02BxXOl6P28l5XZma8KX7X7EtG8hlH4s/1Y79pcQpgBbAltX+5nRwGKjkNczvE6uR5hpHUfLNvcWm5o0CaATCG3rP2kgBcAlCfv5aXluA2JB+L87pHMFYWt8IDXl0of6l66mXVXKvCGfeQKVzT2I99Gv/E4gZsIOIYT7siJgPPGul3H3V2e6txHa2OmKMIuNxTYnBMWl++U5n2+xPteKsnMI8Q1flc/0EkITex6hEb7C3d3M3kN413hF3v8f4CR3PyXztE4l/guJ9qrsRQfvs1ummb0G+Ka7v9HMJhID1x9XwuwOHOi5Q2jKgyvT20jnkTw/jWhHhni1qeIlLyptjDVB+MfE1OA+hCD1IULg3JNYOXqqheuy79NHWCbMDMYTuwQVDfeyhO2We29v9MZKlQ3X7cQq8SEan/yopxKjtkOIile489qQWEz3BUIL9FliBHY2/bfv3YqYIrmtFM8GhBC3HTHqXNzTtUwpH68mRs8L5/9l1zB/z2CvJwrsENcwM0MWxLr8FK6/rqXDN5jZdNy9thGw2Jr5InefYi37v3vD3ueVOLcjOvDDieerfscrMty5xLTTBzzdvmWZPZFYoLNlh7Rqhb3UOhkxsl+FoS63xhOrmb9BCKpNYQ4ipvO7sFPb81i4FnuLu19rfXZGTAH1ncSCkrpOqlVAzbTbBOGHCAFm9X5hOqTxJLGS+lYbvu3pJZ67I6VW9D3EtHqj5ttCO43Xbxe8C6FdO414R/8g3HGtQGgov9cv3rrya6GB/jAxkFyEaCfLAluVJ4npz07tg5ndC3zC3Ws3Qch3tp3nDnyl828idqtaoEs6XWkqEykkz08s0jyb6Pz/5hXNaIadj95mKBMIH6tFOV2cqP+/oSfcv5No7/ejRWObg6qyUF0u/4UAemvltkn03Kc1CpE1z9I68LTY6e44wrzm/kqe3GNHzeltaUNal9EggBLvdF9iY5SrywPAET7TZYT5wQ7EoK4azwTCXvg/DXGcRixY/r27P1M636aUmY43zOzZ0N0Z72Soi8NiL4GvFjKFhXu0HYn29a48txTRV57s7sc25cX678ZLnj+WcMX2TIZfmVB8bUoIxvMTWzlv0zGdfpruIr3Dib7xWO/tkHcI0e/82d23yvr6aq/sVJrt1pXETPsPCWWQleI+izANvYXcQr0pzyPCR9HOYmYPouC8Pn9PorfhxPvorWL9MdGobUnP6fRnCSHyXUSjvlZN3Gsz1Oj+MkLT9VpC4FyOihE6LYsoGL5gamrN/8X00i01x82lOJcmhJjfEh3iQYSfzGvo7gmj0TUMLTaC+bspzBSaFyxOJQpwp29Qc31ewvbs8S7p5D0fpP8GKrsQg5UZtustxVe3SG76ty6Fe4JcaFK5fw36uCQiBjtzln4/SWiJtmNk3imqCz37hdmXaARbXdB0eR5iSqtwcbQvYfN1PKGVPzXPty1AWZb6hUxGLqLJ/4+iwXsD0Yac1BJmV0Lb9W+Guv26Oa93df93bV5/gphSrNocrwasWZP+mpTsd4kZgA/XpPdDQnibofJLDHy2IRZpLk/LmocRxHs/Dbb6xIxDnVuuValxfTkKdbOvvSIhzM704klioc6T1XgIs5Sz6NDOMILNdkbhnRxHg+eDDPM/os/p+/0JDe3/ERr17+fvJSthJpPu0Rq+T7HQ+WlmcOODTGf6QrWa6xcDb2iJ46SM42FClmgMPxPv/zxgoQ7hri29n1vpLYR/rNqeVO5bgjDh6FeeXk3NOgNiQLQB4UDgnEzr6Q75XK7l+CzRvjyQf+8lBiyPEn3B6qW4fk69x65CAXo30Y5/ibAlfifRr9yVR6399cwcY81GeEF6zsYfJbQZNxEj8GJktDWxu8zfcvr3Xx6OpycSNmm3EwJVlXkYOtW8Ki2jx4zr9UQnWeYNxIfareNz4S2aR4992odo6cysGLGuTmiFy1qnYnT5m9K5ZQnhvsofCdduK9FsIwjNdoQQC/WOIwpm7XRZamxbv4GZnUA4+T7Swj7vUkJ4mEI0up9pSif/P57+G6j8hBiw/KGaEevZwLXiocFaoTVg8BRRjqu8hP4bOpxKbMhwX/426rfxdELD81f6bO5BTCVZUxiPLY2nEo1p26i6y/N8kl75+Cbx/TYmFpJ+Pc8/QY2pR4lb+uRn4bxWmP/sBaxtsX99Vcv1W6JzWI2hzz0dC5vJLxJ2oW8gZlBWyt+FbdoBwIk5bTweeHeaebyf0GwU1GpESxxDfMeq/f+qxDt7Xf7/cmKqD0JQeHH+/j4xAJ6zJZ1+zElMda7s7rdSs+ahqAdhxdGM9zS5xxAzBfv3Cfp9YD8z28XDBrVIZx5gamppu6QzYlKrdKe7P5Vx/SlNEu5qvrOVzanfwOQ8wlXhJtS0M2Xa+oCCNF96xksbCc0A2xKzmU3mFIsTmru658LMPko829z02Xo3z11LtF/9+tJPjizrfbmWylblNtQ2+0uZty9TP2v3kLu/P80ZtiPq859TdjgJONH7mzmNqL9w9806PlNbG9KPlxJt4ePEOponmgJnu7cZ0ebMTZiRXEAonsZlf9AXr5il1sT/QWIb6G+lmcXJxGYd67j7/8zss2b25gx+E/CFNAcr+vEN87iJaO/fWLQdyWlm9h1CeF+SUWasCcL/IzqF2wkNyw4WO71tR69jW5BmYfm9hCH1p+jtQvMaokLvVUqrrfJCyyKKrg1bQdpA3e81BvhmtgShBZy+uAw4OoWWW4lpkkabGOIdvZXhU6m7EVqaZYA1c/q4oLARvL9kB9QvzJ3ufkJO/zRNl+1FfIPLiA06HqX+G2xJb8fAdxDC68sIk5h3EhW3cVqOEPr+z8wO86E7AC6b6V5J2EpV7cNG1Dh7g31ZhTOBH6e9U2HmshFRlmoXB7r7uPLvDtP/KxBueuoa5rtLYfahzyIimL4Qru9Co67P47lgKH9Po36BUdsClH42li8mBW7rtuvem4hB3VZmVmff9yrCXvFUM/sk4dXiZjP7CqHZwN3PzMb8S4R2Yz+i43h7WbDwFnMOM/scMbirchmhUS94kCj7EALb6oTwvEimX1d+izTmyvy9OZ/12+7+u+yYvpXv5Tul8GsSi/WKNQRXEwPlO5uepcKCwPvT1GGYuRcxaNwEuMt6u6VZhqvuBtfX7KMNM/sGpV0p0yxpC+BRM9vKc/rZc3etmeQBYqBW5V2Ehvx/NHynzN8niS3mT6yc34kQbFYgZj8XyvP3EwP9r7UJOjW0DTwhNNkbMFzRQ5rr/ZAY1BziuUjYYk3NPsAPzOwWdz+HdgH0pyPMezkfVUH3XOC1ZjY503mAoe2GEcJS9VzRPpDv8kRisLsYITMcTghnt/TJSlko+3zHvPddUOru78i/nUzCGtiPMKtqKx/bE2ZBR1AyDco+enqWCbvkzxPyQu+C2YuJmdcHS+dWybAvJnyZ/yovnUoMGj/r7v/Lc/9Xyc/DxCD9FZVzaxOLB4cthHP3J7KM/ZahyrGZZqzZCH+GmGY+wsLjwO8JrcY4YgX8D9IGcU93P99iAdP1hFr+M3ksSIx4xtOzixtHz49qwXii0vYdPWae6hZRfM/dv5D2U095z95nF8I273piqvhxi611DyKE3HmJKaSbzexgQjt3ZHYopxMNV2GPvD4hzG2bjU2X9/dkPtdPGbpKfTd6Jhr9bATnpdd4zJQdYQpycxPfrhBi677B/MTCgTvN7FhiUcReZrY8cK27z08frOfdYrU89V96q3HHE0LNWUSl+QbRAJQXqAD9jfv7pDkHve8yRGvu6bnDzBYk3v/b6WmQxhFC4y7u3lqBrWHxz0hoiidtvhYnOvC+aXV5HjO7kpju+qW7T+wTz5mEgFpdgLJ6/l2O6PTLDfp44n0/4+4bm9n1hBD5Je/jvaODrd97gVd5LIC8j/BtfVVqEi/1tLfvioUt5tuIlfk/cvdHzGxFeruxbeHu/6rcsx5hirRA/n8SMbN1mMX24Z8hBiBbEAObl9Kn/BKC2CcIAWFjYneqH+e93yAWvDyb6byDqA9/o7eG4HV5bOfuZ3Z85vMaLjsNwuCwwN08qfTLx23E9zyXsIc9mFAE7EiYpHTVynVJ64NEPfgbPaXIhoRGbTdCk9/YzlgsrtytqkBJofN0ok6cRG+781UJreUE4hutSbgJPYIWUhG0GrE2ZFrp/HalYIsQioqfMbwP3J+w7x+y9W4pnm8Br3H3Lay/7XN5oWCb55l+z1G1gR1Hry8bkg6hte9LzXufhzAd2omYaX6U+IYvJmSKSxm62HN9YhH8gU3pZNyNC0qLcm/dtpaui38tYnBudLCXtVijc2dVCWExFbSM99by9Fuf8nOif/5k/r8oMaidRriTW5Moa0c3xdOGxbbuK3rMkNddX5poV68m2tZJlesvIdqDT7p7nRKiPt2xJAhXyY+3HvBfd782zzUKy4RtTRfKHWZt5S3lY8giCu+5NroS2N/dT7dYUX4NMR3/OkKT+TEz+zoxGvsC0citkYLw9oRfvfUtvEacSwj4Xkr3e0RHvUqXB8rC93miYhf33EC4KPkzUYDWZ+gCqmeI6eil8/n6hvE+U2g1+dg5fx5NNLT39wl6KPAB4tlvJTR1fzSz1QkD/r5CiZntlz/3I4TtIwnho8jvrYTZSD9zBBj+nTenj8s9i6nxMwmtjZHbPNKzsVrAYoX6q4gZjZcR36AoM02ug6rP9jjxHZ3hmoS+3kdq4mlaRDSNGMG/i/CxWltvPF3QWCyyKBaWDnme1MztQMw4nE8Ixb/10gKyBgF1q/y7OL0tSwuK73iou/83tUBrlrQMI8bMbiZ8dl+R2pDj3P2oFEZ+4e512uZ+ca1E1KsXEwPwYpB7aP6/GFFO3l3UnRxM/ZqwCX9bnluY8H1+d5ahz1PyotCQBSemET/v4RVmLWIG5FfE4pshMympnT3N3fernD+Q8H6xVv7ftx6MJjObjpk9RZi17Ev0AU+7+yfyu1zu6d1jFPM7mfjey8D0BXVHuPslFWGwSiEMPkUMwm6txHsMoUBZqjqQTA3suYQd+ZaEguUnHfLab+BZrKRv6/iNsPOu9XKT2sCLPRbCbtIS1/3MoCedmrjPIgYewwbcVUG3T3zjiMHLjoT5yFRCg3miu1+YYU4gNtf4RuXeLxLrJXbK/5v6i8YFpaVw5wE/d/fjUrj8LyE4L014UDisz31lQXjYgvKa8I2enrznfaafIHwTsQ35n/P/zxDt1CqpDHFiZn6fvOXnxMzTveV43P23Fgun63Bi8fFPgW/UKTsszCn+QLybb/V51r2B9dz9PX3SqUn5OTAUH82DXETUcH1ZwnRijRHG28/IfBM6LlygtN0rMW3z+/y9ATH6gtC4bZK/ywthXklMk0FoW4ctNiCmDZ7o+p4IwaHTjkuz6Ns1LlIhtu98lBDWb6W3K9puhDu3Lmns3JQOHXbmIYTbKwmB+vY8puS54nv9ibB7mi/TW5Fw1H4J4UsWolF6hpnY9IMYxDxFaJjuobd17UTg7tF6/8RI/px8zr8wfC/5M4EzK/e8mIaNHogB4JFExzeZMGNo3CWvdO/xwAItYc7pGl9DHMcSg1cIby5PElobz283qe0oxfV7wl52fKVuv4Go96/Md3EL0TH8PH/fT3QgXfLbWH6znCxdCv8UoeGvi6txp7su9SDDb8QIF9hV0uuUToZdg1io9UeiI4cQYF5NmJFsnOf+Q7jHhBiwPToz5aRPvidV89f1O2WYW8nNFyr33kPD5hSElnsaYfbSNa/HNx0d7p9Mw+Yf9Nl6t0/YcwmN9wKlcwsQs0pnj/AbtPUpSxDeK07N42uUFvflu36SmBnZjtJus5Xv3G8b5kldyi8tC0pLcT5I/dbSZxKKnSP6HCfRW5x/G5VFvzXHNOo3Rlmu/B37vd9qechv9/3S/4XmvnVReT7bI4Qp54X0duR9mDDReibzsXYlD/MQM1mTqGwgVAm3OrGOqHO5GlM2wjmdc5e7/yb//wmws4Vfz3e4+41mtpa7X13c46HSv70mroWpt82ZkH+7LlzYjJ5/z+oiMqe3iGcLwtsDRGUrNEtLUj9VWOwiA7nVJMPtldeg4ky8H+7+bJphNK56sbAD/jS9kewNhHueK0phWk0AWtJYldLCkjT92JmYDvu2p3bM3Q/M6e5lgV97z53NFBoc2Vfy81OLjRvq8jEnIahu4X0WQSQ/odfJFVNEyxIj02OJKbfXEAOayan9mcNDq7g3YUe3pru7md1IaAJvyngKE44uz7ImYUbzbWLE22QbPRrsRAhsu3vDFJaZfZrQTC6V/99N2NR917Plgem2mH/PerwV0QmdSa+OFGYBKxKDxsk52/K0d5siPxo4NLVkdeZMV3R432uTbYK7H21mDxPa1zsIbXanWY/ktcCG7j7Vhi42u53ofG+0sMn9ZKZrhGvDI72i7chp2vczdI3Ar2kpv1nGy9PLz9Lffu4+wo61OjuxLqG56VIPIN7TM2b2j/x9PmFWUmi9277BA13SsVhccwYhBG9ObwHuioRHmN8AJ1lsBLAwvYXCa9c842hgwEst3AeW+5U5Mp9t7cxJxNqJycQ7A9iMmA1pmum5mtgGd++uGe1Yn5q4kbA7P6bP9S2p9FdZL+v6yY0JM4rp09geGyrtS2/dQVd2AnbLGViI/usoj9mUOhPDdwN7mdm2HiaGXyU8LT3SkMZk4J0W607Kmv5NCdOtLvWkbUFpwbz0FsG/kd46kkWIwcIadTclFxKKu+PpPxO+bf5dDvimhc/3gsL07KqWPEI893yl/9enZxMMMUi41t3no52LiGfezdP23WIB448JRcGHiBm1Uy0233DCzOfjRF2bi+EmYtW8vqxDPqYzpgRhwiNBMRX7BkJN/n7CtOAwwhbvyhSeCpvEIQsCLHzrHk+vABX2Q0MM5jPsGoSniRUJB/oTzWxbwnb3Shvq33NTopK9ghgRnkiMcr5isUjj9cBHMurl6RmbX09oiG6tPOt7CFsyiEbwOzn9XPZH/DHCgL9YxIY327ROIbQ1f6u7aOE38meEjdtZpXQutVjhfWKbCUDe38ZP6C2CeRnx3s4nbBkXIFbtF8/zm+rNPoLFFRaLheYC/mKx4LC6wr7Or2WVjQiBZvqAysOG9DMM3SmoaETuJ4TCG4kR7EqluPYGDrFYGHM1I18VvABwwiwQgjsJ52b2baJcH8JQe7mvEtqXvSvhlyHq7I5E4/X3PL840ci/JtNemdBUHA48ZWb70L7hRvEu6zrnom5X3/echGC0MbH4Z2lKi4jc/VfAr8yG2sqNgDqPDsVCTTymuvdtisDMTiHaiLnpTR1/iBgUQfu3KndwcwH7m9kQYdjdP0V0NE073X2Z9noA0Um9juiE30p09oVgfB7t32Cvjul8jVhwc2RO2Racn3G8i1AyLEuYhxSd4xJ020GwM9mv3E104lVlg9OtndmPaFfPpjfgGk9o40/sdxNRZh9suN6XhoHnlLy+LTHILStGDif60G+Z2USv2I5b2Jp/M5+nEIBPIspwua8teJSOnnTMbCFCabIyMQv206KPT0H3l/QRdIk+51jqTQy/R8zC9BPsy3yHUEasnX07RD+5M1HW96e9/C5Iw4LSrI8QphDbmdlviIHHIXn+U8SMXKOdeypljvQ+NsJm9rbiJ2GqVzU9mweYYGaF3flchMeX6mD6asLt5OfMbFNC2VM2ZVqR3uZZbexJbLo0XSj3WAh3EDE7uRFRHzamp1x0ot58kqj/qxBCcx2r0O4NaSgjUR8/1wcxZbFs/j6EsN8rHuyB/P0Kwr3RfwjB7zyi01ggr19J2JBsQkyRvbJ8lNJ6M1EJTyMEvGJKYy/gd/m7n3/PHxArsovV3Y+SvhlL13+Rv9+e1/clBKl9iEbmadKvKs3TCcOmFhre31OEkPZdwvZ2u8pxK7HQqHrfF8mpBDqYAHT4jo/kd3qM6MzOy/ObUZmyIOzt3k9oqT9bPjqmdXC+m+L9fpaYOrqPGOTsTQya+vrMJQTaDWvOb0jYikGMvt+Zv08iKuUmRIW9pnTPY8yEz8wsO8P2dp/B+tRmGvHSpjAZ7iHCprZ6/l3Ag/l7IUJYvoCok9cTpkJl/78nEQOihRhal95IdL7H0e73dLmmo+VdfD7fba0PSkIDU/YHPU8+4z6kX+2sCwuXwpwM/KT0rlcgBjLnFec7fqepRJs1X+ncfITG5Y6m8kt0Cue1HIWPcCMW4t1Jr025k+iYjA71oE8eViLatGdpaKNK36BTOoTWaPlqWc73/FT+XpxoY04lNOgHEDaTI6kn8+R3PofQjl1DxX8rLX7n6dDOVN7XuwllyEpk3WgIfzqx6HEkz7Q40WZPy/JVvLsfEYu9Ifq6p4kB0ofy+DHRD38uy/c0YlHUaYQ5wb8zvlPorTE6hRBgXpXfaWOiv7mO8OLyU2KGY2NC8B9PDKSuJ9rsRUrfdSIxO/FXQrB6hLCrhmgnjijSLT3r9/LaTJsYlu55kpipfSiPi4htmOlSfulQHzPcdvkNpgLnlM7vSyxW7NJ2vJQGs50Mdzw1pmc1eftHXX6Jvu4JYrbrSSrtG6Ew/H3p/y8QypLi2Jeer/zHCEG4mpfNgcfy94qE3LR+HguVwv0k81nnd35cXuvc/rr7mBOE7wXWzd9XATvm75WAx2vCb5AV4578SKcQjWcX25xLgI+XPkzRUKxL2mJmnMvn7wdI5/hEhb+nIe55KNk2E53PhZm3Jwgt2ZtL1xs7eLp39k6DEE1MJ/SzfXoifz9I2t9kQXxl/t6EilPvhnw8RnQWZxH2YZ/P88sydFOTHYlGYDIhpN9CzWYjLWndQqzuXSLTXTHPf4zoHM8kGol7icb6jPKRYd+WcWxIr6HekNDOvz3DbEmsrIdw8Tch3+t9wKal/OzcdHR4nrnyvf2O6ODLjclXR1CXlqVm8wlC4Fk28zN3XZhK+Ifo37k8nL+fJuw1Dyf8Rvar20W5qgo1k2nZcGNmD6JhfZgOtnJZH24l6vyUUl4PJfyuFvcsSXSKNxJC4KX5HDfUpdFSb99cc341ot42lt8ZfB/zA/NXzrXWgwz3UkKIOyqf9QlCIN+fhvUVpW/QNZ076NkAl8vM9oTpw8b5bm6iZ4N9U57baATvossgrG3TiNZ2ps99K9FbOHYp4TFgLWIV/vsIAXx6OzyCZ2oceObviYRZVPXe3YGJ+fs9RFs0IY/fkQJhpW6vl78nFe+JmC24mNCOnk7UvWfpKQpOy3MvzfC/JASv+fL/eQg7/F/n/42CLjETun3N9e2JxesjeX9NSoRO5XcEaS1O2LyPK53bgBwAtNzbSaExgrw02cGvQgya31vOa6kOXVx5fzcSM1zXEu3iHnntZ0S//W56g8p357nied5H2kvX5OPlxADpcnr1ZS1iwfa/8tqKI3rumX1xo3kQDdkVhMT/OKl9IVycXNtw3waEJngqMWpvLYx00zbcQS7CI6YG3p+/N2YEizGaCtcMvKMFCXu46ccI7v09qeGunP8w8Mf8/VDpXdxEjtyITqwQlldlqHb9TYRm9IvZKPyT0NS+nmi8ine4EXBH6b7GnY3ooL0jGsBiFmEivYHUCvnej286St//mUyv3FAPWzxVycfC1IxKW77BrjTvavZ/9ATs6+g1JNcyVPP8IkI7tS0VzX+Xd0do4lerXNuMGP1fSu78Q8wufK8mnu8QK+YhZlfGtTx3uYMs17f1icHXndR09gzfda/v0ZL+uUSdn0pMnx5ROn5ICBwXlepJ30VwlXjnJTRpPyBMnD4MzDvCMjEV2Knm/BuJ+thYfmegDVmR6MzfBkMWwXWtB04IP18jBsjDdnZsKPt3jSCdpwntztJF+cn0biEGhv/M71QWIMbluU6LbfOe1kEYLbuWNX0jeu3MN8jBMDEgPZeo6w/nu7mO4buUXkfY1470GzcOPEvn+ylGHhtBWpOI9n5BYgD5ulJaT1TifTvhM77YNbYsCN9MRVNI9O135O9GQZcQnm4ntJGb5vEFwnzmfcTM5jr0GaxX4nyMELgWpNLfjqD8TiLcGW5AxzrS8o7rFrEtl2WpSXBva5vnJ/rwt9Cwc19LHH8B3lt9f6X/P0zuykn0XUfT04QXs6dH0ROE16bPot+MYz1Gsb6MNRvhTxB2ccsS07EP5fl1iNHidMzs5fRsEVciKsmHCSHj2Lx+HcNtcy7Mnw8Tdp63VvKwDj3n8n8jOvlrCW3zEWnzswXRiHWlbQHbdi33/4soOJsx1CZxmN1zC38k7AnXY6gt8naEXeF2hDD5UWKq8FJgn3S9sju9BSiFDfCNFn79qjbA+xCag88RNl6F3eM7GLrBwOI07GxE//c2Nz1bp9sJzdztmb8tife1EaF97rJoZESbaxSUyucw0m6uauv6wTyadjX7CuEi6TsNcXfZWKJqp1dQbFBxODEQ+ULGuSyh1bo1zx+Yi3rmJmzdtqRXZjYg3vkvSrZlbyPs2vpxIbHA6UtFPs1sPFFW/kLMktRtuHEqQ3fd64cD483sjMp5I2YL1iUEqOWpt5W7gt43aFwENyTRcPx+XB4zytOEXd4UhtbLLxPl5R+l9IaUOQv3R7u6+6H5/x8YuqvjVGInzgcy7E+IejitF4X9nhDmu9aDjxIDqT0JTdZ5ZnY+cIW7e8M3eDVhulC3eLiO8URbexs9d2VGaDsPIgbeu5TLi7tPM7PD6bjIOHmC9s0n2jaN6NLO7EhosCD81q5NfOcdiS29VzezteltMvAfd7+qQ7x1zMvQMl6wGD273N8R5j9VN1Tb02fznz78myg7PyJmcvcwszuI/uAuM/sq4QLxJkqLGM2sKKdFOzUXw2077808Q8taGmIhKsSAo8ovSr8b+0wzW454fzcwdB1V0aZ+qN+9JeYhvB/dR2lNhJkdTcwm798hjiHZ6nP+n5QW1JnZL4DPeNoM59qMu+nzvLmY94/0Nosxov27uRJunZb8NS3qg2jfD4HpG5rskQvhVsw0b/KwYf9ohrmqKTJ3vxwo6svKGccM15cx7Ue4DjP7BNFwbEAIur8g7HHvyuubEkLC4jW3u/f85RUay/cQDex6RGE4gRjBH2jN/j2/7n1Wntrw7RjnJ0Zaw162h//ZadXzxeX8ewExMj2Ueufc0z1gmNkG9FlwRPeOzj38Xr6c0I69ipgmfo/HRiaPAOu7+39ygcA73H0zCw8bx7v78inkLODuD5fytjyhISgq6ZnEgseTyomb2Wfz5yFEx/l46fJ44rst4+6vttjw5HF3P8jM3kV8+zuJQc4h7t64UKkr2bkXU+bDFrJ57hSUi2pOpOdzd0g0hE/ZU63kr9FiV7Nl3X13M3uQeLd9feVaw8YSJcH0EzRsUEFo2XZy97/lfV8kGvhV3H2Kxa5o76e/B4LX0HMh9Jo8d3NdQHdf08KTyAVER7kJUa5WIxbMbExonuv8nhZxvKNPPoZgw/0VTyPs5v/q7ufk9T29Yftai10VX+/u11e+0xuIQd9uXfLiseVzlzw7vTpd/LWa/6e3X6V7v0ho2nfN/x8jppyL77YpYX/6ZTM7jeg0PkpvsdEGhCbmJndvG5AXaX6BGJgvRnzLTYnB3Pz0XCGVGfINuqRRSWcRcuoYuNLd/5vX7yEE4T9V7tuaWF+yBB2wPptPVMKUz5fb39rv0ieOwn3dnRaebsyfI7/HObi5xt2/lGViTWIgdwoxm/YeC1/snyHKQrHIa8M8DqfU7rr74Q1p7UjMsqxG9FN/Ir7Z04QJ1sn092H7ACFwTiE0sLt4yfdu1rmT3H3phn6yimdc/QM07BRqZoVN7F5Ee9W3v22I40hCw/oBQtBcM9uQtwEHefrs7or19+87jVAU/I8wD7i6HC4F4Yle2r20cv9ZhPnMXsQA6RJi19IVa9Jx+gvkRng2KeSrBYhZBc//VyZm9edpec5phEKlb/sM7d6rzGxcv7pcG34sCcI2dDvFYbj7QznS/CXhhPraahgL91WXEata72V4IX4ww81JCL07kB+RnrZhlwYtZV2+v0Bsh/xI/r9zJUjfjSW8xkOChfuyVxOC4L7EwqwN3f26lnx8jljtehPDBWZ39807PlI13oUJe9CiUD9GmDvcmg3uBe5+SGoVb3T3eZviK8X7JL2p37KWpVjxvRgh1Ja/RbHJwlc9d/SrxLkBOVhx99/nuV3p4wLP3RsbzFK8xxMDsNOJDmJOouFZhtg84kMZ7jJiqv9Ahn+DfxPT/313NbPYjGGSN+xeZA0bS1hv169NaNigglgI9Ervuf85m+g4P5//vwK4xN0X6pOH/YiBxhNmtj8hBFUHgAB4biNqZi8jtDfrEkLNFcAPPby1VAXYahxdNG6dsXBXtlLm93/u/lTp2snE9PFuJSHiQeLbb0o3jxudhKNM7wliEDJsk4Bka3qD22q79CBRF/6YcQ3pMC1W+B/o7mtnOlu4e9kzA2a2EfBn7+b6CMsdC4my9BpikctmeUxz97k7xrMxIQA+3ef6JJp3PfwuYVu4N0O9YHyLcJH12br7auI5k5ZBmLVsGuHuF7S1M2Z2F6FMuMjC5dsX3f03Fru07UmLd5EmYbTmmRoHnu7+P+u/nXBN0s3tZGXA+CJyYyGPmYhp1Gz6YDGzdTrRZxVc7O5nl8IcQvjJfp+FprZrhrvOOtQ9y+OELLBGv7LXIY47iUHBmpSEU4tdJ6/yhl1T+8TXJgjfRNTJOkH47n5tUfZDb/HQsBbpvAh4iQ/dEKnt3f8d+Iq7n9AnnXcQpnTLtzznNEJ509TGzkeswShkuVoteNf2FxhzNsJle49hRyGHtcQxmREYShOq+XcRmuGVZzDfjTbAdDBkJxrQ+SrnXksU7GtJ29eWOO4gthacmW+wJy0LfehoA9whLad5cd95lFaL9omj70KvvP55Qtj+Jj2TgDMIg/ovj/DdDPuOhFu//Svlr3ZRDaExXSd/X0ZooCB87hYeGI7MvF1EDAjKtqyFTW7rxhK0bFBBCF2vLv3/ECX7O0JzOFI7wdFYrHFk0zclGv3tCOfzHy8flXAvJ8w13spQW7U5iAHmk/Tsyp4kOuPCFrlwjTdTi+BG8Mx9Fyy2lV9CEF65FP4iYoey8nsobEJvIxf8VtJYixBauub3qaybhR3vPwnhcysqbdjMlJmsb/9H2Pz+jsoCNELY/B5DbQ2fIuzXh22U0FJX+h4d7l+p7TtluCPyG5xLaEKLRWH35TPcUnPcTAgGjR6DGurKgYQQfBbwdXJTklEuv9tQ3zY+lt94aul3cUzO8z8cQTpvoMYrB1Gn+9pvz8DzXEtoc2dm05jJpL0tQ2201yY30hphfLUyBJXFctVwxMx4kyeX6Tba+f+kzPcKI8zfsfSxyyeUHhcDP+4Qz5D8dMxz3TNPG1H+R6vwjFIB3KRyvDEbmDvpeZBYp+X4HZVVrR3Sbdwxa0YLaaVwtQnCw8IQi9IeJzQu59DiDYPQaLSl82rCxdi3iM5/+pHXbyc0h38kpsZfVBPHG4hGfyrp4i7PfxP4zWi9t45xPEPYtr6HMGOpXv8P6f6r0iB9pUvFbMsvYc93X+n/votq6L+r2aNFXujmBms7QnP1YWJqe0gd6PgsvyNW785BDMKeZqiLmrcS24Z2ieuvfd7NApRcBXWMq29docOue5nmr4nGckoehbun+QkBZSIxZbsivc0ZJhJ2jEVao7EIrvgmxVqDxu9E2B9vmPWrOO5oKr9Eh9t3V01CI1UIwrvltyoLyksR2wYPW0TbEOdUQngfkeDbpT7V1O1nibbvBPoIqIQGa4181mHt1XNxEDagOxFa16l0aGeyru1FCO/lQehn6t4/Idj8MsvwybPiufo8a9uA5YmsbycCry2d3znrVjHdvXPpeB8j8OxRKnetrg/73DtX5f8VCXOsPxDt8rqla53625b0zifaqkI4XSHPH0UHt2hN34AYeM1TeieLETMhc5fTyuuLZ5gXUbNoLr/NKxm6EPAxoo2avkCwT55eRCzy/AQxG/QIYVrxbnqeHN5Lz5NDa1/f7xvX5LlNEB7RwHG2VKwZKATTgL+UfheanDot4h5E5/H1/Ajb0WdlOeG79nZ62oQ7iEZppJ4A2hr0tuvrEB3a2/P3uoQ26295lFepPkH/LV+PpqIZq6Szd76nWwiB7Z+l4x8ZxrJQ/5gQdh8jvHlsydDV2eOpaGuJhUiNhXiE7+WIpiPDvJnoJB/N43iiISvMfspeJe4jV6ISjclDM/ud85uVBeHN892+MSvkwqVjEUoajSyfRxC2241bidfUh76a9AzT6BuVEBrup7fi+WuVNH5OOGrvmp9hq40JTcWzHeO4NvM1lTAhGZLfDHMboeFq8gl9PKHJ3YQwX5mTMGf4N7FQ7B5qtOmE4D8xw99DxaPGjBz02iRnaBs1fYYrwy1JdJzltm1q6d6+5Tff2y4NedgNuK70jh/Lb35rHs/muWHve0br7SjW/2k0tGez4yAUCT/Mdz+RGCRtxui2Mz8h2vKniIWk681gXpdg6HbDB1LabngUv9P8xKD+74TQfjPhUaTserPVv3KfuFekpwCYRr3rw1fQ4qOdkoBFaGUnZ1k/jnDD9TSxNqN43tb+tiW912bdPTnfzfeJQejjdFRWZDzfIAYOhca37Glkg/w9oVR3pzC0/ZxAz7vFqjXx183CT6v5/TJi0DCRWIPwMnouRKfl+9yd8A1dvf96OnpyYPQ0wiMShMea14h+bEJv+8wVWsLekn+/VHPNydWTNsIds2YGb7cHupwQQE+vnL+YGHFt2DGpO4AD0vbuGiq2boSQ/zF3/1FDXp3UQFosTHwboRk+jRjVLZnhphKVsXzvrR3zWWZHM9uB+K6re9hRfYFoTKsrUeckbM/mIOxL8Vh8c46Z7UFM0b2f0Gbfb2YnEULNosSA5zbiG19Fzz60E7kIbW7gq2m7WKyE35qhHgP+nH/PqcRfrDieXue8sqsZNVuF92EFYqHo1vRf7X4k8E5CO1rYT07H3a8xs1UIe+p7fLi99clEA9YXG7qSeBywmpktmP+PJwZPd7U9TFIskHklUdcfZ+huZNBt1713ANt6LgJMzjezjxBl+EXEwpIq/yM2znjWzJ5lBGWjgaKtup7Qnt5DCFL7UtpdkdBMTSVmgC7LsIsTgssiNJff3xIePv7k7veUEzezpQi/uMfnqZHuctjEIhY7b66a+ZhADJzuHcU0IMxRnnOa7HuJb7Yj0dGvRLTT8xNuwibk/TPdzlh4UfgsMRPxb2IDnz/O4PPUbTf8HmJnsG19BIsW23D3x3JtQrGI9H1EO/wlM/sXoRVekRigFnnbmagX3/bm9TgvBjazWKzswIlmVrYpH09sbPWPuptLlBd5fY0wFXmv54IqMzuOWJi9NTPoRaiMu/8jbfLnJNqWLYg+ayOvWds0JKOxZuROj3ULhaeRrYnnXJuep5FvZZ7L/KZPtB9geLmGGMR14TCi7/864bLzHKKP3owQTI8kvNOsZjPn+eSnxMChCWd4nZq59npGRmmz8iAqwveBf+f/y9JHY0tpJ6sO8T5Ey45Zfe4rNFflo68Wq2NeliM6/tfl72WomebvEM8tDcfNxOLBEU33EMLeXkSHNC3PzU0I1WcQwvql5WMEcT+VedqTKPzF1M8HgAv73DMP4Slkj4Z4V6HnV7rVHKFjXs8jRtv/zN9/IYTFjzBUy7tJwzHDU3s197RpaR5iJjaoIBYkNE6XM1xzWdVOTya2Lp/h5yJ3I8vfP6Bl1z1Cg1On+Vg983MxNXaJxJTlP/N3513CZvCZ3kzJwT/NGxLc11R+ifbxurzvh1mX9szneYwQNmbY7KvP8xT2jzO7kUVbGX6aGh/Wo33QbN97Vebzz4TwVtj1DtGwMRPtDDGI3J1YXHsbpbZwJp7pBhp2YZuB8rshIYS1mmERAtf29NrgfwI75LWls46eRZg8Xkhl06DKcSTRlhyff09mqInMj4hB5aKl9NcjhMfiW83HUH/Fd5AbtZTuWYuGTbJm8Bt0WRvU5Ft6gyyPS+f1H5BtFzHAemQEedmZUDA0rqlpuH8iuZseYYoxjVJdz/f3ID1/xDOUTp+0F8uy8G1CMdJJCz6SNMaURtiGux0zQoMzmRgBQQh1S1DxN5iuWG6hu09diJdWd25cwz11WpVCi/VwzbVW3P02CxdKd3uudk1PDU+VfkM0AnsSHWf5/ofyb6O2PFf370rL6uR0fbI98c43IUa0JxE2YBAd8NsIjcMEZnw0NifhAuwnZvb10vkriBXOw3D3pyz2JD+bmD4s8jwfoQHdkRh9306MXg8gv6e7H21mDxOV6TdEI9oJD/dwZwG7uXu/1f14g2ud1PzWvavCt29fLHw8n+mhsdyO0CxvaWbDNHAebru6+EatS2cjQrPzXqL+HdsQfIUMczNRR7cqpfkMYTLS2ftKH35LzJh8ktCW/c7MtqDel+uBxGKxr5nZBzz3ss+ycQChNfoacFZqpf5JfI+NCG3H1hnV64lyf5eZXZfPVk7nHTP5TLcQQkXBvMTiKQiB7KWEzekEomx8PdMdVn6zPLyOEOLeR6xUhxDiTiTq1+MAZrZYxnN//r8G8Z2vd/chftpbeIZYgLWz9zRq44j6eBgxLdyFtnbjHmBnC7/nw2a43P1TI8hzE7sDH/Fwa/hJYuBVuDU8gHi3h3rJFWQNH2HG25nrCAXIEYTS50bgJVbxouQNfstrWD6fo/qOf0g8bycs3EG+iKhXVddZTqm/tXCfuSPRd0DMwHw2/16R595NeKN5S4b/K1H3+mkB58l0diPqwm7uPrkuYHoLOIPwZOKk715iYFPkF3qL98pMIjxqVON8GcM9gHSdubsI2CZnZiDq8y89fI8XNPmW/hYhXC5HDBreTG8maQ76uzIr539eQmbYkWiv70qPFtU2bc2WqF5K7rng7ventrvc9yxEmP8VHj8mmdm73P3PjAAzO4YYvO2e/89HzJItSfRpnyEUYTeVbuunBe/MmBKEGT4lMY2wY7yk1Ag1ChMpbHyMMOAeNt3u7qdk+J9lmD0r8XyM0HDU4ukKqoyFy66DmwSkGeB+Myt8Lz5APPM4otGcnjR9nINno3C/D/WldwAhBFxFvSDxITM7lRjRPQb8iuhIy5tgQEw/b9NP6DOzTwM/69BwP0s0hHXnm1ywLUZ8b8zsrUQlfwfRmP6a2PK4PFU2/R14miP0yXfdJhi4e2GG8Zbmx5kezxqEr9YViWnOLxL2XU5saFLn2/eqlmirG0sYPZOBIdnNOL9N/QYVdfldhNi44cOE6ckfiI7n9033ec9F0bgcxN7tM+G2qA9voOcL+aOEsP0Aw6ecnTAl+AwxKL3LzK7J82sRDf+WRLl+BVH3C1/PvyY0T0V7+ACj0LhWBJmX5HtegjBXuLF07d+Zl1up2ZDAS6YgdeXXw23jx8zs4/Q2H7i/Rgg6hWjbjjOzRQlt3N3A/5nZku5+WOa7sR4QwsnXfeY3shgHrFIyp6mmc3Pp9Ksq987o4LuOpelt9PMkYYIDsVBtb0I4udPMziH6jWH1It9Fp3amhuLZ9sn0xhGDv4K+7XwDlxOmZf+pnF+DkX2jYzLtHTLOYe89XZztQJSZs4l6erqnWzwLn/KFG8ctCG0whILFCa8aJ9clntPs/8pw2xD156a6sIS3kHuIGbaysPprYqBycyqc5iXahLIibOW8FzN7CTEoeQ/15gSFeWXfepJmY2sSWt3CFOJDwEFm9tZSGV+c3gZebyHc/l1q4cv8cqK8nWThbm9heiaiaxfvIevyBkS/+RePjYDmJNqPL2Z+v9/nnXXFGOq6sVoOvpx/X0codfYjNNjVetvG64mNuAp2IurjysQ3PY6Y+f/ACONtZEwJwl7jU7fAehsFOPAHM7uCXuUqCxN7Eo3JwQzdMecuQtAuBOG5ad8xa2HCHOCDmYda26auAlILtzFUMN2cnmP6wo7njzT4G83CfxAhzM9LdPg3W2wechvR4L+ZGJ0vRH1n8gxhHnJ2gzavEM778RngW2nXdSxwbk2nDNEQrk3PrrvgLcAE622sMf0RiYZwR3qN6a+Jjun9xGrcIfajqeF5xN1PrJzfiXAvdqQ1b4LhxI5l59Gt81044/kj8Q3nJTqfZciOn+ZdzWrxkkN0dy8Ez7W8v5/LNxGNylZm1s836paE8Pt2og58h5hS/4Kn7WMXUkP/DSo7hlnYbS/l7l/pEMcZ+fNB4Mi00y3vRgYddt1z9+ssnLfvRO97nkhsuvOkxS6JS3hlo5UUUu8gXCZ18llsLX5wGTqALQQby3TeWwr3PWKQAyHM/4meJ49fmtlOLeV3A2IgOAfREfaz/1yTXlv3LmITjdeY2TbAIRYbCTTWg/z9KKFkuLESZgVCE13kcT1iMPh7j12j5stnWiPTmZfw+FKbjrt3tV+cWZrse59x97da7KC5K1FPjyW+6avN7AZ39y7tTEP61edsbOc70rgLm5Xs+0tCWR2rEoLNFd5/DcjGhNb85D7Kj+uIgdrvCUG40GoulXGvQ8x21uGEhtAt9ghYjP6C8BaEn+yHbeiOkP8j2tmyou2/lXs3JDTXEN94LcIW9rfEt1iKkC326tJfEAOIvxO7Pk6G6drN4/Laehm+TeP7WaJMLgt8vqQNXwI4ysxeSyguXpJpX2Zhu38aMeP6NcKzU1n5MqOUlThzEbthPpr/b0zISv/IZ/0QcJ+ZvdhL/og7sDShGCh4I3Bqaab8e8T6pTndvboGasap2kqM1YOeC6lpDLXVPI8Yhf6IGDX8G3irV2x0iKn2B2viazoepbfiumrb9M08vythOP5vQoMx/ah5hgWp7Fs+wnfQZlP3V6Jz2obQgBXPvj2h8XiE0n7gM/Et3kWYRdT6+CUq8Jb0VszeTnTwK1TC7UoMUHYkbA53JEaSkwlB4ZbK8T+iUf8GMH/G0ddXbl6/Cdik5vzrgP/m78sI4eO1xJTicuUjwxyZ5eFGYpT+s/zmj+S17+dxD7nSvVL+1s3y05jfEXyDSS1l4fiW49bM/77A8qX7niUW1/y1y5H33A5sUJOH1wC3lf6fi+j0tiIGO+Wjmr+fEAPZN5fuf5AR+Ajv8176rTxfjnQzNorfYJM8jiHsfV9PLvZsifdF+Z4WbSu/hDnQFKL+PEJobT7dJ96yZ4NTCQf4EIO0J7vUgwz/XXr1doUMuxPRLh5OaLkuoWdDXtSBHxFCf6d0SunNQ9h4r8YMrJ3o8B1HZN9LdM5F23YvuTNf03caYX5m2isHzZ5lysfUyn3TXXPl/xcTmsW5ZyIvb6C/u81zaPCKQQhzy+XvrQnhcm1q1gkx1L6+3PauT8O6n5p47iQGDHNnnCvl+fcRNrxd+osnqV+rsBrwZOn/I6j3Lb0D8K/8vTgh0J5KKH4OIDYogd5aldWJujcty+IHq+8o69G7iJmHBfPcinSQQwivNk2ykgN/rynHI/VH/DAlP/xE3/Kh0v/LZ1plrxHXEjvNznh9mZmbZ8dBdJJ9G4osgEVhLFeGVxDb+44krUdKFeszwHn5ezNCkOjiRH05YoT/FDUuSkaYny7uhnaohiVsmB8hNAzDNnsgRp3zlH73PTLMAkQD9iyh3eo7ACAE/v8jtJ5TiAq/AykMEPZqt9FrmO8g7MCa3sPClfibjqcoCXqVCvVk/u67CUYp/HeoX3zyXUoLegiBZPmab7AC8FT+numOPdP5GC0bSzTc/xQxdftWSo7j85ueSE+w7zcAeJTewo2n6solYQ5SPPObiEFCa2fckOdDiV3UmsIcRM1CSkJwv5TeAsojSscPic7tog552K50PJnfYLu6YwTfcq66cpDlpLH8Zr6PpVefvgw80CedqwmXkcsQHfwGeX49om1orQel/H6PPhtZEOsJTidmncp14I3EIq6u6cxJy+Yno3EQ2t0RuzXM59sz32trOzOC/BzFTC42oiKc9Tl+QK9NH7ZQK89vTr07yI/l8cG2I+NpdbdJKJuG+botXX+Mnl/wp6m4NSNmBr9RCrtCpvsbwuSg67t7nJ67sjtK72L5LLtd+osrqVmsnO/x6tL/jb6lCU3rJPosTCWE59Xynhflu3l3TborETLLA/kOizp5BHDsKNShaQz1R7xw5nEdRqD4I9Zx7JO/18znKftF3oThgvDMDxxn9gXM6oOYEqjzWbp0VtTrCbczQ14Q0QFc3hDvvFlIl6u84OXz9++JqQmIaYon6eZE/a+EEPh+wp/pJuVjhM/eJgg78Pqa/KyW72xvQrCpCnO3AIuUfvc7bs4wvyM0QocQ9jx7lY+afL2W0PA9RVTiB4kGZotSmEVp8B9I2AQXo+WyT8hC69TPF+KthDutanzbkbvg0bAJRin8g9QPIl5ByU8opRXJlW+wfT57p44938cG1Ghi6LCxRIeytBgxkLuB0Gp9j9DgPsPQ1fCtAwCiHuxck8YuxPR7EeZYogOeh9C2TD9K97ycmh3h8lqXXff6aacvz3c2Le8/j5oZpQ7vrSzAOy2aNob7cv0aFV+uhND42Zq0Pk1ocfuWX0pasDw/N9HRDROk8p5CeD2ndH5fYqartR5U4qvdyCLL0+o1dWAFep47WtOh4+YnY+Eg2xkqswSU2pnSO3tthi0PqIb5q60ez0Geb6PnCeAtxHqc9Ym24Lya8l5uXz2Px/J4mqGb2EzLc53zXX13Ndd3znf1OYZuzlEcq+YznEu0Y78lBvD3MLLdZq/O7/FyQuHzHXpmCnd0Kb/khkSE0mf5PHYgzETeRkfhkJj5PoahPvzH5bl/UO9Td5hnKEJ+OYYYGJTr5FTg1lK4xp09G/JZ1w9Pq/7uEM+2+e0uJEwwz6xcPxgJwk4W8mEaKGJxzzm0TLeXwp9Abwp7LkK9Pi3j3rpUCA+mz1bCdHCinnlYfZSevU0QnkoKopXCfgCxA9KZhCbvNkJLfUb5GEE+JlMjbFTCLE4I3jfkezqRWMQGIQh9m5w2Jzq4t+VR/a6fYOimJ7cRHWShAduUZpdl38j730Rvg4U357lvZRz9tB7TGyoqWxCX8rc9QwXhg4kGamlSSMl83JLnGzt2wj/pKQyfVj6a3vTtbbRvLHEtw938TT8qYV9P1IfHM93v0dMytA4AiAHQQ4R2v3iuj+S9e3csuwvQsCNchjmv4SjMNBq107RsPT3K9fFNRNmvatOfYKjJxwPUtBHEAHYyDeWXGgf0TfkiyverGdqxbkCYbLTWg47vpXGKums6tGx+MpPfbp2uR8f4inbmiawbde3MGwlBrd/gqU64m36M8PneUyljXyWm/M8mt1mmg2sumtvWTUrf4zJCezlHHhsT5jFvG6361LHOvYzo737PDG4rTWhjnyLajM3zmxYbD32yS/mlfgBR938xYK7bVfINhNzxypo8viqvlTWxi1Cjhc3jIerr5DSGmmq0DUZeTGWHTaI9+Wc+U2t56fD+tyAGH/tQ2SmSkOWmUjJvyzyPyARjWJozc/PsOAiNUJ1GuNwxt063E8LHOvn7XcSI/qXAFwgvFdCzbZpGzVbChClAEcdlxGYVEDaQD+bvaylt3ziTz/5F0ranz/VCq7Bv/t6H6PifJirt8U1HxvFB6rWQc9Gb5rqBFPr75ONMYlR3LbG15jBbYkJTNo3QLleFn9OJSv2lrLT7ZeXYglhxP4lY0NXlnc1JrP6eRjRmRYN2MqmFpb7RqjZUhxJThl8ghO9N8/dDwGGV9H5Rur94pp/ToWMnRuQXEXZw08s5MUi4On8/THuHsV/l+DrROTxMrPivu2d+wtTi0sz7DXQfAHyTnqZ7av7+Vun6L4GdGvJ7PA07wo2gjvyH0KSOq5zfhdROj9ZBe6fcyZcrUVdfVXP/Kvke+5bfPL8rQ80yJlMx2cj4vkr9lunz5rWmeuB0tBunZYq6JZ3yjnuNQsBMfrtpDBVOGjX7I2hnvO47ZZjriQHniHd3m4Hnm0AKwoRg9BShmPgrcFKev4ve7NV/yHqe7/fREaR1AzX+owmF0Y2jVZ/KYQiBd9nS8XJC8B5WXma2bmf829FThHXpLxoFwtKxHaGkKpfHcpz3AFvV5G9rQoapzUPN/w/RU25UBeH76p67kt7SRL80lejbDyfajePz/1PrysBzVLan0fMjXJh6/JsZ3MfB3advQ/u8wcweJ6Yp1vDSinkzW5NwiD9f6dyiRId4X008TxFTCHea2bFExd/LzJYHrvXcDS5dvyzgJR+SGWYy0fnf6e775wr57xAjxXUIm6TdzWxzQmD6uLv3W+2KmW1NaD9fDmzp7neY2YeBW9z9Lx3fzWPEiPVDxOKscYRZxoHecSeh0qr6Oj/N97n7eDPbipgmqn0mM/sJYRpycfVaKYwRWumlCXc7xe5HG9BbfLIeYS/0y8q9OxId7XJd8pv/r0SMXI1YAX1TKewmTe/E3S+w8JP6OcImcIm8NJEQag7ziocNM3s5UQ7GAVe6+3/N7EliAHFjJeyrMsy86ePxne5+WdkzhJmtCFzl7vOb2Q+IDmbELnHM7POE+c8nzWw5Qms1J3C+lzxFZH3ajejQdyM03eXV53sTg6e9SvfMR0xPGjDBS6uF0yXRL4gFXtcxfNfD7zB8RzjM7A3Aae6+SMfn24sYtHyJnoeYLYi6erC7f7tLPA3xb1f690RCG95vN7VfEN9viAsrM3sF8S1flP9fTHhp2a8S7mtEJ/iafuXXzKZ1yLZnvW2sK4Smqx+fIlytQQi1OxKddFFv1yfqxYmEzfUFhOeFTQjBeDViZfvGRJ1vyuwFma+LiQVDn6jk9yiiHm3UFE8TWfY74SNwCZj90z6E5rfazkwG1nT3/40krzNCprWqh4/6rxFmPzukO7Kz3X3x9Iy0DSEEv5poFyZb7PT5eXdftxTfktTsuufuF2a7toG7X1PJw1rAxe7e5AqzHH56e9fn+ksIwWcq0WZVeZDY7a/qMm7ENOWlS38xgnROIZQ+n2D4rpKfIZQk7yba238QA63XEbNBpzB8N9p+fIxYDLxbPtuaxPt6lBgY7Zj5qX1uMzuRMIP6MaEEeQMhW1xLmHst1CfdRwkZpks71QkzK7eTXyRmSx+uhvMaV7d9mRUSfNeDZkP5BfLvXwht7xKV6z8iOvOuad1KFLrxhMb4/9s773g5qvL/v5/Qq1QpSu899BLKjyqKgtJEoogUEfELSlNAJKKASEekCpGOIE1AmhikSe8kdDD0GkggJJQ8vz8+Z7Kzc2dnZu/uvbs3Oe/Xa1537+zMmTOzZ855znOekphDjKCmWf5HyTaIEicLKuQtR4PKOCQMfEJttrYX6rSansWWHHco0vymM+8kpgaTyPeqXzX1XErvqWJ9x9NYk/Ax0mLk2TstRc0Jq8fScNi/IE1ojShZEsq2RRosr6OBPtfDmlRWs/T1qM9qlo72kZ65D6a2XDk9Wva7BnVCv0lvJXVfAnUaG1IzhZgUfs/v5b2TqBN+LXXsa2HfNEXXypSzI7WlvMQZJdnGUpIRrup1wjkTqXdOrdNOt7JRrw1yCjSJwJ001qanM8tthSYGF6NJx+7I4ewzKi4tV2m/NH63N0Nxh6s+g5MotxtvxxJ10kafRalX/4pWDcYhgafl37PdG8VmKbeEdt6SPWPFerxHzU77HkKWSKSdHx8+Fzpqhc8LoogBuRrLcMztYftKqoyvIO3ziHY8u/D9OeG6P6QWWWh/JA9sj/wvjmvhme2S2j4Jz2aX7FaxrI1ImQ+iFam7kJwya2p/UVbJeylxTG3i3hYM784zqF+5H2mJHU1eTw3bxPCunZrZ0qsH84d28KtU+UUrLJ8g06HK40W72kzVras0wmY23HNieIaZ4C3uvraZrYNesEeRUAxy+pkeaegaxfQEwN0XD2X+BjX01wkxd939UzO7CwmF65jZ8JIqH4EcIeoeYtB2LuTuo83shyX1Od/MHkPh2C7LaAFXCfc9X0k9kuv+k4LMZ1bLvLMWaqBLheuchQbn15Hm5hm03JAwDXJy+qe779jgnr6W+vxgzvfpez4x1Od/wLc8X5NwHTKD+bsrY1j6+yOQDeoJqPP7LRow0/XdAP0GqxbVJVXmOGSHCTlajyplhHLGIm1VniZhQyQUvI4GpGvRLHtBNBG7y8xuB65x95OTmbu7vxS0YIu4MjL9H+oc30WavHT7cy/IEmRmP0JCSeJ5vBfqqI5BYQcXKjh39nCBsTnfbYzCC+VpjTYxs9EoSsUwz8kMZWa3hvpkM8JdgCYdm2fPKajnOKS1npkc7XQ45qvIsbChpqJRHFzPxKouOP97SJN+OjmxXKmPw/tlFPEhaa+PAEe5+40Vr1WkwRqH2sgsSBBLt5dpkM3+mR40r0Xav/D9e2gCm6fpvhdN2nr0i+GYhT1k5iq7TuqYdPKTkcDp7v46bcTMFkC/y/Jh1yjgjGavk33/LRWvFzlMXYFM10bQM7b3w72qfH49rkHj2l3IeXtRd3/dFDv8VHdfpmI5hRpLd781rFZdg36j18KpX0Ht+9tesBKauVbDvjN8/yrSPK6Exv/V3P358J7thlabhiJ/jIfIZE9DJlPLIt+UvD5oXOrfWakJcdn+dfZwfJGW/BHU111rZsug5fpzkTb3bnffO3XPK7v7y2b2MjIfu8vMFkMZH5NVo5lRX2TIxCvpI38MnO+15CUroNXCz8P/s6BV1d+Yssx9j9pK5cNIuK9bzczBkWD/FXd/M5T7MRLgR4X/G62wzIFWp38HnOTuhfHyqxD6mefc3fP6PVM+hQ3c/d+VC223hN7Khjqf4zL7voRewFtT+1ZBs5inUMf4EFoOPQAJpx8ip7ojw3Zr2PebTNnbodnvV1P7foiyplWp7+ToBZn9c9NEaDQ0OC3imRkOavifoM55mdTxm4f7P4TmtHJJWKNx1NufJk4cR6CX/zjq7UsPQS/Q9OH4vPp8hGaYL5VsL6bO2x1NarKahH+h0DHbIoH8X0jYHRY+f4Zm0i+F+o7OXOMZ5BRS6NCXuuaC1Dydc7UeTTzjIo3QwuFaR4V7uAkJpQtSc7pcL5RxTvjt/xSe0UfU7NHfRoNQUT2yqxfXoQnKF0hz/D4pBy0kJH1B49jQayANTN4qwq5IS3EptbBsj6CJzGnhmLEUeG4jze+rSFv9H6RhGhP2rdCu3yB1TEMNKiVxcJuoR5n9abN2qN9Lnn9q3/5hmxDaUvL/7gStKerTdg3X2pd6J6zvEVZlqKD9C8e9T4HdOCX9YtXrNPGce+Xpnjq/klNjb9oePTVl3kobaKIeX0Xv/GPUx2E9mRBhJbUv11ErfFeosUyVYcjMal9kPrY5ObF+G9R1EBpTyjTCH4VtcfLDmo0o2P4d6vgpOauMVX7LzPMqbL/Ur/gdiibTINO/V1Nl3U+wAUaTiYuQ0ul4KsSfJvOukenXUF/2RSvvR+o6aQe1cTThoIb6hifb1LYn33Oox2vUR/uar9n3qW0vXptucGEk1Pwq/D8HEoL/RcWA3mj57NCc/YcAF7W5vo2WGhchtZyLQhrtFhr3cWhQSoeMeh7YPPXDJi/Qj5A95X+pxQfOTexRsb5vIYEjKwgvltQXDY6FzzqnPh/3sj5PhLp8hkxVXg6fx1Ezen8OCUQPoRnsRdQv442ggfDWRD0uR4LwZuHaQ5AQ/mTyuzRRVpEgnH2Bk+dfN3FCGo/zw/VHhnteKfX9e5SEA6IkQQWNow1kk56UCoWhnnvk3Ndp1DzmhwN7ldR5JuToegJyxtiDjIdyq79Bxd+pMA5u5thp0eRlJ3ouoy5Sdat4Xz2Ed2qTv0lIOEj+HxP23U3Nk30jiuPiXo5W2ZYteg8ocRylpF+sep0mfu/KZk0Nzq/k1JhzXl3yibBvfer79uxv/VE4pldtoJ0bEugaOmqlnu2i4fPL1CZXk00smrhebkhIagLq+hQodpBQ///C5x5hzSrW4QkqOnXRWBAubb9I8bZU+Hwb8LNUe0hHaRgK7Bo+r4aUHIkmescKdazrx7N1piYIf4omRjtm22zObzR3g+skDmqP06SDWmgvH7Wp3U6+ZzKyTOqeJzVT5rR0ES5Tgq8Bd5hSrO6EtErf8pw0pmY2Pz1zgW+LGlSWK6ilL8w6veTV5apG31l9uud02kGoT/eMmS2PNH+zU8s5vifwWzPb0rW0cDZwqsk5DmAhM9sAhRgbhjSIybLZDiiqxTfCcvTw9H2VMBP16X0T5kUaJVBntw7qINP3vBFaFroDebOn63N/L+vz94rH4Y0N37cEDjKz09z9g1R9Z0QvQ979ZtkImdS8iH7Td9z9bjObiJZ0bq1azxKM/DTNs1J7/rj7E2hC0ojhqAM9stEBXi1N8MqmnPbp+q1oZmnHhwORU9TcaJKacAW1/PWLo8kq6DnOGj6fhjQnv0LP9qhgHvI4PZeFT3T3T5AmvFXynnEzbErjVK0LJ/+YnByvQ528oQFnWnRvE9HzecXdz0wXYk2kns5g2R3uvlgocxwKT5ReIlwcTaKOQhFt/mNmM5jSny6PntNTwKWhf90Imcc8bWZF78HBaMDeD9n+gczSRqL+uKxfrHqdXj+XJlkUrVxk282fUV+NmR2NlpzPD6Zvt6B28mHox+8DcPe70gV4xtEu3O/r6f1mdg+K45v8fwxaGX0//D8PcrxbmPZyMhJoliffUQsk7CyLxoVHgZ+Y2SvIVCIxg8DM5grn9zAVQALruciO15GPx4tmdibwpsvZ/BkkfBct0/8VOXndjib11yN/nEGoLVbhYJRO/GcoCk9v+ooq7fcB4PBg8rUBMuUDtbU3k4Lc/eLU54dNjvjLAqPd/d1e1K0R30S5DM4BzjGzq1AkoxEoWtBRaHVoTgAzG4MUAoe7+4fU0twnXNnk9RdAfUZ/0dzv2g4Jvd0bCuw/Fi1vZ2ePX0LasnSopvT2BkE7lTlvD/TSpWcVjZxcCtXq1Kd7LgzOj16Ka0k5VyGh+B+kHOFQQxyfqscnwO9Ss55Fw+ceiT2aeK7Xo4ErmUX1yLyDBNxv55z7LWopH0vrg2b+hxKW4sgkPmhjW7mW/LjSP0e2tlXKGEstLM/LtKb16KFFSN37F9Symk1EHXtdVjM0sdgmp9xtqCVvKU0skTpvcXISVECPJdtG70JhcoTw+RVqoYUeA3YOn4cQwjBRYi5D44xwPyG8B638Bs0cQ8VUrWiCexkyExmHTJlWQxr0zamYerod90UDrSha5n4hfF4+1OkD5Mh3Z/j8PzS5bVr7R8pxlJ794kPUUrNO7hd7c51Wf++S80udGqmQfKLCdY4i5QydeRfTIRhzl7d78UzGNtrCMaVmD+RrLBMn6R3C/nXQKtXr1Fb3ksxvj1MtJOTXKUif3OAeF6Y+rFnWHKxuSz2XJLRdj+x0VdpVlfaLVl4fR5rhI1LnngZcnCnvu0gZdk1enUueQSWNcOr/GcP1rg33/xryNfko1OHnaBJ0Dlq9eRL4Um/frVQd/k0qBG2L5aU1wmeQrxFu6n3puEbYzJ4gX3r/HM2eHki0Mi4noOORjfC3UeaY3ZBd6X7IRnhx4M/B0SXtoPJDpF1NyhqUqce0yFHlOOTM0BB33zicMxzYz3Och1IMAdZMH+PuY83ssFT9cPfDzOwoNFgNot7B50lgbzO7HmkhEo3rV1AjrsrBSNM7E6HzpT6sESg492M55z4Rviutj5kdiLTZz6POMf37Tv5sZvOGe38n/L8Sekmf8kzItAKGkG/sfysSxKvwNOq4oEDrUZG8trxS+GtI4PgUTUCWQZ3qw6hdg9ro/jllfIwmFX8PZTwS9i+bd/3g2HYuGswThzAzsyuR/ehiFe/nCcpXEe5E9oFPoGXDU81sc9Q2boWa5rIRwZluh5yvHkLt6/DUsfMgofNRz1kpQu9QK85UdyDzpaT9uCmM4i+pOeiCBNqNXI50k5DN9MNmdjDSBn8ZCUxZ3kOddTtppBUdnbrWKajd/CDpj0I7uQi1rUravzSZfi3dL+4bzhnsPUMxNX2dPuZ04CQzW4ocp8bg8DY/MtUDCcKXu/v9YUWl0Dk4xQ+ovYtZdkTjF7Su4QZpStNMh8a37ZBADhoHkvHjfdRen0Wa/ZWhssbyOBTxZD/Un22C+qtLUR90LAoJ+WjQoCaMQuM1qN+YEb3vnwft6mQ8OKhl9o2mfpXqvZx7XgWlFE9WeLPPpQgnvz8vbb/u/iThGWY4kNR4ZWYXo99+BD3HyqpsZWYfhs+DgK+ZWRLScY66G3JPfDj+ZmbLoYnq3Ci2dZ2Tvckp/VbkxHtQUQUK5LgvIW3w00gjXZngIDgYtcu0vObAnGb2OZLVhgJzhFUJUAKRpui4IEwTy+OBr6MwT3ea4mI+5O5/M7M3kA3i5sH7cj/UwEAv3A/d/fL8IsHlZfmAmR2KZhmrlFXEw/JzWIZfEv1AL4TGljCBTGMMfCl8l5h4TOvur5LqVE2e7Z+hAfga9BKd71o6B9gaGdtXwt1HBmEzsemZES1x/zn1EnyCbMdeypz+VWoCUVl99gP2dffTSqp0OVqeOS8IN3egzuD/zGxBdz+hwm3NTP4LOAmYzczeRMvcTxWUcQoSnl5Dy4I3oWWiiRSbKOSRN4jtieynzyBMnMxsfeCBHEFuceqjCSQ8H76bLHCUcArS4GyCtDGgScOZwMnuvnuFMjCzO4BdzWwOgmlHjlD4M9SWQNEnPg/Xuhw5cFWhVGg0s9koWWIFcPdXKlyvaMA5GPiPma2J7PvzJoyg55Es/79DzVP+VdQfjEbLonWCINLSvlpWweD9/Arl7RfUL+YJkSsjbSaUT8p/jAQ+aPI9MLN/ZHZdjN7NszMmEqC22avr9BGJsHd0wXcG3IAmsFtQm/xPiyaYVfqZLyPb8bzfad5mK12Eu5+ft9/MHkYT1D/Ru4nPeGpmcQkro2hFHsbkGVzRiH6JltfnpKeQClqST4TCSgKqma0KbExP4WjyeJxzzglIU9rwuYTjxpnZn1K7ZgUezwjvoAlSr9pvRjYgnPczdz+96LwSzs38/+fsZZMPpigS30HC46aoXV+SFYJDXV9PJvXBnCuvz/wQ9XmPINOxLGPD9zd7sdlLHWa2GZpIzZ33NZqspf9/IPN/UxOKjgvCHmw/g0Z2C2T/mvfSJMxBrWP/ED2o55ED119CmZdTC6bfLB8gbVMpoc7HoJd4evQDTAwv02Hu/hmyITzHzPakpm1YFy0TJoPHhaG+WfvIr6G00FsE7WldYo9QRt0gE4Tyb4Z7OMvdPzCFtxnj7u+7wp98ueC2bgb+YGZbJ9cKM62jw3e4wsMU1ec55DxXxsrUnsn2KCzMmma2DdIyVBGEH6cWcirNzkhzPT8lL0Va6wG0aqf1J4Lwk7UlRN7BY8M172pw/hgk4L2c2b80oTOvyNZIOB0d2iHA7aZwO1cjrXAVklWEOWmwiuDBljF8noQ0QHVYza6+EVWExmORsLkaWkZNuB5puYZVuJ/JVWr0RWrCuDca3PImjKD2tUqo8/3AL4MgsCfqk85Hmsbp0dIgpJJ7lFXQ3T8z+Uo0bL8pLchIYJYw0IF+n9XRe3Re2Fc4Ka+o/WtEXp/tqD3Xha5r8Tp9QZXVkWHA5sHmcy4k/IA0Vs+jPrVs8B2NnD/zVjGyKxi90QxWYQTS/kP+hGRn9J7fUuGdxd33pX7F6C3kEDYK/e4LIiFl69R1k3vbC8U4LhRQE4JQ9gc0/r8F+SuNOZyF+othoZz5kHZ+CWQD+66ZDQnfl7a/Pmi/o3pxTnL9QeVHgZlthYTfrZGy6wrk5PpvpNRoxGPoN9yrwfdzoH7mu8h077oq9anAKWjieahnQhhaSUKTXtGMHUVfb6ijXrTkmFLPUTRwbY9+4DnCviWoz2O/WmZbHQmQdwJ3Vqzvicgm+Yeh/CXQkuobwPHhmDmQPc4k6lNvXk2wvUHCd14q0aVJpbGtUJ8lkSY3STu4OBIkLkPCwoZFWyhjASTIfkjNjvDDsK9SalCkdfxphePGUwsb9nfUKYGWsirZPiN7Ng/PeHcyyQiQIHchqcQnTTzPJ8h4xTbaUue0ZEuItMZPEuz1wr5lwr6zmqj7eFLJOVL7e5OgYn4kEP6bBskRkNb2wFD/ecK+IYQoFPQMZ3RXaKcfhHIPQMuze1J7l36MBKyDQxmvIo0m9AwzOC5Tn1wP9dT3C9FigHc0UU3SFy+OhNFJyI4y6aOOoSD1dIVrTG6/oQ0slPm+ztM/s32O3sUk7OH5oY5DkGZzGuSp/xQhxXo7N1q03W3iOpPbXB9eY9rw7M4hlV6ekHyCCv1MQRt3pDVLbEM/Q86nyf8306bwasjc56UG381MbZKZfV/ztn+H824GhobPZ6FVzR+iZfX/UiEkZDi3rA9JVn2bvedvEdIIo3H+A6TB/JRaHzKMkHq6iXJ7hDPsRd0m0kRIxhauMx4p27amPgnYm8BaBeetQ8q3quC4XxCSQrWpvh9TEhmpnVu3JdS4D2lS/1VwzC9Qp3CqKX3x9cgWaBBakr8JdSKzIiF0adcyzfFIKN4jlDMJdUBZzdC9wI88kwa3QV3eRDEa/5nZvxXwF3dfILVvKVJB4b0+9eZHwHreM7HEyqgjmQv4KY2XhNYKx1+PNAt7o5d9FaSt8HCOU5s5J/ftqXKmCeXMjGaPg8NxD6NOIrvEma5r2q51JmR0fwsNIgSEcx5DERCuRIPx5u5+X7Dvvi79/IoIS69PUQuG/wghGYGZXYe8fD9BgkQSSD2xCb6+oOi1wt/SpAZeW9mYQC1192nI8WMfU4rcB919jpJ7mQ214bVRxw+anCTxJovs0dPl3Ipm/Kt4SJ1svUxQEc4dR+OEDasjM4mXkLZ42fDODUPvX65tWFi9OBdNPM80ecv/nJrX+adokPhVOP5jQmp1q088MxhllZwjz3wiHFNnPlFyrz9DWfwuyuz/Pnp2DZcxg4Z2jKc6VitIPZ15FnkrOX9GgkS2/SY0WjUZi+KQTr5WMG85HwkGyTLltEijfSv5tuCTcWn/KpP5jUq1i3nXCdr0Fcnv96qsOrWN0E8PR++jU0vu8VZBP5PUdetQRl4bfw7Zxhbi1SLBJHXN2mwaEjTnQhFEzgnHfRetUuQ9360zZc4a9n+U2b8GMJu7jwgrhRcgAfZZNJY+EVZYDkSC6CA0phzrwayuSh9isnsd4g0SdOS0MUO/1deRo9b/mdkI4A53PyLTPtcFLnP3RSqWDdKSXoretfRzK3xPMmX9hFqbyRsry8paFzlJb5odG0yJyG5FK9ZP540dZnYJEua3aVD+tUhxUmjfa0pycZ+7z1l0XFXM7BZkwtfwHTf5N2yGlBCO+rF/uXszK6cqq8sE4a+jpY8jyMkM46kl2NQ5C6Ng/8+FF66HMBga+oZI67FEOC/b4CehMChZG56i+n6CtAPPZPYvCzzi1XOs3wY86yHbTGr/WUgbOBoNktfSc0kIdz8kHP8+0kY+m7zkSJu7EBKot0NOWUeF/0FmGocirdsNFW897x5eqnioey2737aoI5kWuM3dtwj7D0Md3jcaF1N37X/SIKOeNc4OuGX4+3SF+m5SpR7heq+h+I93m9mzwCHufmVoE/e5+5cqlrM59ROR27yJl9XMEq/lccj+z1F7+Bj4mpfbnKbLmhlptvcnY8fr7lf1dnAJZS+P7McWCv83FBpNWfdGoBBFH5Kfde/0cJ/7IM3WyqEu30STo1Uq3O/zqD1lQwiuj/qQpcL/adv+9HFfBT5z97eoQJgk3YpsJuegfvK+NTUb7x40IxyFa52OhLn50TM+FA3EZTT1HoRrjSU4y4U2UoXJ1wnvwIXkm3J5MnHvD8LS+V1oxefOsHvdULevUQuPlUv6d6oyMWpDfY/I7JqE3t3b3f3pcMxxSCgfQY6jltd8YH6O3v2vhK9eR6uhJzfZJw1ByoC8UKilfUgQiqdz91xn9pw2ltxzErHg80ybTF9nUSQszkgODdrvBsjsIy0zlL4nmbLyymimrCuQn9QfGnx/MIoMsqOZzYAUXOnQiQ+i/uUZNKl+Ony3AvrNl0Ea48JxMijtbvaKyqsygmzwe9TOniAzQUCr32fS09TrA7RqcEVTF/R+Uj1X2cgJY0Yq0HfFMt4nP/TRojQRaqzite5FdoPZ/Y8joQd65uyu27y2/DAe2Uv9Lmx3h33rhR93o4r3vkLOvW+IlkAeIidgPQr19Ejq/4ZJAvrgN58P2fgOSu1bG2nP25JRr5/b8KlosLwVLf0nmdh2IoSf68e6jAvPqtcJKqhlHXRywquFY8am2lr2nZtQUv5GSINapS7rhXpcRuOse5XNJwquk2uile1Dwm+8Z85xu6PU6FWf8fUodNE0Oe/tC21uE+PR5PMamgzV1Mv210pYs2eR38ciyNxthvTW7vqW1OW/SHu7RGrfoPC73dOfdWnjPb1FCMlYcMwf0fhzGHK83SR8HgP8seC8uXK2saivr9sfji/tQ9DE4UY0sb8Q2b5P3pq459VzrrMlsvHtt/adve9env8iqQyhOd+viPxNikIn7og00mm5axISlKtmZz0VuLGNbbMsrOenyJF11dAfzIhWGy5F5iYrNXO9jjvLZajiDY+Z/RRpfBZDjeBFM0uC9oNMJbIsjLRISRk7ouXPW8L/v0Gz+qdQ3MQe2sUcDgb+GTQX/0WD9Lpo0P1mOGalBucSjsfd7w0z34NRXMREC/hTd3/MzN6mWpi0W6ilVwV5+M+OgmHfgBwh8rzVXyOE4bLyJAEXlFUiPMvjPWNKYcp1fpC7Hzn5AUhrVqc58xCc3sz+i2xrnwlatmtRuJd9UPzSQ8LS6WHIXmthMr+918w91kC/y/WucFezABM95GRP1TF3+S9896PUdeqCxnvQcqPn/79wzMFey2m/ALJ964HJrOR0d59g9SYmPfBgVlIRB/7mOeYMTZA4LWxP0K7mHPMJIRB7hmUJQdRz7itZthxKNcdK3P0ekxnMdMhDeVP0nqzrtcglVTzUy3gTaeNfzuxfjfr3cE3yvd3vRE5qVVkPreR8YfUJPEYjR5XK7beIoAGcCUWAeYFiJ7yG70HqmMI6uftsFepUdJ0FgKM9k5SiQwxGg2/alGySmZ1ILZRh4TOxnpE1EmZEAnayWvkEik2d8AVSYLxctbJWLTTlIELipwL2QHH509Gd/m1KgHEWGrPyeJee7WsQ9aHmEu/+aajQh6CVzC3QOz9ntnwzOw9F5RmX2T8L8Cd33w2NIUeYWRKq0YM2+FiaTxIBMLOZzVr0npTQaqi8BelpLpVmPFr9KQqduLu7r2gyMVs6nPesuz86uZKNTZu+hPrFxB+pXRQ5sP4BmNndh2b2PwR8L5hz7EtIhlOJdknw/bWhpZzXkT3w5ODkyAv0DqQtOtdrM7bFkNA0ItkfvhtJLd3sakgLdDDSMFUymkfCzoLoBb0SxSr8fdi3cBvveXtCyteS4xZESxzPIMH1fqQlHoXC8zwYns9MqXNmCvseDP8XJgmoWN8vyKTvDfvnpj64d6G2HM1YE+3+LwjOZmjC9HL4fCwSWPZCL/3+4dy3w775KEkRnGpXo6nNiF8J10zMhw4Kz/KY0FZORJq0D4Bft/j7vkRIa0lJ4okmyjyK/EQjTSWoIDgtUOCQhLRi/0Az8+SdWxQ5tp7U4L5eQCsqRyP7wqr1KdTCoInSz9Pvf/h8BvDPitc4OrSFzZHQPR0agEeTcnRDmuiVc85fmSYcEileyXm7SvuteJ23yEnokDmm8D0Ix1R6p0rqUuU6lwLfb+XdateGJkfjc96nryNb/tJnQs+05xehZd8JSEBNt/GjkXPdAWhcO7nJ+o5A/isgx9ExSMnzIXBA2H8UMKxC21w6Z//SFKzkoJWe7DYerYzV7Q/HV+lDPkBRlBpds9G4Mw/wefg8OzJxGRuOfw05lf6HJhzfQvtNa1B7tN9+apejgW8UfL9VOGY8oY/JfL8SFfoqGjtMXotWDR4iBCYIxx9DfXCCeWhS415Ql6eRv0yj77dEZi7Vy+zPH63iTc6HQrn8HYX4GAbMl3kIW4XP6UFjBaQJSmJ55gqDqXI+JuR3R6YIl4XPg4G3Kta1ksCX8/2S5OT7RoLsYHpGtJgdaXs/Cy/ci+ktU8ZMKMnIaShQ/OTlcKTBeis8j9vD9h4abJPl5PeoZRL7kGCagDqthrnEM3WYlH7Wqf2bITvsRi9XNpLAOMoz2L2UvBTh+CXC571DG7qEMInItJfNgFHhc+nyH1qm3T51naScw4FzGvyW65ATmaON70rDyAio8/sWGRMScrKaIW/x9VCSmm0z2y0UdLTh/LYMLhXudwfyM3Ntk/ptKnmol1xnOiSEZSO9XIZsFJPjbgPOyDn/LGSLWfW+iibvL5S13yau8w6ZLEyZ7ystg1d5p0rqUfU6X0Lv/UlolatPzbRK6nxyaA8/pyakfR+tsJ3YyjNB/e8Fqf/rJntoQtbsb/0esHz4/BMUsxy02jcGKQtOC58bZqgM991jchN+k6ayhGbvK/NdaR+CJhx5QvlcaMydhGxa06YX86JITq9lztkEOe8dDGzW5H0k7XciWtFK2u8X4bd8vGxrY7s8F5lU9hDAkQb+nnDM+8jvJnvM+qSyZbZQj0nUZ7irM/mgd9kRV0Yr0A8iO+rzkeA+jiC7NThvUeCjpq7Vrh+kTT/qkHCTzyMboAvD57Fo+RM0uC0SPqc7nKWppTdsKAymrpUW+O4hpGWmiTSfNBb4FqGWfvZolMwDtAxyazhvDLUwW6ui2Xpim5O1h7kGdQzHhZf3gPTW5DOeGZmAnIg6sz1JCSvhhUme6fPAJuHzEmXPhVpazy9Sn5Pt47C/h011powZke3PT5C5ybHIoeATaqk016UWKi8dgu0NavZfi4XrvkV5iuD3ybGVQ5r493Ku8zYhhBKa1LyfOmdB1Hknv12dvXub3pPZUCicrPbpTIKGhxxtcNi/OCm7XWo2wI1ssbZFqyd7IKG7bpKWKbtwcKGFVKLh/KfI18ptBjyZ+n8l1Gk+Gep+EU3ajIVylkL2czuiSCDZ7wtt+5u4TtFKzttl7beJ6xyFBu9GwkjpexD+L32nSupR9To7ovd+EhLgx6W2sWXXaeK59OjDc46ZPvy2E6m9zxNQHzp9K88kHP9u6v9LqBcqFqVJ/xYah6a8J9R9RMmWhEY7AylEnkYp4f8a2uWHaGytE5wL6jNj+C3PQQ7bu5Hjr0BBHxL2nU5G6KM4hGASRvCwcOwqbWgv74e2WhfOEGVsG4+c/Qu3NrbdxZFQ/iDqX1cJ205IS/sBGrtbCp2IhNJBBd9nBeHsZK4pQRg5CX9OzTn6d+HzZ9lr5ZzbtNDdbTbCxyNNzE9cgfkxs0FogD8BaXteRINw1m7sG8Aoq2X4SYzoG3EncIKZ3YWiTmwf9i+NtK4NSdnLOHCM1WdOmgaF3Xo0/D8UNVDQMtpgNIAORcsHGyPh4BUklPbw3kUNeBMPtrMF9ToKCYhnZvb/BPiKux/usts9u6CYsiQBRfwMCfvnoRnyh6nvPkXmDP/NOzHBZSd7FCE2JeUZ9RI7ytGhfl9DHcC6qOOdifIUwaCZepbHqYUUepOwvIPa3rroN16S+t/rZPQCL49msVtSW+X4RdG9J5jC7/2SmnfvSBRqKLGlrZJYYjTVspo1DFwe6jIpfMxrM47au/5x/ze1xBHZcgo91CuyOHq2WSZn3Qv1eII2ZChz9+dQaKtG3ye2/QeRY9vfxHVeD/Z530O/6SD0vC9GAlaV9ptLxrZvEBLaLjezB+jpiQ3l7wFUf6eKqHKd45EyY5jXbO37gteC/e65wE0eRtM07v4pMCREUFkC/dbPh/408X/o7TOZhtR9e89QVXNT3b494TlgW1NK9S2o2azvi0JTVvLHQTa6D4fPi4S/b4ZtudRxDd9nU4rq65EwvAp6HrsBR5nZVq6kFKu4+2NFfQjqzzZEKYVHUmu/6QhI2yFBNeFTtAKW9G2PmNlTSMl2iWcivqTq3DAxVTjkcXdfMXPa4cjc8reNnkW7cflHbYYmKJdSHx51JDJnfMHM9kPC8J3U2tIgpIj4eYVLPYJs9hOfjxuQ8rCKL1Vv+D2K8nNEeqeZHYme88qmKFl5zNP01do1M2nT7OYT8hNLLEttKfxHSDs6FGkJhqJZ1sdI4HyFsCRUcq2vomWixwi2VGH/yZTPbpNZ8ySkJUjPpG9GS6NLhWMnAF8Nn08jaESRAPVB+PwxOUs+qeuNIhXEveC40eR4eZJaDkfC+PXoJVko7NsDTR6gQpKACvXYiNQSci/awUYE+zM0SMyZ+X5RwowQTSaS2f72qHN8CXWAR4V7PTp8nyw7T4Nsui9P/eaFy3/Ie31Y+JzEfhyBhP1zUue8hcLVgDTSiY3zVsC9Fe59j1D34dQShPwVaaISm7/SyAhUSFCRansNA5ejwS9vOyFsvynbUs+l0EO9wrN5nXyN8BYEcyZkPrFNzrnbNHN9WtReZ8r6FSn7uSbPLW2/JednNX2vkZ8w4d9V3oM21anqdcYWtc12bcj04JLQtl5F2qemrlvlmdDTB+JPSFv7BfCfgrJ/TpMRZ9DELNFe35LafxgVbeXb+HwfRCtY6b5qFqRBTXxTJiF76YMJ42VOOcNLtkUo0FqGMpZGzuPPUtM47obigyfHLEkmMVXYfzwaByq13/7ekJJtB7SSMrjBMUsik7mtyVnlKii7TOP7BfWmp5P9M8L/zWqEJ+TVD63SOfmr53WrmU09u079aA1u/k1yjKAJDgmp//dEWrnkpl9Bno/QQiaxBnVqmD0mvHyzl5z/GsE2J7x824XPywIfhs/3UmA/irSKt5Q1XEqWw9GkYVx4YdOOhnuhGICNyp2LXjgB0MDmOfX9/pntgNDZvAFc3Mvfa51Q1jfD/8ujpf8kYcBVaAn6TWr2xFWX//6Uus53w76fUW83OpaaXfPLwPrhcyWTG6TJ+VnO/v9DnryQyhhH/eAymDC5Cv+XZjWjwAYY2cq+Sb6TxROZbSwaNEaH7fOw7/Fw/Dtl7TccV2T3fEb4jZZN7avLuoeW+r6Wc26d+URJHY5DE6pbQluoG3B70Sbr7OVyvt+lwfYDtIowpqj9psppaOtdsZ5V34OLKHmn2nSdkfQik1hvNxSTdB8kuH2BJgdDyfHnyDm3Sj+TnXzchuzDr0AT1DzHy9XQhLYpE7hwbsPQlH30/NZA/WJi0zsLijj0CTnKKeTXkyi4SgXUJupRyT8jPItTqTlCJhOWwnCGTbTfW1Ef8jQFfj3dsCEb7W2RnHAU8B1STsyUC8KTkBIwURi0lB0RjSE9HCORycerNFbQTN6auf9uS6hxMprRHIxsmRzZsfwBzSgPRlqta1zLifOgl/ztVBnXUSHDTxN1GksIwN3LezoVaaOeRZ3SIq6wOjsh56/VTRnyjgZ+TX7w6P8hb9pp0Cy/bnnY3WcP13oWLSecn6nDrqHsj4Fj3P2yTDDxVZDWYL7UOfMgLeKjnhMAveSeV0WDZZJJL1PdySHNXsp8N4laAPRj0IBSmlGvQn3mR85zq1PLavRnD8s6FYP9z4BsazfJlG1Isz46/H8/0oLeZGbXoFWLw5Agu42HZAwFdZ2IBM/nM/uXRJ7lM5gSS1zj7ieH37FHYonUeYXB+81sTyRsnUh+27sWCZYjC+r8IyS4/TD1HBZGguPF7n5eMHf5zBtkdrMKGeGsQtY9U5Kb5TwTaiqESBrp7jM3uo/UsW8B+3h9yKheYwVZ+VLfT48mHokpyiBqv0UyIXkSvft17TeUsRlaGp075xKT37mSelZ5D0C/z84UvFNtus4iaIC+mYIMlX2Bme2DVjymR3aWZwO/z74/mXMK+5mC86ZFQtP64W+SoGlZpK2+C9nLVg6VV5VWx7dQxnxI2FmT+nf3LCRYbYjGun9lztsMOMEzSW7MbG00AdkR/f7Xu/uOOdfdEGWQvcdlurAg0uxvSC1r7GQBp9E7EK53JupHp7GcxFReS7oxCimuylgItd/jUf96OtLGbohCi/6+QhmllIXbTCh6V0yhZJPkFOln9gEhOUUwj5zfa+H4Jo874f+/UsHczSsmADKzw5Fi7DjqZcEDgePc/agq5YSyTkdjcuMQtP0x22hiFjA9slnMdUgIx0yO9tCgjOFFWy/q1NDTteL504Yf9BRg1dT+X1Bz0Ms6KNUlEkH2jg23VJmFy+Fo1rtI9r7CccnMvNQRq8I9P4AElvWQGUOvZmrIY/T98Nv9AQnHk7fUcYXmHm1qm1VDwg1FcahB2py3w7P8BGWcK7vOcygFanb/T6lphFuOjJAq1ylYXqLCCgtaRlwlZ/9gaiY5f6bAQx0NFHeHcyZHNkB2eo9lyt0c2eUejDS96ZBbr5OfNGay+USFZ1JJe93EMy7sQ0L7vRfZOE4btnXRAPANZFf5MHBhQRlPIc3Ugu2qd8G1Fk4/8+x3bbzOSwVb27VqaFL1KySIfhSe5wZIy/koSt/ajuvMiBIdrEDQNqPJzi/DdcaH7dGwb/o+/C1bGt9CGT0iZqBVxO+EZ7kV6pt3QuPBouHzk4SVuwblro1sUycRzN9S311PrZ96A9krX4607MuGegxBWs4ns31CqOOvkWD7Geo/fxS+e5+CxFQVn0lTUYb66B0pfVeQY3E6OcW48PxWJ5WcgnKNb6/MxgrqZUhGejX1O7+KwuY2tTpNhaQlffJyteEhzBwe/soocHL6u9uouNRXco0hVMhO1I6OosI1NirZGmVYO5Se4bEaLocjp6LNs/eF7K6fDJ8rCyQF91No81xy7uTQclTIqEeOuQcSQH8SXtzVirYm6jWJkgghBW15NRrE4M05fq/QMZ0TfpddkV3aRODHqePaFRnhIzTTXqTBdh216Bu3kdPxoUF7nZyy16EWmWNEwfZv2pARLhx/RngmS6f21ZlPVCijNL5qk8+4TBAeRcq2n5rD3DpoIFsNTWjfatR+KbH1budGL8NGduuGhKXrw3v3MJp0zp45Znng08y+1QhmB1X6GSTsHketf04myH+kBZ+KvmybFcvoETGD2kTaqbfn/CL7f6asPAH1JZQIIjnmO+G7oeH53oOE8VL/DGT6ck+49mNoMv2VTB0q5SIoeSaVogx1ekPjzLWN2gOa4JxDjolYZnuePrI9R8q5yrHme9PGuypqRPDAvt/liftEg8POAY4PS68P0dP04eHcs3pyIxL2er0kVJXgaTyYnsv77u5Xu/t/Ss7/L/UZ1q5BIbp+ihrJIakCDzGz35O/HH42cKqZ7RH+X8jMNkAd8bCwb2vgO+7+qJl5qhqjSHnml/AEymbzbMl9HQ084+7nBxODW1H4nA/NbEvUgZRl1DsYpbm9LHVfD4ZyBofPTn4GHycV9aBBHU9NHVsWISQ557so61nd721meIlpjrufZcokeAAaoEHPfkd3vzZ1XFsiI6D7et0bZO8ys3cpz7h0K3BOMLN4IOxbEzmN3hrqW+ilbmYfk58Rbm+Cl3PZMqBr+e9gtBox0syy5hMHldxHwhzAzqaMkXlL8vtWLKcqi6KBM+FB9P6MD989gNqvUZ+ZK91+70YC/wttrlsedUvOKWaletSIbmI40n6t6+4PNTjmJTRBSpP8Tm9TrZ85Fvmc/IRatJcNkPJiEFr2HYjkRczYGGkW/4jGlEKCKcpQNPl7gppZ1WvBVOGR1OHfQJPwi8O5hyKlwEzUxov3Uf/7LFIUrBz2/wr91nt5LQpRlv2BEabseTMip74lkaDdw0SjAVWjDLWEme0OXOqZLK5NsAHFUSPOQMlcli2px/3Almb2HDJxO99biCgRooXh7pPcfZyZzR/G1ZHufk9vy21EVwnCKMHDp2Z2D7WED/e7ezp0zCXhb57NS6lgkyKvw2o7ZbZ7wDQhvEwRy1ELYbMDeibfMLONUYdxSPpgV6ihB8jg7n80sy8h4WRGNMOdiGyW/hwOm5PWU9QeCvzRzHJtnt09CXuSDS23CrXQcn8I5RxtZru6+5gG11qKWvichMVQ256d4lSNVVgp/DX0O6Q7/ESDdHyyo9UwYWZ2NTJF2MQVsinvmB2QdurazP5tkGapWdvWZcxsGPXh2o539ye8mk3XHmggSmKUggb2m6me5vIBNGCeHP5PntuPUcYukJ11Ixw40ZVedUgQYgdTC2l2mwf1QAWWpza5yQ4AbRvEUtwPnGhmP3D3N1GbHYTa1b1oGXl9FIJvkwZlnIkUBAuS/85VVRA0pDeTwjZdL5c2TkgWKBMk3P0T5MyVZjFkRpN8LmNnFPnln6l9L4R3bz8z26K4CvW2tF3EHWjl6tDwvyNBf1/khF2o6AkUCagzoJWrhHWRQizhRST0PoHe15dRO/yJmb2CtMCvhWMXDsfuY2ZHUOvvTnf3t6A4nGFoB1X4N+rPHkaC4UnBFnc1ZMLRLk4LZV8O/MXdq9gvp/kKUrQkZPu3p4Gvmtn0jcajwNoo4tTX0ETiSDO7Ea1m3uAhHG4T3IAUGqeY0rA/iJwvZzWz3d39gibLK6YvVNktqLBnQsv+v0cv0kSk1r4Z+FU4ptES7iI0Z39aaUmo6nEF5+fa7pHywqQ++UKeneY4SjKshf9nRDZlt6CO4PHM9g0kkM+MPHzXAmbN1Ot2Wk9RW2jznDquMLQcFTLqUWLugTQSldtFwT0Np4IHMy2GCUMTvY+QPe3Z5Hs7txwZIXXOeBoHLv9Wk2UthTr/bWjSNIY22j132wb8EwlbRc/tKUKsbWrh/54MbWARFAniBwVlNLLz7rH83MJ9jKBi2Mg2Xy/Z7iKVebLFsuequlUoa7oq/QyNw4P+KbxvR+Rsp4V3tE9MTqhgP1mhjNKIGeG4htEc0IQ1ibeeZJX9bdg3EtghHPdlNJasnip3LWQnnOef8UV4fsn564V7bpi0q03PdRApvwoaRBlqw3XmCGU+HN7LJ5EipqopXlk0iPmojd/p4+4iZVJCKjxaeB92QP3e50ghdDTNhWt7m1oCrV1CG5gOTbiaysyXvae8rauiRmQJnvKHoVSWg7yC53Pq3MKAz2We3KnjngS+7u6vVK953fkfI+/KFzL7F0G5tz18LuIyNOu+HgmGa7n7E8GU5HJ3XyiUeR6yn7qCfG3kISh0zssF9V0PDWqXoef+F+TUsRbqtEo1S2a2UdH3HjQEZvYaWvK/2xTx4hB3v9LMlkVawBFoiT2x//JMOSeY2cFI6N0DzSC/iZaTj0fmHsci+7WG99wMpkDryfLWC+4+IfP9O6hDLUs+UnSNmZFZxM5IuH0DPYOL3P2pdkRGSJ3zBXCau++X2X8kinKxSogK8T008Zo+fZy7VzWXKfVQN7OV0PJw2uv+WG+8hJmctz/S6EyoaD7RNoLH/A+QLfPh7v6umQ1B5iYvNVGOIYe+ZZBQMAoJFuOo0H7L+hBvYPrSG8xsOLCvS/ver4T371zgTs8kDmqynEmUa/eN6hE3PqLkdzKze1E84H0y+89A78W6qX0zIfOog9Dk6JfuflNZPZql6jhYoZyGETOqRHMI485NSABKJ8j4MhJWd0CrHv8PTU4mJ7Mws5+jEJB1GvXQjy6Lxtl3w77/Is1xXtKuFd19vbBvNSRQLh+KGwWcVGX8C+cvjJJbeWZ/XZShdhLqvDtaQZoF+XGc6+43F5wzCfU7ySrtYDQpT1aU5kFmpIaiRiQJNeraTegH33D3ushOZvYVND7/AviSu1eyQghj3NLu/oqZXYScrg8Lz3WUu89SpZy8uubS7AykLzfU6HdE2sdRaCZ3OxJoNmrnLICad+T2SIs6R9i/BBW0AE3Uo2Gc1ibK2BA11C+A81L7jwGuTP3/PgV505FwWZpXnTY5YlW4zqnIfupWpOlJ4k8m6SE/JidBSE45R4W2kmjAPgF+F767klTClBbqOi0VHF1ov6PVvGjG/yTwedjXcmSE1DkObJyzfymksT8otKtjwv8nog72A+DXTV6rHY45W6FJ4btIC/UfpHmaO3z/UsFW5D39D4LGn4xDYHZLnbN6eA6PIE1YshoxDGWtasfv35b224Z6FD6TvOfTh3VZnpBivYUyNqq6tet3Qv34R8hu9Xy0UvhMeC+SeOODkDnQa6HN7kKTXvJNPof1qeA0XlJGYRQRKkRzQMLv2dTHPE5MEu5BmuJHkFC2XOYaVxDyCKT2zUdOcg2qJe0aivr4W8N1j0Tj+OfA9ys+k445lCJTkp1DG5oUnvl5DTaneDUpvVrdVApltKL7E2TWMAmFYq16D89QE+jfISTzQoL6O00+jzMo0ZB3m43wm+imz0YP8F5vMoZtk9yKzDHmQC/TB2hWOwfSMLaDUtu9oEGd4CGFsinu7x5oZnaAu99hZvOigXpM6vSzqHeyGU9xeuhhKK30EeQ7Gr4f/rbsiBVmiPtQszt9CjjDgx1WYH8kCC+Msp0l9VkANd4DkHlMo2tMi4S/E5EAujzqPNMOgrchO+OVyb/nqyre0h9p7OiymSlVN+H6Q9vhaBW0X5sgu6ulqf221yK7sG3d/dlw7DLoOVyTKaMsHvTrqBPLsjrSwu+JolX83cx+hrTHL5riPJatZFSmit2zyRnydBTqJ4mVvQFabt0GTRJ7axP+HjUtVZ6NfB7HowxTRwStQ8LNSAtSGTObCyXOyWrdp6di+w3HHEiOrXczdWlA1WfSH8yLHPN6jVezW22GKv3My+g93odajPUrUJue1sy+jXwj5kX9yp9aGf+sgdNuqM/W4e9dOac2y0uk0u+mrj83tQxtW7n70yYH7Hdcq4ATkSnWrUjA2dVTtqTuPsnMTgQecWlqf5N3cXffIVxvOjQO/B9aRl8aeNHMjkUaxdNR0ovFqMVqTlgMjf+EMg5396Mz93MIMtu8qMIz6ZhDqbtPNLNHwnU+R6aQ86KJ2CRqgQhWRCYh91Mu7zSzurUx0kwn0T0uQyFBe/gtFXAiWgn4CMkId4T9G5IKpGCNAxFM7hvdfe/Sq/XlzKQXM5mL0WA/FpkBHIAG5N5kNSvTCH+OjPOnoWeswBfaeE+ltntoprtN+LwMEv5OR4LUGU1ca18kHOemmcxeG3rEK164bKtYjyHhmbZkh0Uto95FNJjRoZd90Vaef8W6vEmOZh9pKCdSHB4s2UrtGtHLvAUS9D5E2tg6W2HkuHh3aMOvhO1zpDmZPXVMaTxoFNfyA2SCtDFaevx1al/bwgBR8E5Swe6ZCln3+nMjZV9JfR+yKJrYVi1nHSRovo4GjpdDmxpLSZznVBlb0yZb727Z6IPMkyXXW5CCTJgl51bp5xtpCb8efuePkSA8Rxvupa3ZESvce8PQklTItknFrLIl9fg9tZXk8an3cTvkYA5yxn0NaX0XC+/q91H4xhPDMR+Tn953SUqyg1KLi/4FMis8NbX9GTkF391H78usSKBNnJZHohW9LyOzyMtJZclF2tbLyMRoblB2NoXyWOpTKA8O7eCF8PdOZM87cwv3szoSpmdN7duKWqbezZDitKWx3d27SxBO3exS4Qe9CIUfGUMq1l3FMj5Cs5KtyBl8kYCRxBnMDmKftFL/zHUWKdpSjSq5/qEokw7IE/PVJq51HRJg/oeWkLLLlhs12LKCccOtYj0Kl7mauJ9xaMnZ0ZLW2PQWjik09wgv+zRVr1lQTumSWpvay5vhWleh5cOGwfQpTixRKR40JYHLkWNiEgf1AUKyDzRJea/JeysShD8hZ0IT3sdksJxI4wFqYur/PPOJXpsnoVWjzcg4QyGN+erZewvPZnQT5d+JBkqjFod1PuQsuFuV9osmzb/N2X8kFeN/d9tGT9OWF1AUjaNpIa5oznVWRROxPIflqn1eaT9DY4ExsVc+iZ7C/+StyXtqyWm34jUqCX3UMj+CVqwuopZ17bmw/2RKBNQK9XkBjWfjqO/zliGknqda0q7rCcmuMuXvAdxYUocR9KNDabjmBmiCk9z3XwmTjdQxb5Cf5vpsUklCkEP9TKn/Z0eJrRITi2T8zf7vYfsjOeNkH7W/tiUR6jbTiIQXkMfuvGg2szEaXEoxs9mRM8UsqNGF3XYlsiNKL2FOl1PEwkgT1xa8mpOKUwv7tilwdfj8Jvlh1xrxburcvLrkLgea2Zqpf5cmxBtGy30gp4W9kC11FQZTsMxVsQyQbSxIi3k4tVBFaYbR2NxjEOoAVkGz41Z4DGnc98ns3482hoxCy3+Xu/sHZQe6+62EOL05bE2FeNCuHuUkZGoxW9g3+R0xs3/TvjBAXvDdGDQBfjmzf2nU4YImxZuj1YU0W6DJHwXmE1eb2d7ufl5ZJU3pQu9399PNbHo0kK+AQjt+x91vDIdeCxwRzDoAPDgsHkt57OU0K6O+yYPz4gwu85NDkOB3L+Xtd2m08pLlQjRRGnB4781cmuVstKqyJ70LeTgNUkDk9jNWHnbus/Ddtwsu4+SHDG3EINrbL+VRNbTkWijeMmhidhMyM5tIzQTv4FDOedTCun6GTOR+VbE+CxL6gQxJtkZcIcD2C+/WEuGaz3t9+Lwb0e+0BrV0yusgxcQwM9s2OdAzpnUe4qUHh9L93H1sxbr3iuBkvgQa+w5Evgl5TqyzoueTbZ+7U29eeRn1+RVmQpOTMlOv1ZEJy/Bm6l9EgbkY7n4kmixt7e6vt3yx/pDcm5DwD0IhN8ail+S/aKloS1Iq/ZIyhiP7n/FocJgOLfc+TSorDG3IHtPEfRWmAEapCi9A3uefEkLOoNntS/38G/yH1LJSav/2yFO7ShktL3OF45dHs/lES9Yjox7l5h7PE5bzW3wuG1Li6NLHv8v+1DLuNdQaETRHaEKQt2w/mKAdCf8Pol5zP39om+ulvm9LGCCKNcKlGeGokHWPNphPoMlTogXfHgnnX0YD8n2p42ZH9uJjQ1t7DZkn/IeK/VUo5x1qq1PPUNOeLRfacWn7RZOE7+bs34mQ5nogbqG9nY00iX3ilEcLmTBTZTTsZ+iMlrCtTrsl1xpOExp6CrJtUpBVtkK5DyLnwqxG+LfAf5oop8jMpanVAnLSabf52Z9KBUd2NF69Qs801w5cljqu1Amun9rUOmjVPs9c7PFwTMuBCCZfr79vsOTm76VJwTenjPeQBugQUrZWSJB5L/X/gmHQeSY86PvDgx9FzvJVC/fUIwVw2L8XCjZOeFEeR5roI1LnnkYf2MKV1PeTdCeS2r80JfZRqWNPpsVlrlDOf8PLOg7Ff/wYTZReBY4Jx2xUsv0QaSAqxVUsqMvCoc0chbR9VyGbtAWpaDvd4vVfoonICFSMB420H/uFz7OGZzsmvBO7tFDfyamyU/saeqhTwe45HPcdJHy+F7a7CPb14ftK5hMldU/Ht/4LcEL4vCg56Z6RQ+OBBBOVXjyrm4Gh4fNZaED/IdL2P1+l/VJi693X7bOP2ny/2LmicadHvO4myyjtZ6gYizznvFnIWaovOefP4T2+O7zzabOFU9vwzLomikiqTt9CY+hENI79Mjzzib15L1usS6UoQ224ztIU+FAhReAmSLN7eujbEmXRRCQIL5I6vleCMJIZPiVjvpjdmrivInOxpK/cFikX90BmpE3b9idbV8URDjHiXvVMFpJs7D0z+zpaol4cOdi8EpZEX0J2smu4+8hMGSsibc4sqX0zUZ895mGayx5T5Z4eQ0LbZel4dma2CnCLu+d57Cfnzoga4Wfh/yHAg57yJDazx1GInzFm9gQFy3ruvnKF+o5CSy3LeirunpmdjJ71chXKmB51Aj+h5zLXL704Q026nA/QstpDSLhe3903Dl6pw9190QplPIGE8ZmQ1qxu2ajKMwnlfIGSIuR5Rr/tTcS47g+sYjxoUzrnTV1xqXdBWs9V0CRmf3dfOcT33Qu1i91csUG/jTSNj1jPVNm3IBOfD5F28z4qYgUZ4ayWde/6Rm3IlOLzRHc/I7P/p2hisHSFOryM2u6tSBPxY3e/MfQhd7j7XFXvpwphCXY2dx8RosNcgBxOn0Va5wXRgPYqPaMRrBzKMBT39IBwPEibchwSfLqno6+Imb0F7OPNZ0qsUnb6NxyM7I7LMmEWlZf0M4W/U5N1XBctXX8XCTuVI2WY2YiCr93dN2m2Ppnyh5ccMiT1uTAyhbvv1kpd0pjZ11BWsonU+pAj3f2WJsoY7O6PtliPE5Fs8St6Rhm62N3bkk47Oy6Z2WhgAw8mmSF60+vJ+GRms5AyCUHjYVl84NddsZ6XR5Pszwjme+E9+g3wU7SylWQXzMXdzy/6PnVfHwJruvuzQQ5Y191HBTPOS9x9KVMM5IJLVR+Tu81G+CVywrAge+GXUDriochm9C9osE3sfKdBGpm7gd+Z0pWOh8k//m+RdmkyQeA9L2x9RV4KYNAMavaiEz2TrAFp7wZTs98BaScTwbgdA8YvwnVuNbM7w761kTZs20YnpfFqdlhVmIaa3dkQpA0G2ZA3nEBkSJ7JIcimc0yTdUjoWDic3uDu9wRh+ED0vDZFg8K6Xh9OazZqYYO2AK5298+CbfCfTWlf/4HaRKJZAP2uuyK7xmyq7MHUp8reuIl6F9k9f4KExM/M7AqUYOSOzDHHA38yBZe/B/1m6yOzo6IUzWnOA/6GBMkvqNnKr41MrAAws980ug3UJp4HbiqaWJuC+Y8npDl193fQM0y+P6JKhYOgexINbL0HKH1p5/ou9e9zMoHL7nNq/htFtEVYDxPrXZCWa1kk1O2OTOsq48FWta/wktTrZnZd6t9GobsGUQuL1WtCyLon3X2Su99sZk/TQhIs4OEQfuwvSOjqjc9Qo3Ta74Ry2yIIozaaZk56ttf0MTOF7VFXmDVQKuok3Oi0wO5mloRLnA3AzL6JZI1E3jrIzHZH4f9GohWpE9z989ZvCai3N38LOVeOQnJTMtFvnw9BM+rjvt4oCcMSPj8G7OQZNT7SYr2F7IuS5d3/oCXiMWHfCqkyj0LZZbLX+gkhGUOb7qkwBXCTZbWckKDidT5CyyhXIee7owi2zf3cHv6LHI+uQUJQknJxXZoMqN/bZ0cHw+GU1KstkREoCVyOonL8NPsMkXPE6+FzYarsgms3ZfccjpsZabj/iTrL/yEtS/rdLjSfqPhctkOTwq+m9v2QejOMJ5DW+3O02jA6fP4wvPcTkYlHURhHC/dROf1og3IKbb0H4kYf2rnS5oQabajP15BQMQGNWXsgzVsPT/8my50HTeBaSprRYh1aCt2VKWtGeibB+oJ634IbKEhpXuEaS4U+5VU0Sb2InKRDJWX0V5ShSVRLkTxbaF/ZcJrjkHz0Usn2XxRtY1bUJ09CSoEkRXZuaMAW7qvIXOy/bW+j7S6wlzddWdgIDXOR7I+ONFRJZpiZkAfwCcjTdg9SIUHCMaPJyVqGUvq2zbkEaalHUYutu1H4Qd9By37NlFUWG7ktg2HZdcIxp9M4tu8MSIj4B7K/uz+9ZY6dHpmmbIlCt6S3DamQUa9d99TgvBH0s6NLhTrtgYSn4UhbtDuyoZxIyG6FUpJuk3PuNqTCKiGTh89QZ/ho0n5QhIx/o0nRotlniGbjE8Ln16jFdnwW2C58Xhb4sOA+XqKFjHDkZ927mpKwc238HR5Dk5G0sPxVpFncBUV8uY2S0I9IoK4cX7tBGX1i693JjT62c01dZ2Fy7CzRJKU/7P9fRkLFYaRCCNKCIExjwacujng//Y6NQnetQCp0V4VylqSWoOPz1D05Wh1KjmuLwgiNp1shbf9EtLJ2WPp9Lzj3XoJCILP/DNooyFFdEK4UTrPgOh9Qc+idNjz/rzeqRxvuaw3C5AP18zciO+MHSTkHIqfKC8L+B5Aje9NZcPvtZSi56crCBiUaViQ8TZtzjWmpT0owIe9lQXbHlYPhV7y/himAmyynTBBuy2BIhZSEpGIf53x3ARJgh6Ol8WPSW+q4zVGEiaIg9NMAc2bKX7TqS4cE7d+GMtOxIyvHRQ7lDKcXji59sVEhMgIVElSk9jUMXI40momQm37ftkPmLlCSKruPnsGMyBzjOjQpeCnsvwR19GPIJCLpgzpMIjUYpPYPBl4On9ehJO01MoW4K5xnme+S9vss9Y4ude0XmZMlKya7oOXK6ZD5yuOdbrO9fL4jCrbS5DRNXKfldLhVf6cG505ApjhbkYpFTGuCcEuCT5t/x3HkOKuFvqgZB6rrwzs9TaYvmpS8b6nrtW3lNPQ1vwi/06TQ31wGfKXgnH6JMhTa1zLIfHQuNC6vlvp/uXDMq8jmtu75IAViDwfgnOvkCdxLZL5vW5CBive+NW1KItRvla54Y6XCBiUa1qqdWmigP8w5blfCAN/me5sZzXLWIiVwNFlGmSBcOhhSoIFtV13Q7HGjCmU8i1YAFgmdzQzprU3P/VikcZmAJiD7I8HtbWCv/mzfbWxLpZERqJCgoonndw/SdI5FXsobIc3Mb8Ix0yInrVOAVVPn/oImvd1L6jKIkqx74bhS84k21ceBb+fsX5taEpDFKBlowrv0GTVP7rSn9cTQfvdCk+nc9ht+7yQ040XAUeHzwgSzsrg1fP6lJnkVyji2yu/U4Nx5UejQUci87xS0MvkpvReEWxJ82vx8/0p+6K7/AX9topz3yU+C9QUpcwNSUXJarPdaSIM+JtR1WHif1karPg8UnNsvUYZoHDY0+3+jcJqPklq1Q/3kXKn/50Gr55PQxCWJyvARitKR/D8JRU05r2jrxf2tgRQeiXJlFoKikzYmEeq3l6HJmy+0a6JAw0rjTm1pUrNPNHC/j0wolgjbj5FN4cF9cE8zIQeBFcmYaTRRRkMtbPi+cDCkgga2iboUCcLPUkHoKCqjjc/9JST0J7ElkxjNewN/78923cZ7eo6Q4S2z/6fUNMKvE1ZOMsdsQUZDiTQHOyMP599ktulQcoqkU/08fL6QNmTsy9Sj0O6ZJrLupc7pYT7Rxvp+jjTvaxLMksLnhwnmEEhrUaiRRRP5Rts71OIKT9bCZNsvJbbenW6z3bjRRvv/pJ8p+50qlLMBEhw/Cu/bKVX60pxyKsUR76fn3Ch01+k0ESsYjdcr5NxTstqXhGz7DMXm71UYNzSJeTKUeRVSFA3KHLNkUX9CG1YZKtZ1o4rb7eSH03TgX6ny6mQMaqYVk1J/8zYP23VFWxP3NR/yT8ma9pwFnBI+TyBfIbQUTa7q99vLUPHmZ0VG9aV2TWQ0rKkG/wUyp0i/BDegGd1NmTKOoRbn74vw+Q9tvqcZUOivbDzBU2gywDblGuEyx6e2aWCL6oKcGa4lY9KQc9ylwPf7uE2NRxOBM5AglaTEXYwmluW6aaNaYonSBBVhX2ng8nDc4uF33ZEGNtFI27EOWhacvFW8pyp2zz8mFRu8Qpm55hNt/B0+QsL6pPDsEq3ujYRBEEXM2KLV9hs+v9Go/VJi693pNtuNG220/6/6OzVRt9mQ4/b9oX6jmjz/dirEEe/n5z0LsulchV7kCaBxEqw30Ng2vGhr4jrPIaXAfAXHTE/OinLq+5ZXGdr87NcLz+wcJH/8CfmAOCGxV+q55gnCi5Rsk2gydm9JfS8hyBDUT3o2S94F2phEqNvCp/0R+ApStadjD15P8CA2s/mRavxVZCANgJl9gn4MQ4NBOmTRp6G8c9IXc/dDzOz3KIOZASPd/SPayxlIC7cHtTBq6yIhfDZgtxBCCQ/xk8M9fhP94Hen6jtbybVORJq6j5Dgn4Sm2RA55KwJHO3V0j63wi1IaHnbzN6kZ1zOxcPHnwAXm9nqSEDLHndBlYuFuMUrouxfgzJfj0a5yPcOcWC/huISr0t9GxkwuPtZIf7vAdRC2o0CdnT3a8P/B6OlqpFm9kbYtwAaWA9KFXccWj3YDwm/myBt0qUopXJyzRepD9s3GTNbED3nQahjzYaaqxJ+6pcoOsRpqX3nmtlDaFA6z93PLiskvEubodBt30ad+N+RjWLLoZoyOJqITIcmGYbe2WcnH+A+okpBZjZDqPPyodyn0G8wGk0wRiP/iNz2G9rEg2jSd6vXYrG/gEIbRTJ4e9PhVvqdmqjbOKQAOjOEB9u9ySIOBW42sxWQ6dL+4fNaaDzod9z9Y7Sc3Vv2B0aY2TNokvs3pJl9C02432m9loBWTkd7QT4DV4jQHjFxK6TTXos+CAloZrOjfm/xcO0XkaZ3HBSG03RqIe0aUiYzmJkjc5zk/9OR6dy7vboh1W9TV36E9P4XUB8HkufOMrMlqQ+VeSAa16rT3zOTkllAqV0TcsjZM+fc3ZEAdgQVZpvIxrjPQ8qE+8hbot6coCmgjR7fFDs+tU0DS7FG+BoUSeC40CgPSG+p43ZEg8QkJLyPS22VtCiUmHugCcdh4djtwzN9CU2Ojup0m+/ls7+a6qYBmyPB92DUUWadsT6kZnf3AbBc+Lwm8FzF+lyOzAQ2C7/dkFC/J/PafoMyWs4IF45v2nyihd+hXd7pyyMB6gOUUenO8Pl/yAZ6imq/U+LWjf0MCiV6fngPR6IJb9Me9W2ox4xoonsLEgIfT29NljUTsBsK03g6UjA9jCZ7K7epvr02a6Az6bR3RKt62fHvfWCHCvc6b+r/OvtqqmeWyzrTFZpxVihvLPn24GsRMgQjxcMvkLyU3POrSKnTMNte3tZtGuE5kY1ultnQDwYaoH+Wc8ydwHHuvkXFa90InGFmq5KjSfReZAJqwMdIKMzyGjVNwepIUAEN3mPRss9QJEhW0owCuPtDSBOR3ncDgJk9iTSwJ6NoDm9njqt8HdSpNtKgbA5s4uUZxY5HHdowl7agN/wZrRj8DmkG0ppIPJWFz93/bmavELJ2uXtTQeq7iCqJJYDSBBVQLXB5GRshQfZF9Pzfcfe7zWwi+l2Krp8wGrWb5zP7t0ACYVV+Q8h61MQ5veVoYE4zOxRpKaZPf+nVM2adAjwC/MCDVjJoeC5CoSJ/HMorbL8hy9OWDepyZJP3NtUQMnjuh7RQvRoL3P2Q1Oem+pmQBc6LjlGxvmlZPTInPIHszDvN6Ug5cwU1zV2v8JwkWCEZxNZI6/0BWlK/FviPZ7S6Fel18iRv7ypDKSHr50Xo2R6PJjyGQtMdClxkZq8TEvbkFQFcZmbJ+DsjcE5Kkz1Dxar8CClV0uW2wp3I5C/JVOdmNg2aUN0G7U0i1G2C8AOoQZ8c/k8a417UssJNS/6PM2OD/Y2YCS3N/40WX84S/gQcYWa7hpc4Se18ePgOSrJ7tbEuX0Od/YzUQoolOEHgLjI18JApx933LrjOaGrZ7oqYAzizBSEYtNxf2dwjCOeVU/52I+6+s5nNjCZNOwP/CuYPzwEHudIe719Sxonh48Nocvkssiv8fUir+X2qL2PORO39eR+1m2dRp1x1QtmOjHB4BfOJMsxsR+RQdEv4/zfI1OcpYFd3T0xNHkdan0fQZPYBtHo1A+rIqzIErYRNHjTdfayZHYbikZLan9t+zWwdFCVjAnIQfA29G0nUiSgIN6ZtglpCk/3Mk5n/f4zGpd5kNJtMeI9/gJbLf+Pu75rZEJQI56VWym6SbyPN5L9aLSj0Dz9HqyggAe+k0CdOi0y7tkaa8FnM7AYkFN9UNs6006zBSzLvtZF9gRvdfWhm/0Nm9h0kkN5J4zZtyI8hMfO4KOeYKgqyZ4G7zGzTrPBvZl9CypCfufv9FcoCKQDvCCmVZ0A5IVYAvkRI3502KXX3cWY2v5l9F5m43tOg3Hx6q7rui43GBt0fEQyx0WzgjJxzzwJub+JaTh87aoXrXIc0p+8jQeN2pPX+kJoz30fI3rlPPb6RgHocxWYNLUeWQFqpWyjJloWcGFoKYUaJuQf9lEGwkxu1yAifUkss8VLB9mLq3EqBy0uufz9yFlocmcVchDTLx1PRvCKU03JGuDY9z5EEBzfkrzABrdj8G6VcTY57CDgkfB4X7n9GJFDt38T13ifEas7sXz8819L2iwa7U9HAltRlvlDnoZ1uo928heffI85tk2W0rZ8p6p+bKGN1pFx5JPQLydLysHQb7qfn+yo5WdZ6Uc5QtDJ8K5rYHRnGmc/zxoDQtx2JEt+MRyuHPd6z1PH9btbQhmfyNCFaSc53GyGzuP/Rx9kTkXncrxq14dB/Xl6xrOnQJHIdpLC7Hk3yf08qYyDtNCnt9A+Z8xAK7ZrCwxmPZu5JEOW7w77KGdRCY9+03fXPuc7wCts9oT5j6EOPbyTgLFHU0dKGyBKh/E9DpzWe+rioaU/3w1GorIsJzlLkpNUtudaXwotyErIT3yWzjaYfMgh2aqOPIyNUrMNQNHFdHAmOb1OLjrJjxTKupp8ywlWoy8fUslf+DrgsfB5MKvQc9YkK3gdWDJ9XQs42Va93fujrhiDN0zRICH4qXKO0/dIGW++pdaMNglo7+5mi/rmJMkYQYqxSb2O5bn/3e2gcO4tMCLJelPMycGjO/kNIJdRocO5iSJO8fYXrDKdC8iQUW72le2rDsx2X9FUNvl8U+Kgf6vFi0v+l6pUWhFcs+40y5b1NKuJRwTFtSSLUbaYReIldk7vfa2brohnGtkgD8jDwU3d/rIlLfQrsbmYjvHd2RJXwikskZrYGsBB96/F9JXJoKqIpU4MG5Nlw57EbemHWC1saR1EwykjMPb6BhG7PlDE90rJneQ9pzAYcfREZIbS/JYDr3f1jM5sFOal9Xnauu19sZmeGzw+b2aIovfJor+41XNnuuR+YgMyVQG0rsUf8MLUf1HZnDJ/fQI59TyLzrTmbuN5+SBi+k5ovxCC0WrQE1dpvO2y9p1b+iOxL925hLPgy3dXPrE5+pIk36P/6bI7iI29pZiPpGR1o64rlzIs0j1muIIyTwd77m+i9OcvdPzCzJYAx7n5ylYtUHbOR4DWYBtF0+olZaBCVJPgMzADMFD7ncUz4W2TK6O6+X0k9FkQKhEaMB+YvKSPN+SjHw0EFx7TNpLTrBGGYHI4pzz714fD3MSQEtMI06IV5qcWXs5CC0GiT7VjMbLC7P0gqHFw454Z21CHFi2gJb0ZgLzN7K3O9E5F2dT1aeLndvUdYmQachWyEP+jttShxuDOzZ1EnnL2fDUmFexlgvI404TciJ4XrXeF86jCzrZCmPQnJNRI41oOddzhmPiRwrRmOWQo9qxORQNijAwzhal5197TjyHHAoWY2D6n31swqvUve2O75EiQUP1VWRhu5CzjBzO5Cy6vbh/1LowxZCfchze1IFKv8BDNbBZl4/JeKhPa/TXiuy1EL5fh8E+23HbbeUyvtENRG0139zCfkT8aWJeMk3Q+8i1Z8WmUE8P/o6VD7/4D/hPfnViQgzYEE5A9QUpM5UISJdtKqQ1i7WNnM3s/Z/yDq0weRP0mDWl99e4Pv10bCdJkg/Dbqu14K/2ed6ZejuXY3CzDUzDZHJmh1Y7u774veuSFmdh1SiO0Qvp4LCd6V6SpBOERwuAi9rNlG5qTikZYJyxW5GWlM+pIbUDzXU8xsVmq2wLOa2e6uSA0Pm9kjyCThEndvyUmigEQDOxcSNtLavkQD25bYvhU5FM3wP2ihjDkodrg7C3mVTo/sJUFavmNQWtSBSGlkBDPbAzkBXUzNEWID4Oqg+Uq0nCchm/C5UceScAVyXjsaeMbdzw9xNG9Bz+9DM9vS3e8zs+PQsuMIJKSntfKVcffx6P2/yMzmRSYfP0Fagf7sq/ZBz257ZPf5etj/ddRnJOyPbNNAtpezAdshYbTQWTFNcMY73t2fJzXIB6faF6nWfg+jpq3+NdKu/ynUpb8cdwYq7RDUet3PmNm2mV2DgK/lKCquaqI+1yIn7UQ48LBScyxaGew3mtCwlnEjcmJbg5oT6Tpo8jwMJdx4DoUcHJ467x+Z/6c0bqaxUG7ITG2TogLc/T91J5mtj1ZKIBOTNygsBlMvfz0LnGhmN7rYO3X8INQ/VYkelLAcmtyDTO7qqhv+luVNqE5f2440syGv65uQRnJRMtlLwjGrItu5vHR/XxBSnabKnB/NBBsayffxPZXasSAt3DFIc5AIAxu36frT5ezbmQaxlmlDfsTnAwAASq9JREFUbN8m6vYpyh52at5WsYzhlDjc0Q8ZBLttQwPCz3L2/x8hDXP4/y1qtq1pW8LF0Cz8f8A6Yd83kGZhLRTya0SqjFLbuybq3jG7ZyRwfwOYp+Jxc7fhmoVxS6fG9jsQt97+TjnjWK8dlVNlzo5WNsaGuryGFB//adT3d/tW4Rk5NTkg3ZctCnzSB/VpSxzxFuuwSJWtifKWQw7Pn6GESl/NfL9ZGAMaPf8HQ9+9Sth2QhrdDwhpx9t8/w3zJjRTjoUTu4IQy25VT2VmyjnmAWR3dST52qczUaiURAP7NEEDCyQa2H7DlPFuaXd/xcwuQo4Kh5nZwigL1SypYwchrdOPgG8hwfg84HxXJr2ya+0LvObuV4b/z0X21i8AW7v7MxXKGI1C9wzz1sKalWJmn6PJT7LEPh1aDZgWeNjdC2exoYzD0bLNzWgJOKvBPjEcNwt9m0GwqzDF8F3BpWVM718SeMrdZwj/jwXWcPdnzWwcsIq7v2hmayENzCwo+serZnYaClS+TyjnQXefw8zeAdbNXqvJ+jaye+53W2EzmwAs6+4vt+O4CtebhNK5vpPZvxlwqbvPW7X9tmLrPbVjZotTMyMa5cqm2GwZXdXPmNkmyIF1EOpTWw5h1st6/Aj4HvkxrrMav95e431gA3d/KtOXbYhW0JqxUa1yvcnXaGe5fYUpe+WNyHdgPCF7pbtPNLMFkGPwD9FY+kvPMUczs6fQmH2o11bKku/WQIqt5B2C8B4AP3L3B/rivtpBV5lGIHX2/EjN3ojlKRCWw5J+o+QUZ5nZda60fU9QsITr7UuoUdmOxWVHfIOZ3Ybsmo5BjfMIM7sKZWXLS86RsC8yfyC8/Dsi7e92yH6x8IV12d3MQeuxfavyCQrtNLlewdnhXKrHYa3kcBfup2tfxD6gaoKKssDlQ5BW4dVwbpI4YFpqy3FnI1vUYS3Ut5Ldcz/xGHJ8e7lNx+USBlIP24umNKUJ0yDNeOKEWNh+e2PrHRGm5CXnon5yUm23XYmUJ5WD9HdbP+Pu/6ZmqtERzOwg1G+chZatT0fvzYbIx6NqOYPd/dGCQ25BJkmJk6CH3/a3yESx3XSPFrEEM1serbYvhEyoJiBntCPN7J+o/34CRdIqUjwsipRqr2e/cPk5rWhmg1H/Y2j18dH23Uk91qYkQt0mCB8K/NHMfo1+lKx2733KheUiT8JpqHlH/r29VW9IZTuWoIXbDS0tjEXZ385DkRx+h5Ys1iy41leoDcrfAq5w98uD0H8n0u6lqdPAhn1JZIkXqt9i+3D3CWZ2FJqVnlnh+MX6vlYDkqoJKsoCl+8HXBKctuZCnSnItniiKQj9IGqODXla+X0r1LfU7rkfGYYmjkeQ76jxfpPHNeJnaLA4D9nQpX0DPkXhhqo63RXaelcsY2rlFJT4ZWNqiZuGoP7nZPKjL7QNUxSkU5EQ0o5kBMm530aCYTr5xInu3g7HtWbYE/ixK+Pez4DTgqb2cDTJrkqZL83+wAgzewZNIv+GBO63kFKo3XSLs1wVkuyVcwLfDc9/dmTmsAeyA74CJictqcNrvld3A8tQIB8EwffR5P/g6/BdYA93X78N95KU274kQu222Whlo6e9b7JNtpFCRt/3ImFtPjQ4p7dnkF1KnyanaPK+1qDAjgW9wE+GH/AqZHs4KFPGkoRkCQXXeQtYPXx+lBBIP5ybG0sQdRgXE4LB04bYvk08l1wbKxTke0yn2+NA3yhJUEGFwOVoknQA6khXTZ37HDI7GlGytS0Odj8+t9J+qJnjKlxvI2DaFutcaOvd6WfazVt4NzbI2b8h8F4/XP8KUskIcr6vnIwgdc4BYTw5BylXdqOWqOrAfn6+44GFw+e3gcHh85LA+02UU+pLg7Jc7oYiCZ2OhLyZelnveQhRExp8vxAwTX8+yxZ/gxWyYy49basL7dPRKvvI8FzXRmY3k7fMNddEqwAfoBwJ57f5ntqWRKjbbIQ3Kvre3f8T7Okm70qfHv7/KXoJEg3sau4+KdjPftuD3alVCGvWX5jZc2hpbri7v9XgmOmB73lBaDIzuxA19kfQDGxhd3/fzLYBfu/uKzU4b3ngZndfyMxeKqiqe5vsucJ1R6JZe7L0aGhGNxQJUKUh8qyWFjMXr6aNnOIws6vRSkShiYGZvQ2s7wV2+VMbVfqhZo6rcL3l0WDzTPh/c2Sr9xTwR3f/ouj8cE6hrbe7z12lLlMjplS6a7j7yMz+FYH7POXH0UfXfxEtN2dTLafrcb27L9pEmW+gtMrnZPbvCRzp7gu0UOWmCPe3vSvG+APAee5+hpltCVzcbNts1ZemQvmzofF4e4KZUXiXzgTedPdhrV6jvwn2099CK3qreDBHNLPtkIZ9cNH5HvIKZOSvHoehycMP0CrKkoRQrei3+azg3KYxsw9RavpnzewD5KcyKqxuXuLuS1Utq6tMIyoOHBsDv0ANv0eYsSAsP0R5cooqYc1axswKwyi5+4lVfrAgzJTF590HxQleGHU8ydLsaigVcSPmJYSB8jaZGlgtz/0SwOGen+d+JmSfmjAJafGHUwv0XUZWuM8z95gaqZqgokrg8iRcYZ4dVqeSXvQZVQXYqsdV4FykcX/GzL6KQl/djt7n2anZZRdRZusdaczdwO/M7AeuEH6J09tvqZlK9CXtTkYA6s9H5OwfQS3kX3/xb2Br1B+fi8LM7YjGpbwEGYV4sS/NjchWeDp6hlY9seIljkVmhquhVbSE69H4OqzZOncB16EVgUHAoNA3rIvMB67x6gm0GskH6yFnyNfQKuPJyMzyPeCedgvBgbYlEeoqjXBVgvZjsOd4a1YwqE+OexvZZD1hZrsAv0LhPoYiE4C2OMvlaFinQ1rPT4C30xrWvhY2coTypjWwFa+zOhp8X0Ia6mXDjHoYiqCxczuuU3D9yQ537l5qZzylYvUJKjZDWaXqElSY2eno93+JHDtXZKd+KYpB7NRWXgBw92mYQqnyPprZSkjjsQSwm7u/EWwz/+fuj1S8zgfAWkGz8QukHdzYzDZGq0SLVihjOeR/8CgytbielK23u3fE5n8gEDSuNyFFyOOofa+CBNAtvI+TuZgi9fzEU4luMt9vBZzh7gs3UeaFKDrMHzL7fwms3K6+vmJdkpCmn4f/v4tssJ9F2d+aEpJyfGmGI8XYrkhIdZT4Ji3cVF7NNLNXge+4+wOZ1ZUlgEfdfbaSIroOM5sDKT22ppY/YBBysN3VW8xdYIoAdSLwJ3d/JbX/M/T8RjY8uffXvBm4wJXZ9CwUSu1PyPFvVndft3JZA0EQDsbbjwYTh9WQ9mMnNPvI8iAyDShMTmFNhDVrN0FbOhw4x92vDgNu24QNa5BshJ6B1BMN7L+BY9x9XDtMDcxsBHCHux+R6UjWBS5z90VSx34XBZ7PS46yddm1Cuow2dyjt2VMSVh9gopl3X3asD9Pa5TgyF58bqSdfAB56M6HNAm/cPdmgqQPCML7cwmyEW34PprZFmgguRHZ9S8X2vkByOb02xWvNw7FGn/ZzK4H/uPux4W+6Bl3n6nk/OmQ5mo/tGS8OiFcFvBnd3+j8s1PpQSHnqGkMvuhZfvc9LVtvva54bpDPDMgByHyLjQmFTrtZRQds6GV0/uoZTlcJ2wnehMe9d1CuL/dkK3wDWiMv8lr5o0vIG3wnkn/1svrfIzexxcz49dg4HZ3n6O1O+lfQhtaFjnRnoWe3UeE7JW9KG9l5GSdzli6MLIJvhGZ5N3g7l/0sSC8BjCbu48I49sF1CZYP3L3ykk1uso0ooAH0dLQ2+GzoeXDLI48GndDXtgnmMKOnevu2QG/clizduPub5nZYWhZ6Gq0jPA5alg9hI2q5VpJZr6KAnU7TA0q5bm3NmUka8Bkc4+pnaAh3wS187o0we6+ccm5bwFbufvTpvBe77j73aY4xb+juWxBA4WTkeNI2fv4O7R6dHoYMBNuR85KVXkS2DsIwZtSM4X4CpqIFOKKirMYcjw6oonrRmp8CXgfOYEOQqsAPzKlCD+9j699FOpbHwh94tNh/3LIZGkJZGZWxv9l/h+D3velM/t2pRmP+jZgilO7N7UIFiORlruZSdreFPvSzIfe3XtzvmuGB5Dm9OTwfzIu7UX/mMr0CsvP+JZwGbB8qysBZrY1cui/Ewm9oGhE6yO56ysoYtG5ZpaYvfSJttUVri35/A5SAvS6sK7fkO2HpT5/hB78Itktdc4gFJnh78h79gUkHH81fL8XCvM0Bi0nDgr796UfPN2RsDg2fH4LOWuAlnqWDp+3Au5toswqmfm+i+K+XoO0WZO3gnLrIktUqEc6ekXag31LYHTmuJYykpGJaoEEkOOR0H1xp9tup7bQ/rdAy2EfokH+bGDDJssZCywaPr+MHOtAtmLjO32fffTsKr2PoR9Knk02UsOEJq63Yfh9vkCORMn+Y4ArK5ZxHHBcp5/dQNzQUuqEME68GfqOZHu9n+qwBpoQpSOQTAr71uz0M2rx3jZHyqVnkNbuAiTsJ6YnVctZlEw0pbDfkEbycuRQ3mp91wvvcxJl409o1fQjMpERumWjOOPbFyhU67ptuM7jwG9z9h8JPJb6f2OkGR4fxo3jgbX76N7XQHLNLOH/WWgyCs+AMI3IYk1kdAnasMSgfnqkeb0KCUzzoxfoVg8ZgII91gfufneb6rptdheyy90HeNHdtwo2zyu7lkZfBr7v7ncFLc9T7j5zxWsVZuYr08B6QU74ZkwNzOxs9Gx3QBqtlcO1rkWTjF+E49qRkSxrg93D3KO3ZQ9kzOxNagkqLqKXCSrM7H7kfX6TmV2DBoPDkPZpG2/CM3egUPV9NLNXgJ1cGvL0Eup2wLHuvmQT15wGmN3dx6T2LYomG2+H/7+KBLMenttltt4+lUZPqYKZ/Q9NGI/0Dmfgs35MRhCu19Dfpo3XGIVWjvbzlMBhZqcgQXi5iuV8gcI6vp3ZPzdaLf4Jcoi/gPw8BFc1UeeV0PJ/2szoWG9iub0/sYKMb+H7r6N++2dIYO0h+JliVi+FxuoXPCemuymb5orZMdvMlgKecPcZc8r8PtIWD/Y2+pRYThKh0P+ehRQR+1UurK9nKn0g/W+EOvlE+7IrsqE6i/o4vWuhgOhjUBi1YUjoXRvZET1Q8XpPAAu1UN+82dmbyAYxidV6P7Bl+HwNElwWQbOo55q41r0UaPxoQQNLE7F9qZjnnuCB2+k2NSVuwI+BOdpQzlDkTAHyon47tONPgB07fZ999OwqvY/Iu/we4KuhrS8d3pOX0OSh3fUaS07c7fDdiIJtwMVy7uffe0yj5zqlbzSI5d7mayT+ONn9S9PEqlLod+bN2b9IkAnytKE9YuFOiVu4/yVKfufPwng8MfQlyTYORZX4nNpqxOdIyFwkU85olJAjW/5OyM+qqI7pOPSnA/O0eM+XIOXanNSvyG2GbOorlzVQbITTnIy8o8ea2TJIAD4XmUocZ4rJmzaoH0rKoB4YbWY/pWaHVcaiyE62V7h71lYnj1Oohcc5Epk37Iwa7C5FJ5pSDCYUZuZDM9tHS8oriiyR69WcxZUdaX0rz3M/B7CztZaRrM8c7gYy7n52m8q5OPX54aClXBaZuJTarw5Q8t7H76H38Yep434N/BVNtBMHK0Md9FF9UK+Gmay8xNY7UsjFyOwlZuDrGx5EvifZlcqVkGN7ISkHbgeOMcV9TpgGKb0edfchbagrZrYD8Km7X5vZvw0wnbv3V1baZijL+PazBvvnQErCVVF2z6QPWx7lZLjHzNb0mpb5HOAsM1uS+oylByLzrIZ4fRSd7yPFQitjyKYo8tcYs7qu8QWk9KxM15lGmBJHrEi+UPPP9FKOmR0KrOfu3zSztVFUhE9oQ3KK1LGVzTCqYmbTeUHImGD0XknYMAW4Tv+ISYvI7nMUCuszLwgI3p+mBmURCzwkPykpo9fmHpFqTO0TjbL30RRWaVX0bB5x9+f6qB5t74sik8eDa1Bc0rwl9QEXYaEq/dGmzOx7aPXkdGqObOsgk8VfIdthoC6Vb/r8ZJzYCEXASJt4fUqwQW3XexfMDPZ395sz+zcDTnb3FdtxnXYSTDB/j0KY5bXhXEf3YMa4ArCZZyKkhH7vFmQOtlfYZ2i8PYBarN7XkRB8qlcUKNvR7qyNSYS6ShAOmsEL0YCbxd19GlM2kTXc/TlTQO2r3f00M1sEeNpLQg31ok4t/WCmjHavufuV4f/zkJb3Y2Q3NbasDHffraD8jZqozo5I0zySFjSwZZjZbxp85cgp5XmkpW85NFGIarBPl87SBzxT+0Qj2KG94/l2udugMEH9YlcaBeG+wcz+D60CvItMf9Jt3L1NMeW7kX4ShIuykaVxL7AhNbPhyM644ZgZfHwOR1nNHI11x3qDGM0NyvgEhUJ8ObN/URRyrJLPTn9S8ownP1frGVr1RuAwd/9Lg3L/H4o7/9Wc72YLhTetHGuTIHwDsnc+NJS3MjLduByZwuxYtaxuM434MwoE/ztkz5onpT8AHG5mt6K4uz8O+xdFtrfA5B+8GzJh7YtMNTCzDZED2c7ASaj+94fjNkTa18QYf0XUWAvr66nsVqa4o69kZ2VhFrcQWu54NOxeNltU6vhWNYA7oGc/CxKeoJY96Z1Ql7fNbKM2dMCl5h6RltgFrZ5MNRMNU1zeo5DGaiZky/iimR2L7OCScFqXAuNNmfsu9H5OzR5pG4cDB7j7SZ2uSAfoD01YW7KVlk26zWwPpHUG/abvojH2ajPb293Pq3ipMci08uXM/qWRLWo3UviMrXFoVUPmpbmCMFJazZsqZxAou58r78D8QV4Y2YH+70DgDlNK5RmAE0glEWqqpGYMivt6o4LhPhIQH0choY5I7T8N2XotiJyyEse0dDiapg3mq9Sp5PxPgIXD5+MI4ZFQjMh3w+dD0Cwm7Ug2C4r9d1gT1/oC+HLO/rmr3nuo42doSeSvKPHH5K1iGbsC/yKEqgv7vhrK3CXU5zbg2ja0mehw14cbmrgs2el69PM9/x6l6tyGesfc7YD7U8fNBvwIrex8DryIJvHL9FG9GjrLxa2l5/oeBY5G/XD9HwMzpP5fgVT4pzAWHNlH1+5zZ7mS60/XxrKeQ7awdfeEItw820Q5Z6CwdUun9i0T9p3VqWfV4rNpFFr1dXKc31LnbYyUa8n/NyKtPChO/6to4vAZsEt/tTvkt3UfMrH5LVKg/jP03Qs0XV6nf6DMzV2KQhX15twZw8O5PAhZ3wsPewhKM/sksHkvym31B0vH1H0UGBo+Lwl8FD6/gYJdZ89dAXiziWsVetU2Ud9WY/u+hMJPZfcPBl4On9cB3mpDm/lzeBHvDh3YqemtL9vr1LAxFU40kLPFRuFz2ht5GRRaMe+cBVAc6wfRhPT+PqhXR4WWKXVDTjttj/LRxPXrFBhkJjwoUUTLUQ/CmDNjZt/6pITwPrq/fwBz5+xfHtnUt+s6E8M9ZgXhJYGJTZQzWxhPPkfJh14Jn+9BIQ470k4q1HtlFDruQST4no8y5IEm9HmRO85GEZ56tAEkU91FSvhHpkNJmbsg05PpkPLr8Sbq2nJfFurS4556s3WbacRPgIvNbHUkuGZtWC9odKK7T4DJNrNbIecuaCITVgMntr2QcNhbbgHOMbNH0AuZZGNZAQmMoJnVgqhRpVkAKLVHqupVW7G+7TA1mA+9RFlmoGb//RYV7q0Clcw9ItWx+jTbg4ChrUb2GGAsiCJBZJmWBuZk7v6GmZ0Wzvs1ij/abpanZmoUaR8zA3uY2dfoTBvPRgNpGB2kcoFmR6P03OcH07hbkLnbh2a2pbvfB+Dud7V6rQrMBTxhZru6+y2hfj8D/ghc0cbrjEbJO7JsQf77nIvL5nVI6PMGo9/jYeA2DxJYt2GNM749HBzpnkCRcLKRO4Yhwfn50H89jcbNFVDUiGlRsoqE2YAPwuctkI/WZ2b2b6SUqspFVPCPKuF8YE+UfbEluk0Q/hp6Wb+BMpLUOS2g2U4ZMyHbIEPmE19GP/5INGMCcp3YzgV+aMpXvrW7PwPg7pe0eE/7IK3awkjT+n7YvxrSgIOiXQw3s4Oo96o9FjXuMpK0yIZMLrJetQ8jrUcVzkahTYZVPD6Pf6EQKz9Gwf1BgsEZ1CYiK1GbCPQaj2Gj+oJsmu1Hw9+pZaLxFLLZfzmzf0dq7XkyZrYxCi+4Xdh1NdION8TM/lG1Mh7s8t39lbJjI71iOWphvKaUNj6UmgDzdSTQrRP2/wEtefcXG6LJ4XUhSsESwLrAbu5+WRuvczy1EHjbm9nbSBj8AT3TT5fi7rcycFLI/x44yjMp1s3syPDdL8gPrToBtY9jgKOpjzp1M/Azd38tVeRoNEm4DslrO4T9cyGZrTDVs4ekJu6+d2u3C8hkKFHStJREqNuiRowG/oaWYj8uO75BGfejeHhXoFArb5OTCcvMnkcv4h3Bie0GYHc0mM3i7t9s9X6aqPNMSIO9KrWYxZ+jMHAHuvv4Rudmyin1qq1Qxp9pMbKEmX0ZTVq2QMt+oBfiFuCH7v52EB6mSzQEkUi3YGbfQhqLP6K+47dIQNoZ2MpDPOwQUWMn1OHfHM651t0nVrjG8Kr18Sk8MsfUTvD4n99rGQTrPOpD5JLXvYmsXKYMYEu6+6tB02fuvo8p/uuD7j5H22+kvE6/RU5sn6PET/eWnNKba3wHjf3jkKngKJR6/NqS8/YHTnf3CdYzln4d7n5iu+rbLqwk4xv1QQPSQp9Ri8g1J3ISBCUOGpNznb2QP9ZHSMu+mrtPCorFbyNh+lLkB5TFm2nDZVgbwq9OLqvLBOGxKPtIo6DQVcoYioTJP6GB61xgHkJyCne/Ihz3CXJqGR0GtLndfTczWw64093nafF2mq33WDRLngY1zud7OxlosR7ta1xKeLIMup9R3iD1cyTSbYRl8kOpT7F6ZHriZmb3IOH3stRKTyTSFEEQ3h2tYIJCiB5IzSRvDuCcJgXh11Dmx7vN7FngEHe/0syWBe5z9y+17QbK6zID0tbuiQSlDZDGcE93v6YPrtd0aC5T/Pw13P096xlLP427++ItV7LNBCXiQe7+t8z+ndDKcmFiLk9Fn6pwrdXRCvet7v5R2LcVMpk4m4JUz91KtwnCw4F73f2sNpQ1DlgFhVTrEQw/xJ/9hrs/ZGaPolnjxWHG/Ki7z9pqHXpT32Ze3pwyZgT2o3Hosyk2HmYk0i7M7BoUTuifnhM/OHPstMgGPy9UYxVTrshUTsU4u01p04Kd/zbILHBVlCr34yAYHeTufWHD3qguTyIzzKHu/lDYdwBasr/I3fdssrx5kHnFo3mrL2a2EJllcoApebJqZoejJBfHkZPxzd1zM11m/EEa4e6+X8V6fIwc5XutzOwE3WYj/CJwVDBVyFuWz12SMCWpyDIDmgmNSx2H15JTVHFiG2icDiRLQ8nL0BHMbGlge/IFhIYJQiKRLuBjZKL1oZn9FYU8fD57UFjxuA5YHK16fIH61M/QClRlQTiYCn2P/Pel8ipMZODh7oPKj2qa/dHS9cLAwanVxQWQr0Z/ci+wb9rEz91PMLN/oRWVSpgSOJyLxhVHy/gvmtmZSOE1HDgT2T9Plz41HF9pImFmq7j7Y1Xr1SX8HpkrHICCAoAca49AEZQws5WQ8/8SyCz0DfSsJoRz81gbyVKTBWEzmwvYkpy+ivJUz11JtwnCuyHBdb2wpXGUPjCPeTP/b4hehEXQj5yXnKKKE9tA49vADokNY6cIyyRXIgeU1dFSyRLohbqzg1WLREpx96FmNjtyLPoR8Cszuwtpia/wWkbEU5DJxKpoIB6MgrmfgZyDKmFmu6IB/Grg/wHXouD9i9GEoBCJJLiyHZ6Qs/+kDtRlDzP7upntgyaNXwuOn2uiFMtVORb4Chqj09Eurkdj+YbIjGQ3crJgNsEjpjTLFwKXDgQn1RDN4iTgJMvJ+GZmW6AwdjcCm6CgAqBcARu4+7fT5ZnZ+shHAqRlTvavg+L1TkBy12tocjURORcPA443JTSrnOq543gXxL9rZkMC7aDU//MDewBDwv9tSU7RgftqR1y9V+mjYP5N1uMhZJM2+b5QOLUrUA73jj/vuMWt6oZWiU5CyXE+RJmYlkOJGFYMx3yYvHvARjQXU/NJYI/wOR23+DTgD52+/7j1eftaFykLesSoRROr+4G1eln2gihaxIbprZ/vb2ho18k7lLTvvYCbmyjnVWDN8Dn9niwR/v8oeR9brO/SyEH2WeTYNwIJ190cQ7iRXLRe+P8+4Kc5z2515IiZnLcccA0SYM8llRQrfH8n0jBbamyfDzn7D0UOio22lmNh99nz63QFevGDF2Y2ocnkFKGjGIxmmZO3DtxXOwThfdEgPagddWqhHh+lXrT3qQkLKyFb7Y63o7jFrcoW+odDUdaqcWFw+Gfob8an2vnzwCbh8xLA+CauMR5YNHx+l5CMBvk2VE6oE7eBuSEFwa8Kvj8YuLzJMtuaYbXF+3sM2Cl8Tgthq9BEUiXqszymyxmMHLWeICSvamPd1w6C35vhPW3qd+jHZ1wmF32U6mPSz24xpN1dAK14fYY07Cs0uM6HhCQW4ZkvFz6vGfrIRYq2Tj+nRltXmUaUGW67QnetjjoGUMa4sejHHIoMwyslp7DGubehCXuiNnInmi23wubII3dLMxtJz2WJrVssvyrjqCXUeAPZYCcOE3P2Ux0ikV5hZtMhR6Pd0Dv1CFomvNRrXtI7ApegwfxFpLX7pZl9gbzje9gUF/AeClQPWmpM0sjPTW0JMzLlsjrSQDbinyi5QTOcjLSZyyNt85ZIc3ckiinbnyyFQplm+QiYvYlyHgC2RvcGNdOHvZBPzPEoodRPPcemvze4Eo/cZ2YXI/Ol7UpO6RRlctEYZFbycua89ZCA/xyaSGzq7nfQmHSOgreQgDsK/ZYLunvlxCXdRFcJwvQM5D8dElSnRbZ4UJ7Z5AqqJac4G6VO3JPW7IlKCXEgf4A0RYe7+7tmNgQtSbwE4O7faMOl3kV2hp3mPuSxOhLFZz7BzFZBjnx5HWIk0k28gSbHlyBN3eM5x9xKLXEPyCb4erSM+i5KvlGVO1Ff9gQy6zo1BInflIET0D/SexYkJ8pBivFoqbsZNkIxr582M6eJDKt9wOvI3CArJG1Ic05VhwI3m9kKSCbY38z2Rkqrj9GYMyPwTLjPz9Mnu3szQjdmtjgKwToUKXPuROYG3UiZXHQacFyYwDswrSkL7wVoleAEQpY/M1stW7jXbHsfRtrfZ4Hbgd8H+eb7aPKOma2MhO/lw7VGAse7+xPtveX20VWCsOdkCQshwc6l5mRVltlkb/Sj/pWc5BSpopdHMYv7NLZtiLl3G4pEsQIyPH8XaZqWRi9aW/DuCby/P9LMg4znZ0Mz6WcpybgViXQBv0BOcRMaHeAKNj9/6v8XgeWDR/UYD+uFFfkZtRWUY1B/NQQJxb9vsu6RgcfbyDazUbSi5cIxzZBkWAWZp+VmWO0nzkaTu0SIXMjMNkCrLMOqFuLu95jZemgcfwFNFO9HypZX21XZ4NQ3FJlFPImiUVzs9RnWuo0yuejXSCb6H5q8jwx/B4W/v0Qa5bz03ukV8sOorV79GgnSf0Jt60dWkurZ3a9rw722na6KI9wIM1seGdUvVJbZxEOoITObBWlgc5NTmNm9KKxM0TJAO+o+ArjD3Y9Ixwo2s3VRIP5F+uCai1ObjY3yFmIT9+La06IZ6X3u/l5/XTcSiUQGImZ2LhJ2h2QnUGY2CEVIGOXuuzdR5v3Ab9z9phAX+yNyMqz2F2Z2FJpgJhO+iUhLeHh/1qMKZvYKihx1YTdrMdM0IRctjvygBiGTr08bFFlHVZMHM3scaaOPyOw/ErW7VSreUr8yUAThjYBr3H3O8P8awELkZDZx97sLypkr9e9glOUmm3sbaF/w7ZAxbnAQftOC8KLA0+4+Y3EJTV1rdqT53g45R4AmAlcCu3sqnEpfYkr3uKy7v9wf14tEpgRCyKG8RDjdGXIo0haCcPIwsis/Dng6fLUccBBS6KzuTSQpsJBh1d3/Gpa6b6KWYfWH7n55G2+hap1mRgqaQcDIZOxu4vwdgE89ky7ZzLZBY94SaBX4XygLZMMVnZLrWJMrOl1BUca3IrkoU8ZkeaXB96cDvwEWRc/7eleilllQ20oid+Smem6nvNNOuso0wnrm+Dbk5DYUOQxgZoPd/UHgwfSB7n5DhUu8S88827fk7Guns9wn5DuILUvzy11lnIKWvTZGzgOgJdYzkYNBZY1CizyGbKpe7qfrRSIDli503I30I0Exshlaur6U2niULGFv3owQHMq8OPX54aB46ZFhtT9xJdR4sPTAxgwj37TuW8gH51Y03u6PhP4f9+Yi7u55ySfM7NvA/9z9kd6U29e4svY9lNlXRS5Kk2cakeYHyMFuZVJJTVCOhwlIplmdns7Cq1NLGd51dJUgjJZt0kwC3kE2OseEfQ+HbHB/AS5x9w+pTg8b5H7gWuCIMJsF8NApHYs0te1ka7QMkk5acbuZ/Rg50fWXIDwMOcgdgV7MOrOUdmnbI5EphH5z3I10J0G5s6KZDUbChQHPuvujvS3TzL6L7GjrVhlChtX+iiDUThYHnsnZvzHwmbtvAWBmWwLXmNlevdHsFiSfWALYFSWu6jqKMr65+5FtusyMSCabG9klJ1yBbIXPAc4ysyXJSfXcpjq0nQFhGpEmqNh3QzOTuZBh9rnuPqLJchYGXsmxyTJgIXcfnX9m0/WdHWmzV0aJPd5EYWzuBr6RtV1u8VrjgTXcfWRm/4rIZneWdl2rpB6TUv/20La7e9RwRSIBM/uYfnDcjUw9mNlxwM9RFJMek6sucqyujJm9jsw6bs3s/xT40N3nDf8b0k4u3hsHNzO7Dzjf3U/PmDOuDlzn7gu2fDNtpizjm7tXcpBM32+D7ychueWmzLNZDDkWzora3QEoGgqo/R0HnNqtJifdphFuOIsFxcF19+eAQ8zsMODrKAXqTWb2KnAeasBVPEhfQg0la54wV/iuLcKau48F1jezTagZqT/sfZMG+W7gd2b2g7AMlTgN/paaqUR/0AnNeyQyUHkCRaCIgvBUSI5JYC7ufmITxe4CfM/d/967WnUl16IUwtsmk0YzWwbZBf8zOSiYNnwKzNDL66yQLi/F+0g+6EaOQ+ZV+6EYwpugldhLkd9QuzDyHezmBSYEQfckGqR67la6SiPcm1lsCK+2NzKdmB6FHroKOKBoNhhmNvO5+zuZ/YsgQ/5+0Z62k6D5vQlpnh9Hz28VFD5lC3d/qoPVi0QiOYRJcp877ka6EzNrFDYtjbv74k2U+Q6wbtZpaSATBKubUFizN8LuBZDS6gKU9SxhL+Cy9D5XQq4q13kFZcK7O6P13A441t2XbPlm2oyZfYjSTz9rZh+g336Uma2JTEgrRQmp4Cz3OXC2u/80PJuVkYnE5Sge8U4A7j4pHD8/8E0kU/WnMq4puk0jXHkWa2ZrIROJ76IZ0B+QRngBFDD8GhT4OXtekr3OURaa8amvpwHWAh7t9R30vN5vGnzlaBnjeeAmd281qxzu/mQwHRmKPI4NzRIvbkf5zTAQnQ0ikQ6RrA71teNupAtx98X6oNizUZKDYX1QdkcImsUhpmQzg9H78TCaQC6cOfyezL5mNH6XkJ984njkr9SNFGZ8a6KcMme5icB3g5wxA8rZsALwJeSYfwOarJxiZrMi58hZgFnNbHd3v6CJuvQb3SYID6JECA3LSLshh4IbkNB3UzIDAUab2U+phaDJkmSvMyQsphvQp+jFOr43lW/ADuiFnAVpuaGWSegdFAbubTPbqNEsrEm+hJZwnkPPc3oU6Bp3P70N5ZcyUJ0NIpEOEU2JpmLMbHeUvnt86cHF5Zya+ncQMDQIjY/Tc5Whkna0Gwk2wmk74XabGeYlnxgEXAwc1eZrtYvSjG9ZgkPbq5kwc19H9sV5x0+HBOtdUOSIich57grgz0HZVZbquSsF4W4zjTgKeX8OKzjmOWTzMtzdc8NxmNn0SLN8fkE5w4H9gg1vn2Fmu6LGuGtiu2xmX0Xa64uQMH858JG7b9Pitb6PomkYyi2e/nG9v4z8B6KzQSTSCcLgchewi7vnecRHpnDM7BMkqF4O/MXd7+1lOVUdxt1DgoVuJyi+Tnf3CWW21E3aUFe5dl3yieCf1JWYcivM5u4jzGxeJHAOIWR8A74HPOPu5wdnwluQL9aHwJbufp8pzvNg8v2zrgrXeRtYv5Fjb2jLS7v7K2Z2EVoBPiwEJxjVrSan3SYI/xmlHB7JFDKLDfZf27j745n9g1GSkEWDx+e17j5fi9f6H3A+Cib+ednxfYWZJUG1X87xLB3lXRpUOxLpBGWDS2TKxszmQMqS3ZAgMhIpNC7yDsX87RbC+LmGu79XYkvdlA11znXOq3qsu+/W2+t0iiAbfNfd7zWzbyA5YSukqV0ZabovRWHRskyO9BT8uHD3gxpc5xngCOA6lEdgB3e/Pcg7tyaRPbqNbjONWJ6aacSyme+yYc4WJD9eXqWUycHJbj8aR6hoVz72+aillUwzQ7guyKZn5jZca3bgr50UggNjgK/QM6HGarQxJ3wkMoVwPoohnDu4RKZs3P0DlB73NFMWuN2Bw4E/mNk/UHjQmztYxY6Rtp/uI1vqhKyAtiHKY5CkWF4RyQiV5ItOETTDeRnf5qM29n4DuNzd7zez95Ed7ylodfpQd389p+iEWaiZ3PTIEYASa1xILdVz8rw2pPYsu46uEoTdvdRWLgjAlwIbIOE4cShJqOpYcjrwHWTfkgR+7gv+hQJM/5ha1pfVgTOo2TmthEK2tcrFaJb3pzaU1QoD0dkgEukUhYPLQFwJi/QOVzrth4MZwHZIS3yDmb3q7ot2tHIdxsxWcffH+qJsd/9W6jqHoAx1P/IQ5z8IlOfSpcJcsAf+B7ITzsv49h5yoHsV2AI4JJw6LZKhFgW2LhGCQX5VScr3rAbe3X1fM3uQWqrnxHfrBTS560q6yjSiCmZ2OVLf7wM8gDKpzAccCfzCM8G2C8p5H9ixj+L5pq/zZWSvswUKLwKaWd6CgoO/bWYbo7zwt7R4relRtIxPyQ/D1K7sMmX1mA45G+yEXrJJ4e8lyFb6i8ZnRyJTFyW2nQPGnjPSXsxsOaQd3g2YeWo3KQshT59CGsdL3f2VPrrOG8Cm3jMx1QrAbe4+f19ctxXM7BI0od4VhTNLzBE3Q4qxW4FtkM3wqsAiQWO8E1qJeg842d3z4idP8XSVRrgiGwFbufvTZubAOyHe30QUNq2SIIxi6/bJi5TG3d8GtjQF/l4GCYSj0vaA3mRWvAL2QhODd4ElyTjLoclCn+PunyEN12/QS9f1zgaRSKeoshIWmToIIad2QsLv2iil8DHIfGZqZ1lk07oHcLSZ3YmE4r8nTu9BM/oDZB5wuLu/a2ZDgNfdveqq66wostPIzP4FaI8JY1+wKRLex8gXbjIvIO3s/shUYWHgYK9ltF0ArU6/DxwfVtzzlGgPUxHrn1TPbWUgaoTHAisHR6yXge+7+13BEespd6/UUM1sXxT/bu+U+n5AE5xujnH3kzpcj22AG7rAVjkSGTCY2TxoAH/U3Sd2uj6R/sPMNkDC7/ZIWfJ3FEHiro5WrEsxs7WRULwj8o25HjgWuA2ZGa4ALBu0osNQJIOdK5b9VyRYHgQkETzWCeWPcPdd23YjbSLIRWu4EmqkHdTXAm509zwnuPT5RTLQZGe5CvVoS6rn/mYgaoSfRjPDl5Fj3U9MmWD2oUH8uwZsjuyMtzSzkfScAW3djsoCmNnSqIPLmyG10wN1GmQn1GkuBcab2RXAhd7FGWUikU5jyph1HrIJnWzfZ2ZnAm96QTjJyMDHzJ5FE6CHUKzVS3wApKXtJO5+H3CfmV0MnInenXmBU9z9iCAMJtyMQohVZW+UKOKvKH0zKGPtuej36UbuRGYRh4b/3cymAX6JJgdA4yADKNZvO+ivVM9tZSBqhIcie9q/Bg/bm4B50IxjF3e/omI5hU5bnpPOuTeY2VbAlcAjyEnuAdTpzQDc2WaB+3hgbKeXH8LAvj0Khbcxslm6GIUDirFSI5EUZnY6SoW+D4opvHLQ5nwTOMrdV+loBSN9iikRxjnu3pWOWN1GiO+7M9IIL4mEwAtR5IPB4d1Ja0UXBZ5u1sY6OMgtgTT0z6fMCbqOYE9+B1IOboQ05OmMb59QEGSgqsa3Qj3akuq5vxlwGmF3vzj1+eHQyJcFRjcTc7Fdgm4FjgR+6+7HhJfzByjD3IXAf9t8rZmBPczsa3QwDnPQZgwHhpvZAiiY987AoWb2kLuv1R/1iEQGCFsD33H3R4PfQ8IoenpmR6Y8TkOZQHMJzscbuPu/+69K3YeZ7YOE37WBJ9EYc7G7vxa+/wMwZ86pywJvN3u9IPjmZmXrJlLO6d9CmeHyMr5djrTay5MTZCCUszLSeC+PhOSRwPFNTtDaleq5XxkQgnDVYNemNMJNmRqE2WXyw4/y9qQ5TrMM8Lfw+TPk/TvBzI5EcfvamQ1nOaR5hpI4zP1FeAlPQ4b6v0Za8UgkUmNO5LWdZTZqkWYiUy6jkB3l2wBmNhoJvv8L38+FnMDborUbwPwKaTX3aiCcXQscYWY7hP89KMqORauyUyTu/lnwkXrf3Y9ocFhhkAEzmwm4CmnXbwznrI9C+W3r7tdVrE7TqZ67gQEhCNMHwa7NbHZks7JdKCvstiuB3dtoozWOWkKNN9BSzpPo2efNXntNt3mfh7BwQ9EzBrgaea9GIpEaDyCt8Mnh/2TSuheKcR6ZsrHM/3PSU+jNHjM1srAX23IeiBy13kGro3chrefdSAkzJVOWlGcmFE0KFCHiy0hYHYkyy/0emWHVCdJBYfd7lCmuCoehCTzomV+AwrclqZ67kgEhCPdRsOtTUAPYmNpgMwQZ3p+M4je2g/vQzGok0gCfYGaroGQe7TaN6ApCGsad0Mt2MxrQr42e8JFILocCN4c4pdMC+4fPa6FJfyQysJx5+gB3dzNbCY0nSwC7hRXHbwP/c/dHgPXNbBOUxXQQ8HBf5wroEsoyvpUFGVgamWtmuRA4uGol3P3B1Od3kKlG1zMQneXaEuzazN4Dvu3ud2b2bwhcXRZupIn6Lg7M6u6Pm9nMyBt1CJoh7e/uo9txnW7CzO5BnqOXufv7na5PJNLthAH+QGQ6NAgtMR4bHaimfELoqvlDzHnSjl7h//lQHNyp2jTCzLZAUZFuRGmClwvOcAcgU5Jvd7J+naQsKQ9SFDYKMvBDlPX1IHf/W/rEkHDjWHdfpMn65KZ67taQqgNCI5yhXcGuZyLfLu99aqYMLWFm06JZ2H0A7j4ehWaZonH39cK9r2VmeSHjLuhMzSKR7iQIvD/sdD0iHcGBOc3s89T/c4TEBCAb4YgSZu3v7qcn4dFMqai/AmwcPjfE3dvpj9NVNGMWmRdkICT8OsvMlkQr5I5Wsg9EIdEqYeWpnverWlZ/MhA1wn+lDcGuzexWFOfuB0FATUwsLgBmd/fN21TfCSiw98vtKG8gEF6q65DHuyGHn2mRs+BEd5+9g9WLRLoKM/sCWCDRCKb2zw28PbVrAqd0gkY4PRBb3v9Tezsws4+AFUMyrXEo5OBtaGz5CnLIboS7+1QdgcXMvotkpy+jVac02wA/Bw6gFt3hdSQEn1pim52+RmGqZ3dfrsXb6BMGoka4XcGuf4GWB14zs8dRx7MKSr28RbsqCzyGHORebmOZ3c4paGl3VeBNYDCKZ3gGU77TQiTSLI0coWagPhxRZMqkq5ycu5gxSOB9Odnh7ouZ2XZo+X7JTlWs2wl+Oz8HRiABt06wDYLuScBJIQ9AEga1WcpSPXclA04QdvdPgJ+a2UG0EOza3Z80s6VQVIPlQjkXobiEn7SxysOQg9wR5BixT6E2tGsCGwXboEnAtGE55mDkQdqVaRYjkf4ktZTryHnlo9TX06Dg90/3e8Ui/Yq7/6fTdRggXAIcZ2Y7ondmWjPbCNm3FibIirAL8D13/3vel2Y2CMDdJ7n7ODObP2iQR3pzmWFnIn/yPi8yjehKBpxpRDsxs/mB9chZKnD309t0jXQO76liucvM3kd5z180s+eBH7v7v81sCeAJd2/GljsSmSIxs5fCx0WAV6mPGfwp0nz9xpVONjKFE0J6boZMyhzZVv6rjaE8BzSpxBE7ofFzEhq3L0WCXqH96ZRsI1yGmb2Dsrw93+D7G4Gb3P0UM5sVTcBnQT5Zu1f16zGz64HH3f3QYL6yMjKRuBz4wt13bMPttJ2pVhA2s+8Df0Ev1BjqhVR397ZkQQkz1oZMidoAM7sDOMndrw42Q3MDR6M4hyu7e9QIRyKB4PG9rbuP6XRdIp0haDnPBObIfPUBSiBxRX/XqVsJkZiS8GgnoLTK76UmlnlM1TbCZnYU8Jm7D2vw/dvIpOEJM9sFJS9ZBa2Y7191zDaz5YH/0CDVs7u/0OKt9AlTsyD8PxSE+shuDekxUDGleJ7F3a8Kndb1yEP1XWBHd7+9k/WLRCKRbiGEznsIpcQ9HkVEMiRAHAhsi1bYprpQelWzygJNZ5Wd0jGzU1P/DkJC7UiU4e2zzOF7Aku7+ytmdhGKy3xYiPo0yt1naeK68yNfrnQoyD+7+xu9v5u+ZWoWhMcAq3v7UyrnXassCPgUTwgFNKaq92kkMjVR5NHt7lt3pFKRfsHMzgG+7O7bNPj+WhQ9ZM/+rVnnMbNsRrOGWWXje1JPSWzhNI6cEI9A0Z5eBnZw99vNbDBwq7tns/vmXW86lM1vF3d/pleV7hADzlmujVwMbIWct/qMTBDwTZAxOUgo3hX4dl9ev1uYQp0CI5GWKfPojkzxbIB+/0acQS399lSFN5lVNiiY9geWD6eNAk5096v7sdpdQTOxhc1sL5RF7iMUhu6O8NWGVMzY6+6fmdliDMD+a2rWCE8PXIOcUp4gs1Tg7ke26Tr3AeengoAncfVWB65rly1yJBIZmJjZW8A+jTy6I1M2YVxY0d1z4+CG5AdPuvus/VqxLqMsqyyKeXs0ygXw3/D1usD3gcPd/fh+rO6AI8gkCyMN8Edh31bAB+5+d8UyjgNw94P6rKJ9wNSsEd4L2BLZrS5JxlkOaIsgjOy8/pmz/31ixqBIJKKl3Uc7XYlIx5gFaTob8Qm1lcSpmbKssgcCP3P3c1LfnWdm96PxPArCBbj7Q8hWPb3vhiaLmQUYamabkx8udt+WKtlHTM2C8OHAAe5+Uh9fp0cQ8MBqKGRSJBKZujkbaa2Gdbgekc6xcgg7mcc8/VqT7uVKYHjIIZDNKnsVsB0yL8oyAgnRkQKCH8+WSCs8ffq7JlbIl0POcaAwgHXFtFTBPmRqFoSnQba7fU0MAh6JRIqYA9g5aFF6eHR3qxYl0lZupnGGQehiIaIfKcsqOw2wPfCHzHnb0T9j/YDFzNZBK9cTUPKL15CmfSJS4lUShJuxS+4mpmYb4eOBse2yBS64Tl4QcEMC8q7u/kXjsyORyJROmXf3QB1cItUws0WqHNfIhnhqIzjIJVllv04tk9lswC+A+6jZCK8TthP7eqwfyJjZncAjKCnJWBRD+GOUrORcd7+4g9Xrc6ZmQfh0YGfgKfpBCxOyqq2K7AEfcffn2ll+JBKJRKZ8wtj1G3d/t9N16TQlSTTSTNUJNcowsw+BNd39WTP7AGWhG2VmawKXuPtSna1h3zI1m0Ysh2ZAoGQPado2OzCzbYAbQkaVrsyqEolE+hcz+wfwfXcfGz43whvFl41MtXwfmdZN9YKwuy/W6TpMIXya+vwWSvs+CoVTm+IjW021gnA/LjdeCow3syuAC939nn66biQS6V7eozbhfq+TFYkMOIpsiSOAmc2KJpEflx4cATm4rQk8C9wO/N7M5kOTrsc7WK9+Yao1jegvzGw2ZMC/M7AxMBol87hooGVfiUQikUhnScej73Rdug0z2wf4JYrUBIrMdKy7n965WnU/ZrYGMJu7jzCzeVEs5iFIMP7RlJ7eOwrC/YiZLQB8DwnFqwIPuftana1VJBKJRAYKURDOx8wOBQ5BZiN3hd0boExzR7t7NppEJAJEQbjfCRntvgX8GljZ3afpcJUikUgkMkCIgnA+ZjYa+KW7X5rZPxQJwpWic0zNBM3wEsD17v5xiNAx0d0/73DV+pRBna7A1IKZbWxmf0GG6H9BjnqbdbZWkUgkEolMEXwZeCBn//3AfP1clwGFmc1nZvehZ3UJted1IordPEUTBeE+xsyOM7NXgJvQi7oXML+77+buhfFDI5FIJBLJcBGK9Rqp51lkdphlZyD64xRzEvAmMDcwPrX/CmCLjtSoH5lqo0b0I0OAY4DL3L1RCs1IJBKJTOWY2czAYKQ0qVNUuftV4e/e/V+zAcEw4HIz2xC4G0VlWR/YCNihg/UaCGwKbOruY8zqgpK8gFIuT9FEQbiPcff1zGxaYC0zy8vhfUFnahaJRCKRbsHMNkPhNufO+dpRCuFIA9z9KjNbG2WX+yYKMzcSWMvdHyk8OTIT9bGEE+ZFaZenaKKzXB9jZssA1wGLoxfzCzQB+QwZoc/ewepFIpFIpAsws6eQjeuh7v56p+sTmXows+uBx9390OCMuTIK9Xo58IW779jRCvYxURDuY8zsJuADYHdkgzMY+BJwBvBrd7+1Y5WLRCKRSFdgZh+jSEIxA2mkXzGz5YH/AI8iU5LrgRWQrDJkSm+T0TSi71kT2CiEIpkETOvuD5vZwcCf0MwrEolEIlM3dwPLILvMSEXMrJLjYFx9bYy7jzSzlYC9gYnAjMhR7s/u/kZHK9cPREG47zFqXpjvoIw3z6CMN0t2qlKRSCQS6SrOBI43swWBJ5D53GTc/eGO1Kr7mRX4H8qGFmMrN4mZTYcSkOzi7kd0uj6dIArCfc+TwCroBb0f+KWZfQHsCTzfyYpFIpFIpGv4e/h7ds530VmuMVsBuwEHI636ecCV7j6xo7UaILj7Z2a2GGpjUyXRRriPMbOvAbMEj9bFke3NssC7wI7ufnsn6xeJRCKRzmNmhZnP3P1//VWXgYiZzQ38AAnFX0UROP4SI0aUY2bHAbj7QZ2uSyeIgnAHMLO5gDEeH34kEolEIm3FzNYC/oAcv+Zx9zEdrlJXY2anA0OBl4CHgI/T37v7vp2oV38RTSM6QEysEYlEIpEsZrYycCCwPFqqHgkc7+5PdLRiAwQzmwXYCUVpWhm4kIxQF8llOSCxQV88890Ur7CLGuFIJBKJRDqMmW0NXAXciZyXQJnR1ge2dffrOlW3bsfMNkDC7/bIL+dclM11XEcrFhkQREE4EolEIpEOY2aPA1dnPffN7EhgG3dfpTM1627M7BlgDqT9PdfdR3W2RpGBRhSEI5FIJBLpMGY2AVjR3Z/P7F8KeMLdZ+xMzbqbEJ9/Asra2lCgiXGEI42INsKRSCQSiXSet4HV6RlWc3Xgrf6vzoDhR52uQGRgEwXhSCQSiUQ6zznAWWa2JHAP0m6uj5znjutkxboZdz+/mePN7HvAP9w9OtFFgGgaEYlEIpFIxzEzA34OHAAsGHa/joTgU2O4zfYQUjIPdveYhS4CREE4EolEIpGuwsxmA4hRD9qPmY0DVomCcCRhUKcrEIlEIpHI1I6ZDTKzQTBZAJ7FzPYws/U6XLVIZIomCsKRSCQSiXSeG4D/AzCzWYEHkVnEf8xsl05WLBKZkomCcCQSiUQinWd14N/h87bAWODLwJ7IYS4SifQBURCORCKRSKTzzAZ8ED5vgZJrfIaE4yU6ValIZEonCsKRSCQSiXSe0cAQM5sF+Bpwa9g/FzC+Y7Wa8vgf8FmnKxHpHmIc4UgkEolEOs+JKE3wR0hYuyPs3xB4olOVGkiY2YzAN5EG/Sx3/8DMlgDGuPv7AO6+YifrGOk+Yvi0SCQSiUS6ADNbHVgYuNXdPwr7tgI+cPe7O1q5LickIrkVmZjMASzt7i+a2fHAHO6+RyfrF+leoiAciUQikUhkQGNm16MEJHsjW+tVgiC8ITDc3aOddSSXaBoRiUQikUgXYGZzAVsirfD06e/c/ciOVGrgsB6wjrt/oSR9kxlNLVNfJNKDKAhHIpFIJNJhzGwd4J/ABGBe4DVgAWAi8DIQBeFypsvZtzDwYX9XJDJwiFEjIpFIJBLpPMcBFwFfQcLwJkiIexA4toP1GijcAuyf+t/NbHbgtyhZSSSSS7QRjkQikUikw5jZh8Ca7v6smX0ArOvuo8xsTeASd1+qszXsbsxsQWBE+Hdx4BFgSeAtYEN3f6dTdYt0N9E0IhKJRCKRzvNp6vNbwCLAKBROLdq4luDur5vZYOB7wGpoxfts4GJ3/6STdYt0N1EjHIlEIpFIhzGzm4EL3P1iMzsLpVz+E/B9YFZ3X7ejFYxEplCiIByJRCKRSIcxszWA2dx9hJnNC1wADAGeBX7k7jGpRglmthrwc2D5sGsUcJK7P9yxSkW6nigIRyKRSCQSGdCY2VA0efg38N+wex3kdLiru1/UqbpFupsoCEcikUgk0iUEzfASwPXu/rGZzQJMdPfPO1y1rsbMXgbOdvejM/sPAfZy90U7Ua9I9xMF4UgkEolEOoyZzQf8A1gTcGCpkBntLGCCu+/X0Qp2OWb2Mcom93xm/5LA4+4+c2dqFul2YhzhSCQSiUQ6z0nAm8DcwPjU/iuALTpSo4HFCOD/5ez/f8B/+rUmkQFFDJ8WiUQikUjn2RTY1N3HZFIEv4ASa0SKuRE4JpiW3Bv2rQNsCwwzs22TA939qg7UL9KlRNOISCQSiUQ6jJmNBdYICTXGoWX+F81sLeBGd5+7w1XsasxsUsVD3d2n6dPKRAYU0TQiEolEIpHOcwewa+p/N7NpgF8Ct3WkRgMIdx9UcYtCcKSOqBGORCKRSKTDmNnyyJb1UWAj4HpgBeBLwBB3f6Fztet+zGywuz/a6XpEBh5RIxyJRCKRSIdx95HASsA9wC3AjMhRbtUoBFfiYTN7yMz2NrMvdboykYFD1AhHIpFIJNJBzGw64C5gF3d/ptP1GYiY2VLAbsAPgLmAq4Bz3X1ERysW6XqiRjgSiUQikQ7i7p8Bi6H4wZFe4O7PufshKMLGDkijfpOZvWBmh5nZVztbw0i3EjXCkUgkEol0GDM7DsDdD+p0XaYEzGxGYG/gGGB64HOkJT7A3V/rZN0i3UUUhCORSCQS6TBmdjowFHgJeAj4OP29u+/biXoNNEK4ud2A7wJjgeHAecACwO+AOd19zc7VMNJtREE4EolEIpEOY2ZFtqzu7pv0W2UGIGa2PxKAlwJuAP4C3OTuk1LHLAk87e4xmVhkMlEQjkQikUgkMqAxs+eAc4Hh7v5Wg2OmB77n7uf3a+UiXU0UhCORSCQSiQxozGxRYHRaAxz2G7CQu4/uSMUiXU+MGhGJRCKRSGSg8wIwT87+uZDddSSSSxSEI5FIJBKJDHSM/PBzswIT+rkukQFENBiPRCKRSCQyIDGzU8NHB44xs/Gpr6cB1kJpqyORXKIgHIlEIpFIZKCyUvhrwHLAp6nvPgUeBo7v70pFBg7RWS4SiUQikciAxsyGA/u5+9iS474KvJ51qotMvURBOBKJRCKRyFSBmY0FBrv7i52uS6Q7iM5ykUgkEolEphas0xWIdBdREI5EIpFIJBKJTJVEQTgSiUQikUgkMlUSBeFIJBKJRCKRyFRJFIQjkUgkEolMLcQIAZE6oiAciUQikUhkaiE6y0XqiIJwJBKJRCKRKQIzm8fM1jazGRocsjzwv/6sU6S7iYJwJBKJRCKRAY2ZzWZmlwNvA/cAXwn7zzSzYclx7v6Ku3/RmVpGupEoCEcikUgkEhnoHIuE39WAT1L7rwe+05EaRQYE03a6ApFIJBKJRCItsjXwHXd/1MzSDnGjgMU7VKfIACBqhCORSCQSiQx05gTey9k/GxBNISINiYJwJBKJRCKRgc4DSCuckGiF90I2w5FILtE0IhKJRCKRyEDnUOBmM1sByTb7h89rARt2tGaRriZqhCORSCQSiQxo3P0eYD1geuAFYFPgdWBdd3+4k3WLdDfmHpOsRCKRSCQSiUSmPqJGOBKJRCKRyIDGzHYws21y9m9jZtt3ok6RgUEUhCORSCQSiQx0hgETcvZ/HL6LRHKJgnAkEolEIpGBzuLAMzn7nyfGEY4UEAXhSCQSiUQiA50xwFI5+5cGxvVzXSIDiCgIRyKRSCQSGehcC5xkZksnO8xsGeBE4JpOVSrS/cSoEZFIJBKJRAY0ZjYbcBOwNvBG2L0AcD+wpbuP7VTdIt1NFIQjkUgkEolMEZjZ5sBgwICHgds8CjqRAqIgHIlEIpFIJBKZKokpliORSCQSiQw4zGx/4HR3nxA+N8TdT+ynakUGGFEjHIlEIpFIZMBhZi8Ba7j7e+FzI9zdYwi1SC5REI5EIpFIJBKJTJXE8GmRSCQSiUQGNGa2SqfrEBmYREE4EolEIpHIQOcRM3vCzA42s4U6XZnIwCEKwpFIJBKJRAY6ywJXAXsAL5nZCDPbzcxm73C9Il1OtBGORCKRSCQyxWBmawNDgR2B2YHr3X3HztYq0q1EQTgSiUQikcgURxCIzwRWdvdpOl2fSHcSTSMikUgkEolMEZjZ4mb2azMbBdwFjEHmEpFILlEjHIlEIpFIZEBjZvsgc4i1gSeBi4GL3f21jlYs0vVEQTgSiUQikciAxsxeAS4FLnT3Jzpdn8jAIQrCkUgkEolEBjRmZh4FmkgviDbCkUgkEolEBjTu7ma2kpmdZmY3mtkCAGb2bTNbtdP1i3QvURCORCKRSCQyoDGzLYAHgK8AmwAzha+WAI7oVL0i3U8UhCORSCQSiQx0fgfs7+7fAT5N7b8dWKsjNYoMCKIgHIlEIpFIZKCzAvDPnP3vA3P1c10iA4goCEcikUgkEhnojEFmEVlWA17t57pEBhBREI5EIpFIJDLQuQQ4zsy+CjgwrZltBBwPXNDRmkW6mhg+LRKJRCKRyIDGzKYD/grsBBgwKfy9BNjV3b/oXO0i3UwUhCORSCQSiUwRmNkSwKpoxfsRd3+uw1WKdDlREI5EIpFIJBKJTJVM2+kKRCKRSCQSiTSLmZ1X9Vh3360v6xIZuERBOBKJRCKRyEBk3sz/GyLb4CfC/ysiE4k7+rNSkYFFFIQjkUgkEokMONz9W8lnMzsE+AT4kbt/HPbNApxLTTCORHoQbYQjkUgkEokMaMzsDWBTdx+Z2b8CcJu7z9+ZmkW6nRhHOBKJRCKRyEBnVmDBnP0LADP3c10iA4goCEcikUgkEhnoXAkMN7OdzGzRsO2ETCOu6nDdIl1MNI2IRCKRSCQyoDGzmYATgN2A6cLuz5EgfKC7j+9U3SLdTRSEI5FIJBKJTBEEB7klUFa55xPHuUikEVEQjkQikUgkEolMlUQb4UgkEolEIpHIVEkUhCORSCQSiUQiUyVREI5EIpFIJBKJTJVEQTgSiUQikUgkMlXy/wFo4fKZX0BZlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = optimaize.feature_importances_\n",
    "feat_names = kevin_train_X.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Feature importances by RandomForest\")\n",
    "plt.bar(range(len(indices)), importances[indices], color='lightblue',  align=\"center\")\n",
    "plt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')\n",
    "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_network_usages'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_network_usages',\n",
       " 'days_since_reactivation',\n",
       " 'days_to_redemption',\n",
       " 'months_since_suspended',\n",
       " 'is_active',\n",
       " 'total_spent',\n",
       " 'average_suspension_length',\n",
       " 'days_since_update',\n",
       " 'sms_in_total',\n",
       " 'months_since_enrolled',\n",
       " 'num_redemptions',\n",
       " 'num_deactivations',\n",
       " 'sms_total',\n",
       " 'average_monthly_spend',\n",
       " 'num_suspensions',\n",
       " 'sms_out_total',\n",
       " 'num_reactivations',\n",
       " 'carrier_carrier 1',\n",
       " 'plan_plan 1',\n",
       " 'total_quantity',\n",
       " 'has_enrolled',\n",
       " 'total_ram',\n",
       " 'voice_min_in',\n",
       " 'voice_min_total',\n",
       " 'voice_count_total',\n",
       " 'reason_PASTDUE',\n",
       " 'has_earned_points',\n",
       " 'has_deactivated',\n",
       " 'num_enrols',\n",
       " 'voice_count_out']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = []\n",
    "for i in range(30):\n",
    "    top_features.append(feat_names[indices[i]])\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = kevin_train_X[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the performance of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:43:07] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/data.py:114: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.883915633553373"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8)\n",
    "clf3 = XGBClassifier()\n",
    "clf3.fit(X_train,y_train)\n",
    "pred = clf3.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function average_precision_score at 0x7f5b54669710> [0 1 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "print(average_precision_score(,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tunning of LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1876\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1871\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1872\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.156684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5908\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5900\n",
      "[LightGBM] [Info] Number of data points in the train set: 37245, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271607 -> initscore=-0.986485\n",
      "[LightGBM] [Info] Start training from score -0.986485\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10116, number of negative: 27130\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5902\n",
      "[LightGBM] [Info] Number of data points in the train set: 37246, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271600 -> initscore=-0.986522\n",
      "[LightGBM] [Info] Start training from score -0.986522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-4)]: Done 324 out of 324 | elapsed: 89.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 15174, number of negative: 40694\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5931\n",
      "[LightGBM] [Info] Number of data points in the train set: 55868, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271604 -> initscore=-0.986497\n",
      "[LightGBM] [Info] Start training from score -0.986497\n",
      "{'learning_rate': 0.1, 'max_bin': 255, 'max_depth': 40, 'num_iterations': 500, 'num_leaves': 150} 0.8931536047738414\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lg = lgb.LGBMClassifier(random_state=11,silent=False)\n",
    "param_dist = {\"max_bin\":[63,255],\n",
    "              \"max_depth\": [20,40,50],\n",
    "              \"num_iterations\" :[100,200,500],\n",
    "              \"learning_rate\" : [0.05,0.1],\n",
    "              \"num_leaves\": [100,150,200]\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(lg, n_jobs=-4, param_grid=param_dist, cv = 3, scoring=\"f1\", verbose=1)\n",
    "grid_search.fit(kevin_train_X,kevin_train_y)\n",
    "print(grid_search.best_params_,grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_bin': 255,\n",
       " 'max_depth': 40,\n",
       " 'num_iterations': 500,\n",
       " 'num_leaves': 150}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931536047738414"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 12140, number of negative: 32554\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5917\n",
      "[LightGBM] [Info] Number of data points in the train set: 44694, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.271625 -> initscore=-0.986394\n",
      "[LightGBM] [Info] Start training from score -0.986394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9023195034302516"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8)\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                        n_estimators=700,\n",
    "                        max_bin = 255,\n",
    "                        max_depth=40, \n",
    "                        num_iterations =850, \n",
    "                        random_state=11,\n",
    "                        num_leaves = 150,\n",
    "                        silent=False)\n",
    "\n",
    "lg.fit(X_train,y_train)\n",
    "pred = lg.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final F1 score of LightBGM after para tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 12200, number of negative: 32494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.402600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5916\n",
      "[LightGBM] [Info] Number of data points in the train set: 44694, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.272967 -> initscore=-0.979620\n",
      "[LightGBM] [Info] Start training from score -0.979620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9025825433148087"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8,random_state=2)\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                        n_estimators=400,\n",
    "                        max_bin=255,\n",
    "                        max_depth=40, \n",
    "                        num_iterations=850, \n",
    "                        random_state=11,\n",
    "                        num_leaves = 150,\n",
    "                        silent=False)\n",
    "\n",
    "lg.fit(X_train,y_train)\n",
    "pred = lg.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the overfitting issue and decide the final hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 12200, number of negative: 32494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5916\n",
      "[LightGBM] [Info] Number of data points in the train set: 44694, number of used features: 69\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.272967 -> initscore=-0.979620\n",
      "[LightGBM] [Info] Start training from score -0.979620\n",
      "[1]\tvalid_0's binary_logloss: 0.516577\n",
      "[2]\tvalid_0's binary_logloss: 0.467335\n",
      "[3]\tvalid_0's binary_logloss: 0.42784\n",
      "[4]\tvalid_0's binary_logloss: 0.395623\n",
      "[5]\tvalid_0's binary_logloss: 0.3688\n",
      "[6]\tvalid_0's binary_logloss: 0.345681\n",
      "[7]\tvalid_0's binary_logloss: 0.325841\n",
      "[8]\tvalid_0's binary_logloss: 0.308439\n",
      "[9]\tvalid_0's binary_logloss: 0.293643\n",
      "[10]\tvalid_0's binary_logloss: 0.280687\n",
      "[11]\tvalid_0's binary_logloss: 0.269344\n",
      "[12]\tvalid_0's binary_logloss: 0.259021\n",
      "[13]\tvalid_0's binary_logloss: 0.249737\n",
      "[14]\tvalid_0's binary_logloss: 0.241849\n",
      "[15]\tvalid_0's binary_logloss: 0.234815\n",
      "[16]\tvalid_0's binary_logloss: 0.228266\n",
      "[17]\tvalid_0's binary_logloss: 0.222151\n",
      "[18]\tvalid_0's binary_logloss: 0.216616\n",
      "[19]\tvalid_0's binary_logloss: 0.211875\n",
      "[20]\tvalid_0's binary_logloss: 0.207233\n",
      "[21]\tvalid_0's binary_logloss: 0.20355\n",
      "[22]\tvalid_0's binary_logloss: 0.200058\n",
      "[23]\tvalid_0's binary_logloss: 0.19681\n",
      "[24]\tvalid_0's binary_logloss: 0.193918\n",
      "[25]\tvalid_0's binary_logloss: 0.191175\n",
      "[26]\tvalid_0's binary_logloss: 0.188455\n",
      "[27]\tvalid_0's binary_logloss: 0.18623\n",
      "[28]\tvalid_0's binary_logloss: 0.183957\n",
      "[29]\tvalid_0's binary_logloss: 0.181975\n",
      "[30]\tvalid_0's binary_logloss: 0.180227\n",
      "[31]\tvalid_0's binary_logloss: 0.178561\n",
      "[32]\tvalid_0's binary_logloss: 0.176731\n",
      "[33]\tvalid_0's binary_logloss: 0.175581\n",
      "[34]\tvalid_0's binary_logloss: 0.17409\n",
      "[35]\tvalid_0's binary_logloss: 0.172611\n",
      "[36]\tvalid_0's binary_logloss: 0.171614\n",
      "[37]\tvalid_0's binary_logloss: 0.17024\n",
      "[38]\tvalid_0's binary_logloss: 0.169254\n",
      "[39]\tvalid_0's binary_logloss: 0.168119\n",
      "[40]\tvalid_0's binary_logloss: 0.167238\n",
      "[41]\tvalid_0's binary_logloss: 0.166415\n",
      "[42]\tvalid_0's binary_logloss: 0.165171\n",
      "[43]\tvalid_0's binary_logloss: 0.164277\n",
      "[44]\tvalid_0's binary_logloss: 0.163463\n",
      "[45]\tvalid_0's binary_logloss: 0.162636\n",
      "[46]\tvalid_0's binary_logloss: 0.162071\n",
      "[47]\tvalid_0's binary_logloss: 0.161168\n",
      "[48]\tvalid_0's binary_logloss: 0.160524\n",
      "[49]\tvalid_0's binary_logloss: 0.160135\n",
      "[50]\tvalid_0's binary_logloss: 0.159802\n",
      "[51]\tvalid_0's binary_logloss: 0.159319\n",
      "[52]\tvalid_0's binary_logloss: 0.158825\n",
      "[53]\tvalid_0's binary_logloss: 0.158384\n",
      "[54]\tvalid_0's binary_logloss: 0.158168\n",
      "[55]\tvalid_0's binary_logloss: 0.157658\n",
      "[56]\tvalid_0's binary_logloss: 0.157355\n",
      "[57]\tvalid_0's binary_logloss: 0.156933\n",
      "[58]\tvalid_0's binary_logloss: 0.156564\n",
      "[59]\tvalid_0's binary_logloss: 0.156137\n",
      "[60]\tvalid_0's binary_logloss: 0.155374\n",
      "[61]\tvalid_0's binary_logloss: 0.154912\n",
      "[62]\tvalid_0's binary_logloss: 0.154488\n",
      "[63]\tvalid_0's binary_logloss: 0.154261\n",
      "[64]\tvalid_0's binary_logloss: 0.153742\n",
      "[65]\tvalid_0's binary_logloss: 0.153424\n",
      "[66]\tvalid_0's binary_logloss: 0.152793\n",
      "[67]\tvalid_0's binary_logloss: 0.152668\n",
      "[68]\tvalid_0's binary_logloss: 0.152463\n",
      "[69]\tvalid_0's binary_logloss: 0.152211\n",
      "[70]\tvalid_0's binary_logloss: 0.151806\n",
      "[71]\tvalid_0's binary_logloss: 0.151633\n",
      "[72]\tvalid_0's binary_logloss: 0.151454\n",
      "[73]\tvalid_0's binary_logloss: 0.151329\n",
      "[74]\tvalid_0's binary_logloss: 0.151005\n",
      "[75]\tvalid_0's binary_logloss: 0.150921\n",
      "[76]\tvalid_0's binary_logloss: 0.150725\n",
      "[77]\tvalid_0's binary_logloss: 0.150495\n",
      "[78]\tvalid_0's binary_logloss: 0.15022\n",
      "[79]\tvalid_0's binary_logloss: 0.150066\n",
      "[80]\tvalid_0's binary_logloss: 0.14986\n",
      "[81]\tvalid_0's binary_logloss: 0.149642\n",
      "[82]\tvalid_0's binary_logloss: 0.149398\n",
      "[83]\tvalid_0's binary_logloss: 0.149159\n",
      "[84]\tvalid_0's binary_logloss: 0.149052\n",
      "[85]\tvalid_0's binary_logloss: 0.148866\n",
      "[86]\tvalid_0's binary_logloss: 0.148526\n",
      "[87]\tvalid_0's binary_logloss: 0.148286\n",
      "[88]\tvalid_0's binary_logloss: 0.147905\n",
      "[89]\tvalid_0's binary_logloss: 0.147812\n",
      "[90]\tvalid_0's binary_logloss: 0.14763\n",
      "[91]\tvalid_0's binary_logloss: 0.147621\n",
      "[92]\tvalid_0's binary_logloss: 0.147418\n",
      "[93]\tvalid_0's binary_logloss: 0.147404\n",
      "[94]\tvalid_0's binary_logloss: 0.147172\n",
      "[95]\tvalid_0's binary_logloss: 0.14694\n",
      "[96]\tvalid_0's binary_logloss: 0.146731\n",
      "[97]\tvalid_0's binary_logloss: 0.146464\n",
      "[98]\tvalid_0's binary_logloss: 0.146302\n",
      "[99]\tvalid_0's binary_logloss: 0.146022\n",
      "[100]\tvalid_0's binary_logloss: 0.145955\n",
      "[101]\tvalid_0's binary_logloss: 0.145841\n",
      "[102]\tvalid_0's binary_logloss: 0.145754\n",
      "[103]\tvalid_0's binary_logloss: 0.145725\n",
      "[104]\tvalid_0's binary_logloss: 0.145816\n",
      "[105]\tvalid_0's binary_logloss: 0.145783\n",
      "[106]\tvalid_0's binary_logloss: 0.145532\n",
      "[107]\tvalid_0's binary_logloss: 0.145135\n",
      "[108]\tvalid_0's binary_logloss: 0.14507\n",
      "[109]\tvalid_0's binary_logloss: 0.145078\n",
      "[110]\tvalid_0's binary_logloss: 0.145065\n",
      "[111]\tvalid_0's binary_logloss: 0.145107\n",
      "[112]\tvalid_0's binary_logloss: 0.14509\n",
      "[113]\tvalid_0's binary_logloss: 0.145192\n",
      "[114]\tvalid_0's binary_logloss: 0.145027\n",
      "[115]\tvalid_0's binary_logloss: 0.144958\n",
      "[116]\tvalid_0's binary_logloss: 0.144871\n",
      "[117]\tvalid_0's binary_logloss: 0.144626\n",
      "[118]\tvalid_0's binary_logloss: 0.144684\n",
      "[119]\tvalid_0's binary_logloss: 0.144707\n",
      "[120]\tvalid_0's binary_logloss: 0.14467\n",
      "[121]\tvalid_0's binary_logloss: 0.14474\n",
      "[122]\tvalid_0's binary_logloss: 0.144715\n",
      "[123]\tvalid_0's binary_logloss: 0.144731\n",
      "[124]\tvalid_0's binary_logloss: 0.144916\n",
      "[125]\tvalid_0's binary_logloss: 0.144736\n",
      "[126]\tvalid_0's binary_logloss: 0.144537\n",
      "[127]\tvalid_0's binary_logloss: 0.144482\n",
      "[128]\tvalid_0's binary_logloss: 0.144649\n",
      "[129]\tvalid_0's binary_logloss: 0.14456\n",
      "[130]\tvalid_0's binary_logloss: 0.144636\n",
      "[131]\tvalid_0's binary_logloss: 0.144655\n",
      "[132]\tvalid_0's binary_logloss: 0.144559\n",
      "[133]\tvalid_0's binary_logloss: 0.14442\n",
      "[134]\tvalid_0's binary_logloss: 0.144557\n",
      "[135]\tvalid_0's binary_logloss: 0.144555\n",
      "[136]\tvalid_0's binary_logloss: 0.144451\n",
      "[137]\tvalid_0's binary_logloss: 0.144428\n",
      "[138]\tvalid_0's binary_logloss: 0.144599\n",
      "[139]\tvalid_0's binary_logloss: 0.144621\n",
      "[140]\tvalid_0's binary_logloss: 0.144693\n",
      "[141]\tvalid_0's binary_logloss: 0.144757\n",
      "[142]\tvalid_0's binary_logloss: 0.144683\n",
      "[143]\tvalid_0's binary_logloss: 0.144598\n",
      "[144]\tvalid_0's binary_logloss: 0.144501\n",
      "[145]\tvalid_0's binary_logloss: 0.144543\n",
      "[146]\tvalid_0's binary_logloss: 0.1444\n",
      "[147]\tvalid_0's binary_logloss: 0.14451\n",
      "[148]\tvalid_0's binary_logloss: 0.144504\n",
      "[149]\tvalid_0's binary_logloss: 0.14463\n",
      "[150]\tvalid_0's binary_logloss: 0.144821\n",
      "[151]\tvalid_0's binary_logloss: 0.14491\n",
      "[152]\tvalid_0's binary_logloss: 0.145075\n",
      "[153]\tvalid_0's binary_logloss: 0.145072\n",
      "[154]\tvalid_0's binary_logloss: 0.145179\n",
      "[155]\tvalid_0's binary_logloss: 0.145255\n",
      "[156]\tvalid_0's binary_logloss: 0.145229\n",
      "[157]\tvalid_0's binary_logloss: 0.145214\n",
      "[158]\tvalid_0's binary_logloss: 0.145145\n",
      "[159]\tvalid_0's binary_logloss: 0.145018\n",
      "[160]\tvalid_0's binary_logloss: 0.145004\n",
      "[161]\tvalid_0's binary_logloss: 0.145039\n",
      "[162]\tvalid_0's binary_logloss: 0.144989\n",
      "[163]\tvalid_0's binary_logloss: 0.145092\n",
      "[164]\tvalid_0's binary_logloss: 0.145068\n",
      "[165]\tvalid_0's binary_logloss: 0.145168\n",
      "[166]\tvalid_0's binary_logloss: 0.145289\n",
      "[167]\tvalid_0's binary_logloss: 0.145307\n",
      "[168]\tvalid_0's binary_logloss: 0.145342\n",
      "[169]\tvalid_0's binary_logloss: 0.145332\n",
      "[170]\tvalid_0's binary_logloss: 0.145397\n",
      "[171]\tvalid_0's binary_logloss: 0.14532\n",
      "[172]\tvalid_0's binary_logloss: 0.145321\n",
      "[173]\tvalid_0's binary_logloss: 0.145446\n",
      "[174]\tvalid_0's binary_logloss: 0.145307\n",
      "[175]\tvalid_0's binary_logloss: 0.145216\n",
      "[176]\tvalid_0's binary_logloss: 0.14522\n",
      "[177]\tvalid_0's binary_logloss: 0.145325\n",
      "[178]\tvalid_0's binary_logloss: 0.145422\n",
      "[179]\tvalid_0's binary_logloss: 0.145486\n",
      "[180]\tvalid_0's binary_logloss: 0.145627\n",
      "[181]\tvalid_0's binary_logloss: 0.145761\n",
      "[182]\tvalid_0's binary_logloss: 0.145883\n",
      "[183]\tvalid_0's binary_logloss: 0.145888\n",
      "[184]\tvalid_0's binary_logloss: 0.145924\n",
      "[185]\tvalid_0's binary_logloss: 0.145831\n",
      "[186]\tvalid_0's binary_logloss: 0.145966\n",
      "[187]\tvalid_0's binary_logloss: 0.146043\n",
      "[188]\tvalid_0's binary_logloss: 0.146136\n",
      "[189]\tvalid_0's binary_logloss: 0.146226\n",
      "[190]\tvalid_0's binary_logloss: 0.146328\n",
      "[191]\tvalid_0's binary_logloss: 0.146222\n",
      "[192]\tvalid_0's binary_logloss: 0.146257\n",
      "[193]\tvalid_0's binary_logloss: 0.146244\n",
      "[194]\tvalid_0's binary_logloss: 0.146193\n",
      "[195]\tvalid_0's binary_logloss: 0.146305\n",
      "[196]\tvalid_0's binary_logloss: 0.146376\n",
      "[197]\tvalid_0's binary_logloss: 0.146452\n",
      "[198]\tvalid_0's binary_logloss: 0.146427\n",
      "[199]\tvalid_0's binary_logloss: 0.146544\n",
      "[200]\tvalid_0's binary_logloss: 0.146653\n",
      "[201]\tvalid_0's binary_logloss: 0.146887\n",
      "[202]\tvalid_0's binary_logloss: 0.146941\n",
      "[203]\tvalid_0's binary_logloss: 0.146938\n",
      "[204]\tvalid_0's binary_logloss: 0.147159\n",
      "[205]\tvalid_0's binary_logloss: 0.147167\n",
      "[206]\tvalid_0's binary_logloss: 0.14734\n",
      "[207]\tvalid_0's binary_logloss: 0.147548\n",
      "[208]\tvalid_0's binary_logloss: 0.147636\n",
      "[209]\tvalid_0's binary_logloss: 0.147681\n",
      "[210]\tvalid_0's binary_logloss: 0.147704\n",
      "[211]\tvalid_0's binary_logloss: 0.14776\n",
      "[212]\tvalid_0's binary_logloss: 0.147898\n",
      "[213]\tvalid_0's binary_logloss: 0.147955\n",
      "[214]\tvalid_0's binary_logloss: 0.148051\n",
      "[215]\tvalid_0's binary_logloss: 0.148138\n",
      "[216]\tvalid_0's binary_logloss: 0.148307\n",
      "[217]\tvalid_0's binary_logloss: 0.148332\n",
      "[218]\tvalid_0's binary_logloss: 0.148447\n",
      "[219]\tvalid_0's binary_logloss: 0.148525\n",
      "[220]\tvalid_0's binary_logloss: 0.148652\n",
      "[221]\tvalid_0's binary_logloss: 0.148769\n",
      "[222]\tvalid_0's binary_logloss: 0.148785\n",
      "[223]\tvalid_0's binary_logloss: 0.148953\n",
      "[224]\tvalid_0's binary_logloss: 0.14899\n",
      "[225]\tvalid_0's binary_logloss: 0.149123\n",
      "[226]\tvalid_0's binary_logloss: 0.149188\n",
      "[227]\tvalid_0's binary_logloss: 0.149218\n",
      "[228]\tvalid_0's binary_logloss: 0.149379\n",
      "[229]\tvalid_0's binary_logloss: 0.149617\n",
      "[230]\tvalid_0's binary_logloss: 0.14973\n",
      "[231]\tvalid_0's binary_logloss: 0.149797\n",
      "[232]\tvalid_0's binary_logloss: 0.149821\n",
      "[233]\tvalid_0's binary_logloss: 0.149921\n",
      "[234]\tvalid_0's binary_logloss: 0.150072\n",
      "[235]\tvalid_0's binary_logloss: 0.150143\n",
      "[236]\tvalid_0's binary_logloss: 0.150235\n",
      "[237]\tvalid_0's binary_logloss: 0.150345\n",
      "[238]\tvalid_0's binary_logloss: 0.150386\n",
      "[239]\tvalid_0's binary_logloss: 0.150516\n",
      "[240]\tvalid_0's binary_logloss: 0.150613\n",
      "[241]\tvalid_0's binary_logloss: 0.150671\n",
      "[242]\tvalid_0's binary_logloss: 0.150865\n",
      "[243]\tvalid_0's binary_logloss: 0.150982\n",
      "[244]\tvalid_0's binary_logloss: 0.151072\n",
      "[245]\tvalid_0's binary_logloss: 0.151116\n",
      "[246]\tvalid_0's binary_logloss: 0.151167\n",
      "[247]\tvalid_0's binary_logloss: 0.151327\n",
      "[248]\tvalid_0's binary_logloss: 0.15131\n",
      "[249]\tvalid_0's binary_logloss: 0.151503\n",
      "[250]\tvalid_0's binary_logloss: 0.151615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9000979431929481"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8,random_state=2)\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                        n_estimators=400,\n",
    "                        max_bin=255,\n",
    "                        max_depth=40, \n",
    "                        num_iterations=250, \n",
    "                        random_state=11,\n",
    "                        num_leaves = 150,\n",
    "                        silent=False)\n",
    "\n",
    "lg.fit(X_train,y_train, eval_set=(X_test,y_test))\n",
    "pred = lg.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 12200, number of negative: 32494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5916\n",
      "[LightGBM] [Info] Number of data points in the train set: 44694, number of used features: 69\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.272967 -> initscore=-0.979620\n",
      "[LightGBM] [Info] Start training from score -0.979620\n",
      "[1]\tvalid_0's binary_logloss: 0.516577\n",
      "[2]\tvalid_0's binary_logloss: 0.467335\n",
      "[3]\tvalid_0's binary_logloss: 0.42784\n",
      "[4]\tvalid_0's binary_logloss: 0.395623\n",
      "[5]\tvalid_0's binary_logloss: 0.3688\n",
      "[6]\tvalid_0's binary_logloss: 0.345681\n",
      "[7]\tvalid_0's binary_logloss: 0.325841\n",
      "[8]\tvalid_0's binary_logloss: 0.308439\n",
      "[9]\tvalid_0's binary_logloss: 0.293643\n",
      "[10]\tvalid_0's binary_logloss: 0.280687\n",
      "[11]\tvalid_0's binary_logloss: 0.269344\n",
      "[12]\tvalid_0's binary_logloss: 0.259021\n",
      "[13]\tvalid_0's binary_logloss: 0.249737\n",
      "[14]\tvalid_0's binary_logloss: 0.241849\n",
      "[15]\tvalid_0's binary_logloss: 0.234815\n",
      "[16]\tvalid_0's binary_logloss: 0.228266\n",
      "[17]\tvalid_0's binary_logloss: 0.222151\n",
      "[18]\tvalid_0's binary_logloss: 0.216616\n",
      "[19]\tvalid_0's binary_logloss: 0.211875\n",
      "[20]\tvalid_0's binary_logloss: 0.207233\n",
      "[21]\tvalid_0's binary_logloss: 0.20355\n",
      "[22]\tvalid_0's binary_logloss: 0.200058\n",
      "[23]\tvalid_0's binary_logloss: 0.19681\n",
      "[24]\tvalid_0's binary_logloss: 0.193918\n",
      "[25]\tvalid_0's binary_logloss: 0.191175\n",
      "[26]\tvalid_0's binary_logloss: 0.188455\n",
      "[27]\tvalid_0's binary_logloss: 0.18623\n",
      "[28]\tvalid_0's binary_logloss: 0.183957\n",
      "[29]\tvalid_0's binary_logloss: 0.181975\n",
      "[30]\tvalid_0's binary_logloss: 0.180227\n",
      "[31]\tvalid_0's binary_logloss: 0.178561\n",
      "[32]\tvalid_0's binary_logloss: 0.176731\n",
      "[33]\tvalid_0's binary_logloss: 0.175581\n",
      "[34]\tvalid_0's binary_logloss: 0.17409\n",
      "[35]\tvalid_0's binary_logloss: 0.172611\n",
      "[36]\tvalid_0's binary_logloss: 0.171614\n",
      "[37]\tvalid_0's binary_logloss: 0.17024\n",
      "[38]\tvalid_0's binary_logloss: 0.169254\n",
      "[39]\tvalid_0's binary_logloss: 0.168119\n",
      "[40]\tvalid_0's binary_logloss: 0.167238\n",
      "[41]\tvalid_0's binary_logloss: 0.166415\n",
      "[42]\tvalid_0's binary_logloss: 0.165171\n",
      "[43]\tvalid_0's binary_logloss: 0.164277\n",
      "[44]\tvalid_0's binary_logloss: 0.163463\n",
      "[45]\tvalid_0's binary_logloss: 0.162636\n",
      "[46]\tvalid_0's binary_logloss: 0.162071\n",
      "[47]\tvalid_0's binary_logloss: 0.161168\n",
      "[48]\tvalid_0's binary_logloss: 0.160524\n",
      "[49]\tvalid_0's binary_logloss: 0.160135\n",
      "[50]\tvalid_0's binary_logloss: 0.159802\n",
      "[51]\tvalid_0's binary_logloss: 0.159319\n",
      "[52]\tvalid_0's binary_logloss: 0.158825\n",
      "[53]\tvalid_0's binary_logloss: 0.158384\n",
      "[54]\tvalid_0's binary_logloss: 0.158168\n",
      "[55]\tvalid_0's binary_logloss: 0.157658\n",
      "[56]\tvalid_0's binary_logloss: 0.157355\n",
      "[57]\tvalid_0's binary_logloss: 0.156933\n",
      "[58]\tvalid_0's binary_logloss: 0.156564\n",
      "[59]\tvalid_0's binary_logloss: 0.156137\n",
      "[60]\tvalid_0's binary_logloss: 0.155374\n",
      "[61]\tvalid_0's binary_logloss: 0.154912\n",
      "[62]\tvalid_0's binary_logloss: 0.154488\n",
      "[63]\tvalid_0's binary_logloss: 0.154261\n",
      "[64]\tvalid_0's binary_logloss: 0.153742\n",
      "[65]\tvalid_0's binary_logloss: 0.153424\n",
      "[66]\tvalid_0's binary_logloss: 0.152793\n",
      "[67]\tvalid_0's binary_logloss: 0.152668\n",
      "[68]\tvalid_0's binary_logloss: 0.152463\n",
      "[69]\tvalid_0's binary_logloss: 0.152211\n",
      "[70]\tvalid_0's binary_logloss: 0.151806\n",
      "[71]\tvalid_0's binary_logloss: 0.151633\n",
      "[72]\tvalid_0's binary_logloss: 0.151454\n",
      "[73]\tvalid_0's binary_logloss: 0.151329\n",
      "[74]\tvalid_0's binary_logloss: 0.151005\n",
      "[75]\tvalid_0's binary_logloss: 0.150921\n",
      "[76]\tvalid_0's binary_logloss: 0.150725\n",
      "[77]\tvalid_0's binary_logloss: 0.150495\n",
      "[78]\tvalid_0's binary_logloss: 0.15022\n",
      "[79]\tvalid_0's binary_logloss: 0.150066\n",
      "[80]\tvalid_0's binary_logloss: 0.14986\n",
      "[81]\tvalid_0's binary_logloss: 0.149642\n",
      "[82]\tvalid_0's binary_logloss: 0.149398\n",
      "[83]\tvalid_0's binary_logloss: 0.149159\n",
      "[84]\tvalid_0's binary_logloss: 0.149052\n",
      "[85]\tvalid_0's binary_logloss: 0.148866\n",
      "[86]\tvalid_0's binary_logloss: 0.148526\n",
      "[87]\tvalid_0's binary_logloss: 0.148286\n",
      "[88]\tvalid_0's binary_logloss: 0.147905\n",
      "[89]\tvalid_0's binary_logloss: 0.147812\n",
      "[90]\tvalid_0's binary_logloss: 0.14763\n",
      "[91]\tvalid_0's binary_logloss: 0.147621\n",
      "[92]\tvalid_0's binary_logloss: 0.147418\n",
      "[93]\tvalid_0's binary_logloss: 0.147404\n",
      "[94]\tvalid_0's binary_logloss: 0.147172\n",
      "[95]\tvalid_0's binary_logloss: 0.14694\n",
      "[96]\tvalid_0's binary_logloss: 0.146731\n",
      "[97]\tvalid_0's binary_logloss: 0.146464\n",
      "[98]\tvalid_0's binary_logloss: 0.146302\n",
      "[99]\tvalid_0's binary_logloss: 0.146022\n",
      "[100]\tvalid_0's binary_logloss: 0.145955\n",
      "[101]\tvalid_0's binary_logloss: 0.145841\n",
      "[102]\tvalid_0's binary_logloss: 0.145754\n",
      "[103]\tvalid_0's binary_logloss: 0.145725\n",
      "[104]\tvalid_0's binary_logloss: 0.145816\n",
      "[105]\tvalid_0's binary_logloss: 0.145783\n",
      "[106]\tvalid_0's binary_logloss: 0.145532\n",
      "[107]\tvalid_0's binary_logloss: 0.145135\n",
      "[108]\tvalid_0's binary_logloss: 0.14507\n",
      "[109]\tvalid_0's binary_logloss: 0.145078\n",
      "[110]\tvalid_0's binary_logloss: 0.145065\n",
      "[111]\tvalid_0's binary_logloss: 0.145107\n",
      "[112]\tvalid_0's binary_logloss: 0.14509\n",
      "[113]\tvalid_0's binary_logloss: 0.145192\n",
      "[114]\tvalid_0's binary_logloss: 0.145027\n",
      "[115]\tvalid_0's binary_logloss: 0.144958\n",
      "[116]\tvalid_0's binary_logloss: 0.144871\n",
      "[117]\tvalid_0's binary_logloss: 0.144626\n",
      "[118]\tvalid_0's binary_logloss: 0.144684\n",
      "[119]\tvalid_0's binary_logloss: 0.144707\n",
      "[120]\tvalid_0's binary_logloss: 0.14467\n",
      "[121]\tvalid_0's binary_logloss: 0.14474\n",
      "[122]\tvalid_0's binary_logloss: 0.144715\n",
      "[123]\tvalid_0's binary_logloss: 0.144731\n",
      "[124]\tvalid_0's binary_logloss: 0.144916\n",
      "[125]\tvalid_0's binary_logloss: 0.144736\n",
      "[126]\tvalid_0's binary_logloss: 0.144537\n",
      "[127]\tvalid_0's binary_logloss: 0.144482\n",
      "[128]\tvalid_0's binary_logloss: 0.144649\n",
      "[129]\tvalid_0's binary_logloss: 0.14456\n",
      "[130]\tvalid_0's binary_logloss: 0.144636\n",
      "[131]\tvalid_0's binary_logloss: 0.144655\n",
      "[132]\tvalid_0's binary_logloss: 0.144559\n",
      "[133]\tvalid_0's binary_logloss: 0.14442\n",
      "[134]\tvalid_0's binary_logloss: 0.144557\n",
      "[135]\tvalid_0's binary_logloss: 0.144555\n",
      "[136]\tvalid_0's binary_logloss: 0.144451\n",
      "[137]\tvalid_0's binary_logloss: 0.144428\n",
      "[138]\tvalid_0's binary_logloss: 0.144599\n",
      "[139]\tvalid_0's binary_logloss: 0.144621\n",
      "[140]\tvalid_0's binary_logloss: 0.144693\n",
      "[141]\tvalid_0's binary_logloss: 0.144757\n",
      "[142]\tvalid_0's binary_logloss: 0.144683\n",
      "[143]\tvalid_0's binary_logloss: 0.144598\n",
      "[144]\tvalid_0's binary_logloss: 0.144501\n",
      "[145]\tvalid_0's binary_logloss: 0.144543\n",
      "[146]\tvalid_0's binary_logloss: 0.1444\n",
      "[147]\tvalid_0's binary_logloss: 0.14451\n",
      "[148]\tvalid_0's binary_logloss: 0.144504\n",
      "[149]\tvalid_0's binary_logloss: 0.14463\n",
      "[150]\tvalid_0's binary_logloss: 0.144821\n",
      "[151]\tvalid_0's binary_logloss: 0.14491\n",
      "[152]\tvalid_0's binary_logloss: 0.145075\n",
      "[153]\tvalid_0's binary_logloss: 0.145072\n",
      "[154]\tvalid_0's binary_logloss: 0.145179\n",
      "[155]\tvalid_0's binary_logloss: 0.145255\n",
      "[156]\tvalid_0's binary_logloss: 0.145229\n",
      "[157]\tvalid_0's binary_logloss: 0.145214\n",
      "[158]\tvalid_0's binary_logloss: 0.145145\n",
      "[159]\tvalid_0's binary_logloss: 0.145018\n",
      "[160]\tvalid_0's binary_logloss: 0.145004\n",
      "[161]\tvalid_0's binary_logloss: 0.145039\n",
      "[162]\tvalid_0's binary_logloss: 0.144989\n",
      "[163]\tvalid_0's binary_logloss: 0.145092\n",
      "[164]\tvalid_0's binary_logloss: 0.145068\n",
      "[165]\tvalid_0's binary_logloss: 0.145168\n",
      "[166]\tvalid_0's binary_logloss: 0.145289\n",
      "[167]\tvalid_0's binary_logloss: 0.145307\n",
      "[168]\tvalid_0's binary_logloss: 0.145342\n",
      "[169]\tvalid_0's binary_logloss: 0.145332\n",
      "[170]\tvalid_0's binary_logloss: 0.145397\n",
      "[171]\tvalid_0's binary_logloss: 0.14532\n",
      "[172]\tvalid_0's binary_logloss: 0.145321\n",
      "[173]\tvalid_0's binary_logloss: 0.145446\n",
      "[174]\tvalid_0's binary_logloss: 0.145307\n",
      "[175]\tvalid_0's binary_logloss: 0.145216\n",
      "[176]\tvalid_0's binary_logloss: 0.14522\n",
      "[177]\tvalid_0's binary_logloss: 0.145325\n",
      "[178]\tvalid_0's binary_logloss: 0.145422\n",
      "[179]\tvalid_0's binary_logloss: 0.145486\n",
      "[180]\tvalid_0's binary_logloss: 0.145627\n",
      "[181]\tvalid_0's binary_logloss: 0.145761\n",
      "[182]\tvalid_0's binary_logloss: 0.145883\n",
      "[183]\tvalid_0's binary_logloss: 0.145888\n",
      "[184]\tvalid_0's binary_logloss: 0.145924\n",
      "[185]\tvalid_0's binary_logloss: 0.145831\n",
      "[186]\tvalid_0's binary_logloss: 0.145966\n",
      "[187]\tvalid_0's binary_logloss: 0.146043\n",
      "[188]\tvalid_0's binary_logloss: 0.146136\n",
      "[189]\tvalid_0's binary_logloss: 0.146226\n",
      "[190]\tvalid_0's binary_logloss: 0.146328\n",
      "[191]\tvalid_0's binary_logloss: 0.146222\n",
      "[192]\tvalid_0's binary_logloss: 0.146257\n",
      "[193]\tvalid_0's binary_logloss: 0.146244\n",
      "[194]\tvalid_0's binary_logloss: 0.146193\n",
      "[195]\tvalid_0's binary_logloss: 0.146305\n",
      "[196]\tvalid_0's binary_logloss: 0.146376\n",
      "[197]\tvalid_0's binary_logloss: 0.146452\n",
      "[198]\tvalid_0's binary_logloss: 0.146427\n",
      "[199]\tvalid_0's binary_logloss: 0.146544\n",
      "[200]\tvalid_0's binary_logloss: 0.146653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.900147082856676"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8,random_state=2)\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                        n_estimators=400,\n",
    "                        max_bin=255,\n",
    "                        max_depth=40, \n",
    "                        num_iterations=200, \n",
    "                        random_state=11,\n",
    "                        num_leaves = 150,\n",
    "                        silent=False)\n",
    "\n",
    "lg.fit(X_train,y_train, eval_set=(X_test,y_test))\n",
    "pred = lg.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 12200, number of negative: 32494\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5916\n",
      "[LightGBM] [Info] Number of data points in the train set: 44694, number of used features: 69\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.272967 -> initscore=-0.979620\n",
      "[LightGBM] [Info] Start training from score -0.979620\n",
      "[1]\tvalid_0's binary_logloss: 0.516577\n",
      "[2]\tvalid_0's binary_logloss: 0.467335\n",
      "[3]\tvalid_0's binary_logloss: 0.42784\n",
      "[4]\tvalid_0's binary_logloss: 0.395623\n",
      "[5]\tvalid_0's binary_logloss: 0.3688\n",
      "[6]\tvalid_0's binary_logloss: 0.345681\n",
      "[7]\tvalid_0's binary_logloss: 0.325841\n",
      "[8]\tvalid_0's binary_logloss: 0.308439\n",
      "[9]\tvalid_0's binary_logloss: 0.293643\n",
      "[10]\tvalid_0's binary_logloss: 0.280687\n",
      "[11]\tvalid_0's binary_logloss: 0.269344\n",
      "[12]\tvalid_0's binary_logloss: 0.259021\n",
      "[13]\tvalid_0's binary_logloss: 0.249737\n",
      "[14]\tvalid_0's binary_logloss: 0.241849\n",
      "[15]\tvalid_0's binary_logloss: 0.234815\n",
      "[16]\tvalid_0's binary_logloss: 0.228266\n",
      "[17]\tvalid_0's binary_logloss: 0.222151\n",
      "[18]\tvalid_0's binary_logloss: 0.216616\n",
      "[19]\tvalid_0's binary_logloss: 0.211875\n",
      "[20]\tvalid_0's binary_logloss: 0.207233\n",
      "[21]\tvalid_0's binary_logloss: 0.20355\n",
      "[22]\tvalid_0's binary_logloss: 0.200058\n",
      "[23]\tvalid_0's binary_logloss: 0.19681\n",
      "[24]\tvalid_0's binary_logloss: 0.193918\n",
      "[25]\tvalid_0's binary_logloss: 0.191175\n",
      "[26]\tvalid_0's binary_logloss: 0.188455\n",
      "[27]\tvalid_0's binary_logloss: 0.18623\n",
      "[28]\tvalid_0's binary_logloss: 0.183957\n",
      "[29]\tvalid_0's binary_logloss: 0.181975\n",
      "[30]\tvalid_0's binary_logloss: 0.180227\n",
      "[31]\tvalid_0's binary_logloss: 0.178561\n",
      "[32]\tvalid_0's binary_logloss: 0.176731\n",
      "[33]\tvalid_0's binary_logloss: 0.175581\n",
      "[34]\tvalid_0's binary_logloss: 0.17409\n",
      "[35]\tvalid_0's binary_logloss: 0.172611\n",
      "[36]\tvalid_0's binary_logloss: 0.171614\n",
      "[37]\tvalid_0's binary_logloss: 0.17024\n",
      "[38]\tvalid_0's binary_logloss: 0.169254\n",
      "[39]\tvalid_0's binary_logloss: 0.168119\n",
      "[40]\tvalid_0's binary_logloss: 0.167238\n",
      "[41]\tvalid_0's binary_logloss: 0.166415\n",
      "[42]\tvalid_0's binary_logloss: 0.165171\n",
      "[43]\tvalid_0's binary_logloss: 0.164277\n",
      "[44]\tvalid_0's binary_logloss: 0.163463\n",
      "[45]\tvalid_0's binary_logloss: 0.162636\n",
      "[46]\tvalid_0's binary_logloss: 0.162071\n",
      "[47]\tvalid_0's binary_logloss: 0.161168\n",
      "[48]\tvalid_0's binary_logloss: 0.160524\n",
      "[49]\tvalid_0's binary_logloss: 0.160135\n",
      "[50]\tvalid_0's binary_logloss: 0.159802\n",
      "[51]\tvalid_0's binary_logloss: 0.159319\n",
      "[52]\tvalid_0's binary_logloss: 0.158825\n",
      "[53]\tvalid_0's binary_logloss: 0.158384\n",
      "[54]\tvalid_0's binary_logloss: 0.158168\n",
      "[55]\tvalid_0's binary_logloss: 0.157658\n",
      "[56]\tvalid_0's binary_logloss: 0.157355\n",
      "[57]\tvalid_0's binary_logloss: 0.156933\n",
      "[58]\tvalid_0's binary_logloss: 0.156564\n",
      "[59]\tvalid_0's binary_logloss: 0.156137\n",
      "[60]\tvalid_0's binary_logloss: 0.155374\n",
      "[61]\tvalid_0's binary_logloss: 0.154912\n",
      "[62]\tvalid_0's binary_logloss: 0.154488\n",
      "[63]\tvalid_0's binary_logloss: 0.154261\n",
      "[64]\tvalid_0's binary_logloss: 0.153742\n",
      "[65]\tvalid_0's binary_logloss: 0.153424\n",
      "[66]\tvalid_0's binary_logloss: 0.152793\n",
      "[67]\tvalid_0's binary_logloss: 0.152668\n",
      "[68]\tvalid_0's binary_logloss: 0.152463\n",
      "[69]\tvalid_0's binary_logloss: 0.152211\n",
      "[70]\tvalid_0's binary_logloss: 0.151806\n",
      "[71]\tvalid_0's binary_logloss: 0.151633\n",
      "[72]\tvalid_0's binary_logloss: 0.151454\n",
      "[73]\tvalid_0's binary_logloss: 0.151329\n",
      "[74]\tvalid_0's binary_logloss: 0.151005\n",
      "[75]\tvalid_0's binary_logloss: 0.150921\n",
      "[76]\tvalid_0's binary_logloss: 0.150725\n",
      "[77]\tvalid_0's binary_logloss: 0.150495\n",
      "[78]\tvalid_0's binary_logloss: 0.15022\n",
      "[79]\tvalid_0's binary_logloss: 0.150066\n",
      "[80]\tvalid_0's binary_logloss: 0.14986\n",
      "[81]\tvalid_0's binary_logloss: 0.149642\n",
      "[82]\tvalid_0's binary_logloss: 0.149398\n",
      "[83]\tvalid_0's binary_logloss: 0.149159\n",
      "[84]\tvalid_0's binary_logloss: 0.149052\n",
      "[85]\tvalid_0's binary_logloss: 0.148866\n",
      "[86]\tvalid_0's binary_logloss: 0.148526\n",
      "[87]\tvalid_0's binary_logloss: 0.148286\n",
      "[88]\tvalid_0's binary_logloss: 0.147905\n",
      "[89]\tvalid_0's binary_logloss: 0.147812\n",
      "[90]\tvalid_0's binary_logloss: 0.14763\n",
      "[91]\tvalid_0's binary_logloss: 0.147621\n",
      "[92]\tvalid_0's binary_logloss: 0.147418\n",
      "[93]\tvalid_0's binary_logloss: 0.147404\n",
      "[94]\tvalid_0's binary_logloss: 0.147172\n",
      "[95]\tvalid_0's binary_logloss: 0.14694\n",
      "[96]\tvalid_0's binary_logloss: 0.146731\n",
      "[97]\tvalid_0's binary_logloss: 0.146464\n",
      "[98]\tvalid_0's binary_logloss: 0.146302\n",
      "[99]\tvalid_0's binary_logloss: 0.146022\n",
      "[100]\tvalid_0's binary_logloss: 0.145955\n",
      "[101]\tvalid_0's binary_logloss: 0.145841\n",
      "[102]\tvalid_0's binary_logloss: 0.145754\n",
      "[103]\tvalid_0's binary_logloss: 0.145725\n",
      "[104]\tvalid_0's binary_logloss: 0.145816\n",
      "[105]\tvalid_0's binary_logloss: 0.145783\n",
      "[106]\tvalid_0's binary_logloss: 0.145532\n",
      "[107]\tvalid_0's binary_logloss: 0.145135\n",
      "[108]\tvalid_0's binary_logloss: 0.14507\n",
      "[109]\tvalid_0's binary_logloss: 0.145078\n",
      "[110]\tvalid_0's binary_logloss: 0.145065\n",
      "[111]\tvalid_0's binary_logloss: 0.145107\n",
      "[112]\tvalid_0's binary_logloss: 0.14509\n",
      "[113]\tvalid_0's binary_logloss: 0.145192\n",
      "[114]\tvalid_0's binary_logloss: 0.145027\n",
      "[115]\tvalid_0's binary_logloss: 0.144958\n",
      "[116]\tvalid_0's binary_logloss: 0.144871\n",
      "[117]\tvalid_0's binary_logloss: 0.144626\n",
      "[118]\tvalid_0's binary_logloss: 0.144684\n",
      "[119]\tvalid_0's binary_logloss: 0.144707\n",
      "[120]\tvalid_0's binary_logloss: 0.14467\n",
      "[121]\tvalid_0's binary_logloss: 0.14474\n",
      "[122]\tvalid_0's binary_logloss: 0.144715\n",
      "[123]\tvalid_0's binary_logloss: 0.144731\n",
      "[124]\tvalid_0's binary_logloss: 0.144916\n",
      "[125]\tvalid_0's binary_logloss: 0.144736\n",
      "[126]\tvalid_0's binary_logloss: 0.144537\n",
      "[127]\tvalid_0's binary_logloss: 0.144482\n",
      "[128]\tvalid_0's binary_logloss: 0.144649\n",
      "[129]\tvalid_0's binary_logloss: 0.14456\n",
      "[130]\tvalid_0's binary_logloss: 0.144636\n",
      "[131]\tvalid_0's binary_logloss: 0.144655\n",
      "[132]\tvalid_0's binary_logloss: 0.144559\n",
      "[133]\tvalid_0's binary_logloss: 0.14442\n",
      "[134]\tvalid_0's binary_logloss: 0.144557\n",
      "[135]\tvalid_0's binary_logloss: 0.144555\n",
      "[136]\tvalid_0's binary_logloss: 0.144451\n",
      "[137]\tvalid_0's binary_logloss: 0.144428\n",
      "[138]\tvalid_0's binary_logloss: 0.144599\n",
      "[139]\tvalid_0's binary_logloss: 0.144621\n",
      "[140]\tvalid_0's binary_logloss: 0.144693\n",
      "[141]\tvalid_0's binary_logloss: 0.144757\n",
      "[142]\tvalid_0's binary_logloss: 0.144683\n",
      "[143]\tvalid_0's binary_logloss: 0.144598\n",
      "[144]\tvalid_0's binary_logloss: 0.144501\n",
      "[145]\tvalid_0's binary_logloss: 0.144543\n",
      "[146]\tvalid_0's binary_logloss: 0.1444\n",
      "[147]\tvalid_0's binary_logloss: 0.14451\n",
      "[148]\tvalid_0's binary_logloss: 0.144504\n",
      "[149]\tvalid_0's binary_logloss: 0.14463\n",
      "[150]\tvalid_0's binary_logloss: 0.144821\n",
      "[151]\tvalid_0's binary_logloss: 0.14491\n",
      "[152]\tvalid_0's binary_logloss: 0.145075\n",
      "[153]\tvalid_0's binary_logloss: 0.145072\n",
      "[154]\tvalid_0's binary_logloss: 0.145179\n",
      "[155]\tvalid_0's binary_logloss: 0.145255\n",
      "[156]\tvalid_0's binary_logloss: 0.145229\n",
      "[157]\tvalid_0's binary_logloss: 0.145214\n",
      "[158]\tvalid_0's binary_logloss: 0.145145\n",
      "[159]\tvalid_0's binary_logloss: 0.145018\n",
      "[160]\tvalid_0's binary_logloss: 0.145004\n",
      "[161]\tvalid_0's binary_logloss: 0.145039\n",
      "[162]\tvalid_0's binary_logloss: 0.144989\n",
      "[163]\tvalid_0's binary_logloss: 0.145092\n",
      "[164]\tvalid_0's binary_logloss: 0.145068\n",
      "[165]\tvalid_0's binary_logloss: 0.145168\n",
      "[166]\tvalid_0's binary_logloss: 0.145289\n",
      "[167]\tvalid_0's binary_logloss: 0.145307\n",
      "[168]\tvalid_0's binary_logloss: 0.145342\n",
      "[169]\tvalid_0's binary_logloss: 0.145332\n",
      "[170]\tvalid_0's binary_logloss: 0.145397\n",
      "[171]\tvalid_0's binary_logloss: 0.14532\n",
      "[172]\tvalid_0's binary_logloss: 0.145321\n",
      "[173]\tvalid_0's binary_logloss: 0.145446\n",
      "[174]\tvalid_0's binary_logloss: 0.145307\n",
      "[175]\tvalid_0's binary_logloss: 0.145216\n",
      "[176]\tvalid_0's binary_logloss: 0.14522\n",
      "[177]\tvalid_0's binary_logloss: 0.145325\n",
      "[178]\tvalid_0's binary_logloss: 0.145422\n",
      "[179]\tvalid_0's binary_logloss: 0.145486\n",
      "[180]\tvalid_0's binary_logloss: 0.145627\n",
      "[181]\tvalid_0's binary_logloss: 0.145761\n",
      "[182]\tvalid_0's binary_logloss: 0.145883\n",
      "[183]\tvalid_0's binary_logloss: 0.145888\n",
      "[184]\tvalid_0's binary_logloss: 0.145924\n",
      "[185]\tvalid_0's binary_logloss: 0.145831\n",
      "[186]\tvalid_0's binary_logloss: 0.145966\n",
      "[187]\tvalid_0's binary_logloss: 0.146043\n",
      "[188]\tvalid_0's binary_logloss: 0.146136\n",
      "[189]\tvalid_0's binary_logloss: 0.146226\n",
      "[190]\tvalid_0's binary_logloss: 0.146328\n",
      "[191]\tvalid_0's binary_logloss: 0.146222\n",
      "[192]\tvalid_0's binary_logloss: 0.146257\n",
      "[193]\tvalid_0's binary_logloss: 0.146244\n",
      "[194]\tvalid_0's binary_logloss: 0.146193\n",
      "[195]\tvalid_0's binary_logloss: 0.146305\n",
      "[196]\tvalid_0's binary_logloss: 0.146376\n",
      "[197]\tvalid_0's binary_logloss: 0.146452\n",
      "[198]\tvalid_0's binary_logloss: 0.146427\n",
      "[199]\tvalid_0's binary_logloss: 0.146544\n",
      "[200]\tvalid_0's binary_logloss: 0.146653\n",
      "[201]\tvalid_0's binary_logloss: 0.146887\n",
      "[202]\tvalid_0's binary_logloss: 0.146941\n",
      "[203]\tvalid_0's binary_logloss: 0.146938\n",
      "[204]\tvalid_0's binary_logloss: 0.147159\n",
      "[205]\tvalid_0's binary_logloss: 0.147167\n",
      "[206]\tvalid_0's binary_logloss: 0.14734\n",
      "[207]\tvalid_0's binary_logloss: 0.147548\n",
      "[208]\tvalid_0's binary_logloss: 0.147636\n",
      "[209]\tvalid_0's binary_logloss: 0.147681\n",
      "[210]\tvalid_0's binary_logloss: 0.147704\n",
      "[211]\tvalid_0's binary_logloss: 0.14776\n",
      "[212]\tvalid_0's binary_logloss: 0.147898\n",
      "[213]\tvalid_0's binary_logloss: 0.147955\n",
      "[214]\tvalid_0's binary_logloss: 0.148051\n",
      "[215]\tvalid_0's binary_logloss: 0.148138\n",
      "[216]\tvalid_0's binary_logloss: 0.148307\n",
      "[217]\tvalid_0's binary_logloss: 0.148332\n",
      "[218]\tvalid_0's binary_logloss: 0.148447\n",
      "[219]\tvalid_0's binary_logloss: 0.148525\n",
      "[220]\tvalid_0's binary_logloss: 0.148652\n",
      "[221]\tvalid_0's binary_logloss: 0.148769\n",
      "[222]\tvalid_0's binary_logloss: 0.148785\n",
      "[223]\tvalid_0's binary_logloss: 0.148953\n",
      "[224]\tvalid_0's binary_logloss: 0.14899\n",
      "[225]\tvalid_0's binary_logloss: 0.149123\n",
      "[226]\tvalid_0's binary_logloss: 0.149188\n",
      "[227]\tvalid_0's binary_logloss: 0.149218\n",
      "[228]\tvalid_0's binary_logloss: 0.149379\n",
      "[229]\tvalid_0's binary_logloss: 0.149617\n",
      "[230]\tvalid_0's binary_logloss: 0.14973\n",
      "[231]\tvalid_0's binary_logloss: 0.149797\n",
      "[232]\tvalid_0's binary_logloss: 0.149821\n",
      "[233]\tvalid_0's binary_logloss: 0.149921\n",
      "[234]\tvalid_0's binary_logloss: 0.150072\n",
      "[235]\tvalid_0's binary_logloss: 0.150143\n",
      "[236]\tvalid_0's binary_logloss: 0.150235\n",
      "[237]\tvalid_0's binary_logloss: 0.150345\n",
      "[238]\tvalid_0's binary_logloss: 0.150386\n",
      "[239]\tvalid_0's binary_logloss: 0.150516\n",
      "[240]\tvalid_0's binary_logloss: 0.150613\n",
      "[241]\tvalid_0's binary_logloss: 0.150671\n",
      "[242]\tvalid_0's binary_logloss: 0.150865\n",
      "[243]\tvalid_0's binary_logloss: 0.150982\n",
      "[244]\tvalid_0's binary_logloss: 0.151072\n",
      "[245]\tvalid_0's binary_logloss: 0.151116\n",
      "[246]\tvalid_0's binary_logloss: 0.151167\n",
      "[247]\tvalid_0's binary_logloss: 0.151327\n",
      "[248]\tvalid_0's binary_logloss: 0.15131\n",
      "[249]\tvalid_0's binary_logloss: 0.151503\n",
      "[250]\tvalid_0's binary_logloss: 0.151615\n",
      "[251]\tvalid_0's binary_logloss: 0.151629\n",
      "[252]\tvalid_0's binary_logloss: 0.151776\n",
      "[253]\tvalid_0's binary_logloss: 0.151961\n",
      "[254]\tvalid_0's binary_logloss: 0.152266\n",
      "[255]\tvalid_0's binary_logloss: 0.152346\n",
      "[256]\tvalid_0's binary_logloss: 0.152452\n",
      "[257]\tvalid_0's binary_logloss: 0.152522\n",
      "[258]\tvalid_0's binary_logloss: 0.152604\n",
      "[259]\tvalid_0's binary_logloss: 0.152794\n",
      "[260]\tvalid_0's binary_logloss: 0.152813\n",
      "[261]\tvalid_0's binary_logloss: 0.152841\n",
      "[262]\tvalid_0's binary_logloss: 0.153007\n",
      "[263]\tvalid_0's binary_logloss: 0.153128\n",
      "[264]\tvalid_0's binary_logloss: 0.153238\n",
      "[265]\tvalid_0's binary_logloss: 0.153324\n",
      "[266]\tvalid_0's binary_logloss: 0.153369\n",
      "[267]\tvalid_0's binary_logloss: 0.153513\n",
      "[268]\tvalid_0's binary_logloss: 0.153581\n",
      "[269]\tvalid_0's binary_logloss: 0.153616\n",
      "[270]\tvalid_0's binary_logloss: 0.153745\n",
      "[271]\tvalid_0's binary_logloss: 0.153778\n",
      "[272]\tvalid_0's binary_logloss: 0.154065\n",
      "[273]\tvalid_0's binary_logloss: 0.15422\n",
      "[274]\tvalid_0's binary_logloss: 0.154348\n",
      "[275]\tvalid_0's binary_logloss: 0.154454\n",
      "[276]\tvalid_0's binary_logloss: 0.154534\n",
      "[277]\tvalid_0's binary_logloss: 0.154614\n",
      "[278]\tvalid_0's binary_logloss: 0.15469\n",
      "[279]\tvalid_0's binary_logloss: 0.154748\n",
      "[280]\tvalid_0's binary_logloss: 0.154937\n",
      "[281]\tvalid_0's binary_logloss: 0.154979\n",
      "[282]\tvalid_0's binary_logloss: 0.155151\n",
      "[283]\tvalid_0's binary_logloss: 0.155288\n",
      "[284]\tvalid_0's binary_logloss: 0.155454\n",
      "[285]\tvalid_0's binary_logloss: 0.15561\n",
      "[286]\tvalid_0's binary_logloss: 0.155719\n",
      "[287]\tvalid_0's binary_logloss: 0.155859\n",
      "[288]\tvalid_0's binary_logloss: 0.155968\n",
      "[289]\tvalid_0's binary_logloss: 0.156063\n",
      "[290]\tvalid_0's binary_logloss: 0.156211\n",
      "[291]\tvalid_0's binary_logloss: 0.156309\n",
      "[292]\tvalid_0's binary_logloss: 0.156511\n",
      "[293]\tvalid_0's binary_logloss: 0.156686\n",
      "[294]\tvalid_0's binary_logloss: 0.156852\n",
      "[295]\tvalid_0's binary_logloss: 0.156964\n",
      "[296]\tvalid_0's binary_logloss: 0.157132\n",
      "[297]\tvalid_0's binary_logloss: 0.15729\n",
      "[298]\tvalid_0's binary_logloss: 0.15749\n",
      "[299]\tvalid_0's binary_logloss: 0.157547\n",
      "[300]\tvalid_0's binary_logloss: 0.157763\n",
      "[301]\tvalid_0's binary_logloss: 0.15792\n",
      "[302]\tvalid_0's binary_logloss: 0.15802\n",
      "[303]\tvalid_0's binary_logloss: 0.158196\n",
      "[304]\tvalid_0's binary_logloss: 0.158339\n",
      "[305]\tvalid_0's binary_logloss: 0.158629\n",
      "[306]\tvalid_0's binary_logloss: 0.158728\n",
      "[307]\tvalid_0's binary_logloss: 0.158838\n",
      "[308]\tvalid_0's binary_logloss: 0.158994\n",
      "[309]\tvalid_0's binary_logloss: 0.15915\n",
      "[310]\tvalid_0's binary_logloss: 0.159228\n",
      "[311]\tvalid_0's binary_logloss: 0.159389\n",
      "[312]\tvalid_0's binary_logloss: 0.159499\n",
      "[313]\tvalid_0's binary_logloss: 0.159532\n",
      "[314]\tvalid_0's binary_logloss: 0.159669\n",
      "[315]\tvalid_0's binary_logloss: 0.159692\n",
      "[316]\tvalid_0's binary_logloss: 0.159864\n",
      "[317]\tvalid_0's binary_logloss: 0.16013\n",
      "[318]\tvalid_0's binary_logloss: 0.160336\n",
      "[319]\tvalid_0's binary_logloss: 0.160597\n",
      "[320]\tvalid_0's binary_logloss: 0.160785\n",
      "[321]\tvalid_0's binary_logloss: 0.160846\n",
      "[322]\tvalid_0's binary_logloss: 0.161113\n",
      "[323]\tvalid_0's binary_logloss: 0.161293\n",
      "[324]\tvalid_0's binary_logloss: 0.16146\n",
      "[325]\tvalid_0's binary_logloss: 0.161703\n",
      "[326]\tvalid_0's binary_logloss: 0.16196\n",
      "[327]\tvalid_0's binary_logloss: 0.162138\n",
      "[328]\tvalid_0's binary_logloss: 0.162329\n",
      "[329]\tvalid_0's binary_logloss: 0.162551\n",
      "[330]\tvalid_0's binary_logloss: 0.162608\n",
      "[331]\tvalid_0's binary_logloss: 0.162878\n",
      "[332]\tvalid_0's binary_logloss: 0.163158\n",
      "[333]\tvalid_0's binary_logloss: 0.163274\n",
      "[334]\tvalid_0's binary_logloss: 0.163535\n",
      "[335]\tvalid_0's binary_logloss: 0.163616\n",
      "[336]\tvalid_0's binary_logloss: 0.163883\n",
      "[337]\tvalid_0's binary_logloss: 0.16408\n",
      "[338]\tvalid_0's binary_logloss: 0.164146\n",
      "[339]\tvalid_0's binary_logloss: 0.164123\n",
      "[340]\tvalid_0's binary_logloss: 0.164249\n",
      "[341]\tvalid_0's binary_logloss: 0.164436\n",
      "[342]\tvalid_0's binary_logloss: 0.164444\n",
      "[343]\tvalid_0's binary_logloss: 0.164524\n",
      "[344]\tvalid_0's binary_logloss: 0.164592\n",
      "[345]\tvalid_0's binary_logloss: 0.164891\n",
      "[346]\tvalid_0's binary_logloss: 0.164974\n",
      "[347]\tvalid_0's binary_logloss: 0.165211\n",
      "[348]\tvalid_0's binary_logloss: 0.16544\n",
      "[349]\tvalid_0's binary_logloss: 0.165545\n",
      "[350]\tvalid_0's binary_logloss: 0.165542\n",
      "[351]\tvalid_0's binary_logloss: 0.165719\n",
      "[352]\tvalid_0's binary_logloss: 0.165813\n",
      "[353]\tvalid_0's binary_logloss: 0.166007\n",
      "[354]\tvalid_0's binary_logloss: 0.166311\n",
      "[355]\tvalid_0's binary_logloss: 0.16634\n",
      "[356]\tvalid_0's binary_logloss: 0.166528\n",
      "[357]\tvalid_0's binary_logloss: 0.166727\n",
      "[358]\tvalid_0's binary_logloss: 0.166845\n",
      "[359]\tvalid_0's binary_logloss: 0.166928\n",
      "[360]\tvalid_0's binary_logloss: 0.16717\n",
      "[361]\tvalid_0's binary_logloss: 0.167322\n",
      "[362]\tvalid_0's binary_logloss: 0.167575\n",
      "[363]\tvalid_0's binary_logloss: 0.167709\n",
      "[364]\tvalid_0's binary_logloss: 0.167792\n",
      "[365]\tvalid_0's binary_logloss: 0.167991\n",
      "[366]\tvalid_0's binary_logloss: 0.168108\n",
      "[367]\tvalid_0's binary_logloss: 0.168328\n",
      "[368]\tvalid_0's binary_logloss: 0.168307\n",
      "[369]\tvalid_0's binary_logloss: 0.168381\n",
      "[370]\tvalid_0's binary_logloss: 0.168515\n",
      "[371]\tvalid_0's binary_logloss: 0.168683\n",
      "[372]\tvalid_0's binary_logloss: 0.168894\n",
      "[373]\tvalid_0's binary_logloss: 0.168996\n",
      "[374]\tvalid_0's binary_logloss: 0.169063\n",
      "[375]\tvalid_0's binary_logloss: 0.169128\n",
      "[376]\tvalid_0's binary_logloss: 0.169366\n",
      "[377]\tvalid_0's binary_logloss: 0.169543\n",
      "[378]\tvalid_0's binary_logloss: 0.169669\n",
      "[379]\tvalid_0's binary_logloss: 0.169858\n",
      "[380]\tvalid_0's binary_logloss: 0.170045\n",
      "[381]\tvalid_0's binary_logloss: 0.170146\n",
      "[382]\tvalid_0's binary_logloss: 0.170353\n",
      "[383]\tvalid_0's binary_logloss: 0.170577\n",
      "[384]\tvalid_0's binary_logloss: 0.170712\n",
      "[385]\tvalid_0's binary_logloss: 0.170989\n",
      "[386]\tvalid_0's binary_logloss: 0.171083\n",
      "[387]\tvalid_0's binary_logloss: 0.171255\n",
      "[388]\tvalid_0's binary_logloss: 0.171439\n",
      "[389]\tvalid_0's binary_logloss: 0.171522\n",
      "[390]\tvalid_0's binary_logloss: 0.171692\n",
      "[391]\tvalid_0's binary_logloss: 0.171837\n",
      "[392]\tvalid_0's binary_logloss: 0.172159\n",
      "[393]\tvalid_0's binary_logloss: 0.172301\n",
      "[394]\tvalid_0's binary_logloss: 0.172438\n",
      "[395]\tvalid_0's binary_logloss: 0.172789\n",
      "[396]\tvalid_0's binary_logloss: 0.173118\n",
      "[397]\tvalid_0's binary_logloss: 0.173222\n",
      "[398]\tvalid_0's binary_logloss: 0.173417\n",
      "[399]\tvalid_0's binary_logloss: 0.173501\n",
      "[400]\tvalid_0's binary_logloss: 0.173605\n",
      "[401]\tvalid_0's binary_logloss: 0.173738\n",
      "[402]\tvalid_0's binary_logloss: 0.173998\n",
      "[403]\tvalid_0's binary_logloss: 0.174239\n",
      "[404]\tvalid_0's binary_logloss: 0.174353\n",
      "[405]\tvalid_0's binary_logloss: 0.174331\n",
      "[406]\tvalid_0's binary_logloss: 0.174575\n",
      "[407]\tvalid_0's binary_logloss: 0.174721\n",
      "[408]\tvalid_0's binary_logloss: 0.174834\n",
      "[409]\tvalid_0's binary_logloss: 0.175108\n",
      "[410]\tvalid_0's binary_logloss: 0.175332\n",
      "[411]\tvalid_0's binary_logloss: 0.175509\n",
      "[412]\tvalid_0's binary_logloss: 0.175661\n",
      "[413]\tvalid_0's binary_logloss: 0.175945\n",
      "[414]\tvalid_0's binary_logloss: 0.176037\n",
      "[415]\tvalid_0's binary_logloss: 0.176142\n",
      "[416]\tvalid_0's binary_logloss: 0.176391\n",
      "[417]\tvalid_0's binary_logloss: 0.176514\n",
      "[418]\tvalid_0's binary_logloss: 0.176724\n",
      "[419]\tvalid_0's binary_logloss: 0.176883\n",
      "[420]\tvalid_0's binary_logloss: 0.177037\n",
      "[421]\tvalid_0's binary_logloss: 0.177252\n",
      "[422]\tvalid_0's binary_logloss: 0.177406\n",
      "[423]\tvalid_0's binary_logloss: 0.177453\n",
      "[424]\tvalid_0's binary_logloss: 0.177566\n",
      "[425]\tvalid_0's binary_logloss: 0.177682\n",
      "[426]\tvalid_0's binary_logloss: 0.177747\n",
      "[427]\tvalid_0's binary_logloss: 0.177925\n",
      "[428]\tvalid_0's binary_logloss: 0.178116\n",
      "[429]\tvalid_0's binary_logloss: 0.178253\n",
      "[430]\tvalid_0's binary_logloss: 0.178506\n",
      "[431]\tvalid_0's binary_logloss: 0.178743\n",
      "[432]\tvalid_0's binary_logloss: 0.178987\n",
      "[433]\tvalid_0's binary_logloss: 0.179079\n",
      "[434]\tvalid_0's binary_logloss: 0.179326\n",
      "[435]\tvalid_0's binary_logloss: 0.179494\n",
      "[436]\tvalid_0's binary_logloss: 0.179657\n",
      "[437]\tvalid_0's binary_logloss: 0.179892\n",
      "[438]\tvalid_0's binary_logloss: 0.180033\n",
      "[439]\tvalid_0's binary_logloss: 0.180233\n",
      "[440]\tvalid_0's binary_logloss: 0.180343\n",
      "[441]\tvalid_0's binary_logloss: 0.180609\n",
      "[442]\tvalid_0's binary_logloss: 0.180926\n",
      "[443]\tvalid_0's binary_logloss: 0.181144\n",
      "[444]\tvalid_0's binary_logloss: 0.181137\n",
      "[445]\tvalid_0's binary_logloss: 0.181315\n",
      "[446]\tvalid_0's binary_logloss: 0.181583\n",
      "[447]\tvalid_0's binary_logloss: 0.181788\n",
      "[448]\tvalid_0's binary_logloss: 0.181925\n",
      "[449]\tvalid_0's binary_logloss: 0.182119\n",
      "[450]\tvalid_0's binary_logloss: 0.182274\n",
      "[451]\tvalid_0's binary_logloss: 0.182379\n",
      "[452]\tvalid_0's binary_logloss: 0.182449\n",
      "[453]\tvalid_0's binary_logloss: 0.182683\n",
      "[454]\tvalid_0's binary_logloss: 0.182826\n",
      "[455]\tvalid_0's binary_logloss: 0.183024\n",
      "[456]\tvalid_0's binary_logloss: 0.183117\n",
      "[457]\tvalid_0's binary_logloss: 0.183264\n",
      "[458]\tvalid_0's binary_logloss: 0.183411\n",
      "[459]\tvalid_0's binary_logloss: 0.183616\n",
      "[460]\tvalid_0's binary_logloss: 0.183723\n",
      "[461]\tvalid_0's binary_logloss: 0.18399\n",
      "[462]\tvalid_0's binary_logloss: 0.184229\n",
      "[463]\tvalid_0's binary_logloss: 0.1844\n",
      "[464]\tvalid_0's binary_logloss: 0.184611\n",
      "[465]\tvalid_0's binary_logloss: 0.184766\n",
      "[466]\tvalid_0's binary_logloss: 0.184878\n",
      "[467]\tvalid_0's binary_logloss: 0.184914\n",
      "[468]\tvalid_0's binary_logloss: 0.185156\n",
      "[469]\tvalid_0's binary_logloss: 0.185374\n",
      "[470]\tvalid_0's binary_logloss: 0.185408\n",
      "[471]\tvalid_0's binary_logloss: 0.185618\n",
      "[472]\tvalid_0's binary_logloss: 0.18573\n",
      "[473]\tvalid_0's binary_logloss: 0.185788\n",
      "[474]\tvalid_0's binary_logloss: 0.185827\n",
      "[475]\tvalid_0's binary_logloss: 0.18627\n",
      "[476]\tvalid_0's binary_logloss: 0.186369\n",
      "[477]\tvalid_0's binary_logloss: 0.18661\n",
      "[478]\tvalid_0's binary_logloss: 0.186905\n",
      "[479]\tvalid_0's binary_logloss: 0.187091\n",
      "[480]\tvalid_0's binary_logloss: 0.18711\n",
      "[481]\tvalid_0's binary_logloss: 0.187211\n",
      "[482]\tvalid_0's binary_logloss: 0.187406\n",
      "[483]\tvalid_0's binary_logloss: 0.187557\n",
      "[484]\tvalid_0's binary_logloss: 0.18775\n",
      "[485]\tvalid_0's binary_logloss: 0.187938\n",
      "[486]\tvalid_0's binary_logloss: 0.188139\n",
      "[487]\tvalid_0's binary_logloss: 0.188297\n",
      "[488]\tvalid_0's binary_logloss: 0.188509\n",
      "[489]\tvalid_0's binary_logloss: 0.188868\n",
      "[490]\tvalid_0's binary_logloss: 0.188988\n",
      "[491]\tvalid_0's binary_logloss: 0.189096\n",
      "[492]\tvalid_0's binary_logloss: 0.189354\n",
      "[493]\tvalid_0's binary_logloss: 0.189343\n",
      "[494]\tvalid_0's binary_logloss: 0.189616\n",
      "[495]\tvalid_0's binary_logloss: 0.189947\n",
      "[496]\tvalid_0's binary_logloss: 0.190093\n",
      "[497]\tvalid_0's binary_logloss: 0.190239\n",
      "[498]\tvalid_0's binary_logloss: 0.190481\n",
      "[499]\tvalid_0's binary_logloss: 0.190729\n",
      "[500]\tvalid_0's binary_logloss: 0.190789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9011599411860806"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(kevin_train_X,kevin_train_y,train_size=0.8,random_state=2)\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.1,\n",
    "                        n_estimators=400,\n",
    "                        max_bin=255,\n",
    "                        max_depth=40, \n",
    "                        num_iterations=500, \n",
    "                        random_state=11,\n",
    "                        num_leaves = 150,\n",
    "                        silent=False)\n",
    "\n",
    "lg.fit(X_train,y_train, eval_set=(X_test,y_test))\n",
    "pred = lg.predict(X_test)\n",
    "f1_score = metrics.f1_score(y_test,pred)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_bin=255, max_depth=40, n_estimators=400, num_iterations=500,\n",
       "               num_leaves=150, random_state=11, silent=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
